<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Dockerfile FROM]]></title>
    <url>%2F2019%2F04%2F29%2FDockerfile-FROM-1%2F</url>
    <content type="text"><![CDATA[FROM用法1FROM &lt;baseimage&gt; 或者 FROM &lt;baseimage&gt;:&lt;tag&gt; 指定从哪个镜像为基础迭代，如果本地没有镜像则会从仓库拉取，通常是第一行，而scratch是空镜像，是所有rootfs和一些单独可执行文件做镜像的根源，关于scratch后续会说。 例如centos的Dockerfile是下面12345678910FROM scratchADD centos-7-x86_64-docker.tar.xz /LABEL org.label-schema.schema-version="1.0" \ org.label-schema.name="CentOS Base Image" \ org.label-schema.vendor="CentOS" \ org.label-schema.license="GPLv2" \ org.label-schema.build-date="20190305"CMD ["/bin/bash"] 而hello-world为123456FROM scratchCOPY hello /CMD ["/hello"]docker images | grep hellohello-world latest fce289e99eb9 3 months ago 1.84kB nginx:alpine镜像的dockerfile 链接为https://github.com/nginxinc/docker-nginx/blob/7d7c67f2eaa6b2b32c718ba9d93f152870513c7c/mainline/alpine/Dockerfile，大家可以仿照这个经典案例写出自己的Dockerfile。 nginx:alpine既满足运行的最小环境下大小又很小，主要归功于FROM alpine ，现在alpine这个系统和rootfs得益于docker发展非常快，也有很多应用镜像都有alpine版本。 12345678910111213141516FROM alpine:3.9LABEL maintainer="NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;"ENV NGINX_VERSION 1.15.11RUN ...省略步骤，步骤是下载源码，安装编译需要的依赖，编译安装完删掉源码包和编译的依赖保留运编译出来的nginx二进制和需要的所有so文件COPY nginx.conf /etc/nginx/nginx.confCOPY nginx.vh.default.conf /etc/nginx/conf.d/default.confEXPOSE 80STOPSIGNAL SIGTERMCMD ["nginx", "-g", "daemon off;"]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像03]]></title>
    <url>%2F2019%2F04%2F29%2FDocker%E9%95%9C%E5%83%8F03%2F</url>
    <content type="text"><![CDATA[构建镜像构建镜像只有两种方式，docker build 和 docker commit。实际上docker build是调用的docker commit。不推荐手动去docker commmit运行的容器成镜像。所以主要讲docker build和dockerfile。 使用docker build 指定Dockerfile来完成一个新镜像的构建。命令格式一般为：1docker build [option] [-t &lt;image&gt;:&lt;tag&gt;] &lt;path&gt; 其中path指向的文件称为context（上下文），context包含docker build镜像过程中需要的Dockerfile以及其他的资源文件。执行build命令后执行流程如下： Docker client端 解析命令行参数，完成对相关信息的设置，Docker client向Docker server发送POST/build的HTTP请求，包含了所需的上下文文件。 Docker server端 创建一个临时目录，并将context指定的文件系统解压到该目录下 读取并解析Dockerfile 根据解析出的Dockerfile遍历其中的所有指令，并分发到不同的模块（parser）去执行 parser为Dockerfile的每一个指令创建一个对应的临时容器，在临时容器中执行当前指令，然后通过commit使用此镜像生成一个镜像层 Dockerfile中所有的指令对应的层的集合，就是此次build后的结果。如果指定了tag参数，便给镜像打上对应的tag。最后一次commit生成的镜像ID就会作为最终的镜像ID返回。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像02]]></title>
    <url>%2F2019%2F04%2F29%2FDocker%E9%95%9C%E5%83%8F02%2F</url>
    <content type="text"><![CDATA[容器是单独的一层读写层一个镜像可以运行无数个容器，容器需要读取文件的场景和对应原理是如下。 在无挂载卷情况下，通过docker cp或exec产生的数据，文件会在读写层里，删除容器则文件也一并删除。 读取文件，从上层往下找到镜像层，找到即可返回，复制到容器层读入内存。 修改文件，从上层往下找到镜像层，找到即可返回，复制到容器层后修改。 删除文件，找到后在容器层记录下删除操作(类似盖层布，后续读取的时候会认为文件不存在) 容器与镜像关系为下图 通过docker ps 的-s选项可以看出容器的size和容器层总大小，这里我用docker命令演示下容器是单独一层读写层和容器被删除后数据消失。 创建一个容器，在容器里写入1g数据，宿主机的可用容量减少1G，docker的overlay2存储目录记录了下这个文件，但是删除后文件也被删除了。在抽象逻辑上一个容器就是单独一个读写层，而删除容器后这层在宿主机上的文件也会被删除。 计算实际占用大小时镜像的大小不会被重复计算，只需要计算一个大小+它起的所有容器大小。目前启动了5个nginx1234567# docker ps -sCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES SIZEac5c0d1f8d6b nginx:alpine "nginx -g 'daemon of…" 7 seconds ago Up 5 seconds 80/tcp web5 2B (virtual 16.1MB)0dd2c0c36084 nginx:alpine "nginx -g 'daemon of…" 11 seconds ago Up 9 seconds 80/tcp web4 2B (virtual 16.1MB)413d9270c702 nginx:alpine "nginx -g 'daemon of…" 15 seconds ago Up 13 seconds 80/tcp web3 2B (virtual 16.1MB)43f8e010f7bb nginx:alpine "nginx -g 'daemon of…" 19 seconds ago Up 17 seconds 80/tcp web2 2B (virtual 16.1MB)610abcfab29d nginx:alpine "nginx -g 'daemon of…" 25 seconds ago Up 23 seconds 80/tcp web1 2B (virtual 16.1MB) 使用exec往容器里写数据123456789101112docker exec web1 sh -c 'dd if=/dev/zero of=/test.log bs=1000000 count=10'docker exec web2 sh -c 'dd if=/dev/zero of=/test.log bs=1000000 count=20'docker exec web3 sh -c 'dd if=/dev/zero of=/test.log bs=1000000 count=30'docker exec web4 sh -c 'dd if=/dev/zero of=/test.log bs=1000000 count=40'docker exec web5 sh -c 'dd if=/dev/zero of=/test.log bs=1000000 count=50']# docker ps -asCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES SIZEac5c0d1f8d6b nginx:alpine "nginx -g 'daemon of…" 56 seconds ago Up 54 seconds 80/tcp web5 50MB (virtual 66.1MB)0dd2c0c36084 nginx:alpine "nginx -g 'daemon of…" About a minute ago Up 58 seconds 80/tcp web4 40MB (virtual 56.1MB)413d9270c702 nginx:alpine "nginx -g 'daemon of…" About a minute ago Up About a minute 80/tcp web3 30MB (virtual 46.1MB)43f8e010f7bb nginx:alpine "nginx -g 'daemon of…" About a minute ago Up About a minute 80/tcp web2 20MB (virtual 36.1MB)610abcfab29d nginx:alpine "nginx -g 'daemon of…" About a minute ago Up About a minute 80/tcp web1 10MB (virtual 26.1MB) 实际占用量计算123456781 x 16.1MB 只读镜像层1 x 10MB1 x 20MB1 x 30MB1 x 40MB1 x 50MB===========================161.1MB 这样我们可以推导出docker镜像是分层和容器是单独一层只读镜像的。也有部分人不懂这些知识，每次是进容器里安装东西然后commit，导致最后容器越来越大，甚至看到过16g的镜像。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像01]]></title>
    <url>%2F2019%2F04%2F29%2FDocker%E9%95%9C%E5%83%8F01%2F</url>
    <content type="text"><![CDATA[Docker镜像层镜像为什么是有层的？镜像分层是为了解决什么？ 虽然镜像解决了打包，但是实际应用中我们的应用都是基于同一个rootfs来打包和迭代的，难道每个rootfs都会多份吗？ 为此docker利用了存储驱动AUFS，devicemapper，overlay，overlay2的存储技术实现了分层。初期是AUFS，到现在的overlay2驱动（不推荐devicemapper坑很多）。例如一个nginx:alpine和python:alpine镜像可以从分层角度这样去理解。 实际上只有不同的层才占据存储空间，相同的层则是引用关系。抽象地看镜像是一个实体，实际上是/var/lib/docker目录里的分层文件外加一些json和db文件把层联系起来组成了镜像。存储路径是/var/lib/docker/存储驱动类型/。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[proxmox中cloud-init使用方法]]></title>
    <url>%2F2019%2F04%2F18%2Fproxmox%E4%B8%ADcloud-init%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[模版制作标准分区ext4，不添加swap分区，原因下文说。 系统装完后，将网卡配置文件内的onboot打开，清除uuid。关闭selinux和firewalld以及碍事的NetworkManager。123systemctl disable --now firewalld NetworkManagersetenforce 0sed -ri '/^[^#]*SELINUX=/s#=.+$#=disabled#' /etc/selinux/config 为了让虚拟化层可以重启和关闭虚拟机，必须安装acpid服务；为了使根分区正确调整大小安装cloud-utils-growpart，cloud-init支持下发前设置信息写入。12yum install -y acpid cloud-init cloud-utils-growpartsystemctl enable acpid 禁用默认zeroconf路线1echo "NOZEROCONF=yes" &gt;&gt; /etc/sysconfig/network 防止ssh连接使用dns导致访问过慢12sed -ri '/UseDNS/&#123;s@#@@;s@\s+.+@ no@&#125;' /etc/ssh/sshd_configsystemctl restart sshd cloud-init配置文件:1. ssh_pwauth 为 0 是禁止使用password登陆。2. disable_root：1 是禁止root登陆。3. package-update-upgrade-install会在第一次开机启动时自动yum update -y。123sed -ri '/disable_root/&#123;s#\S$#0#&#125;' /etc/cloud/cloud.cfgsed -ri '/ssh_pwauth/&#123;s#\S$#1#&#125;' /etc/cloud/cloud.cfgsed -ri '/package-update/s@^@#@' /etc/cloud/cloud.cfg 默认cloud-init会创建一个系统类型的用户,可以注释掉。1234567# default_user:# name: centos# lock_passwd: true# gecos: Cloud User# groups: [wheel, adm, systemd-journal]# sudo: ["ALL=(ALL) NOPASSWD:ALL"]# shell: /bin/bash 安装些基础包和预设一些脚本的话就可以关机。12yum install vim git wget -ypoweroff 转换模版12345678root@pve:~# qm list VMID NAME STATUS MEM(MB) BOOTDISK(GB) PID 100 cloud-init stopped 2048 20.00 0 101 k8s-m1 running 2048 20.00 7438root@pve:~# qm set 100 --ide2 local-lvm:cloudinitupdate VM 100: -ide2 local-lvm:cloudinit Using default stripesize 64.00 KiB. Logical volume "vm-100-cloudinit" created. 在Dashboard上可以看到虚拟机的could-init部分已经可以更改属性了。 在Dashboard上把它转换成模板,部署时完整克隆,开机之前双击需要设置的信息即可,否则例如密码不设置默认是模板的密码。也可以通过命令行初始化虚拟机信息。1qm set &lt;vmid&gt; --ipconfig0 ip=10.105.26.x/23,gw=10.105.26.1 备份和恢复虚拟机123456789101112131415161718192021222324252627282930313233root@pve:~# vzdump 100INFO: starting new backup job: vzdump 100INFO: Starting Backup of VM 100 (qemu)INFO: status = stoppedINFO: update VM 100: -lock backupINFO: backup mode: stopINFO: ionice priority: 7INFO: VM Name: cloud-initINFO: include disk 'scsi0' 'local-lvm:vm-100-disk-0' 20GINFO: creating archive '/var/lib/vz/dump/vzdump-qemu-100-2019_04_18-12_48_38.vma'INFO: starting kvm to execute backup taskTotal translation table size: 0Total rockridge attributes bytes: 417Total directory bytes: 0Path table size(bytes): 10Max brk space used 0178 extents written (0 MB)INFO: started backup task 'd65a8f26-20fe-4232-abd3-ec0bcf4623cd'INFO: status: 3% (785645568/21474836480), sparse 1% (395206656), duration 3, read/write 261/130 MB/sINFO: status: 21% (4593876992/21474836480), sparse 19% (4184059904), duration 6, read/write 1269/6 MB/sINFO: status: 34% (7457996800/21474836480), sparse 32% (6929133568), duration 9, read/write 954/39 MB/sINFO: status: 50% (10746396672/21474836480), sparse 46% (10083291136), duration 12, read/write 1096/44 MB/sINFO: status: 61% (13169524736/21474836480), sparse 57% (12349382656), duration 15, read/write 807/52 MB/sINFO: status: 70% (15039004672/21474836480), sparse 64% (13956280320), duration 18, read/write 623/87 MB/sINFO: status: 80% (17196580864/21474836480), sparse 74% (15934279680), duration 21, read/write 719/59 MB/sINFO: status: 89% (19120455680/21474836480), sparse 82% (17667883008), duration 24, read/write 641/63 MB/sINFO: status: 95% (20594622464/21474836480), sparse 88% (18997477376), duration 27, read/write 491/48 MB/sINFO: status: 100% (21474836480/21474836480), sparse 92% (19877691392), duration 28, read/write 880/0 MB/sINFO: transferred 21474 MB in 28 seconds (766 MB/s)INFO: stopping kvm after backup taskINFO: archive file size: 1.49GBINFO: Finished Backup of VM 100 (00:00:32)INFO: Backup job finished 输出路径在：/var/lib/vz/dump/，导入的话使用如下命令1qmrestore vzdump-qemu-xx.vma &lt;vmid&gt;]]></content>
      <categories>
        <category>Proxmox</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s配置secret拉取私有仓库镜像]]></title>
    <url>%2F2019%2F04%2F10%2Fk8s%E9%85%8D%E7%BD%AEsecret%E6%8B%89%E5%8F%96%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[https://kubernetes.io/docs 样例1234567891011# cat ~/.docker/config.json &#123; "auths": &#123; "harbor.station.com": &#123; "auth": "YWRtaW46SGFyYm9yMTIzNDU=" &#125; &#125;, "HttpHeaders": &#123; "User-Agent": "Docker-Client/18.06.1-ce (linux)" &#125;&#125; 这个时候我们虽然可以通过交互式登录，使用docker pull拉取镜像，但无法通过k8s创建Pod时拉取镜像。 生成密钥secret1# kubectl create secret docker-registry harbor --docker-server=x.x.x.x --docker-username=admin --docker-password=Harbor12345 --docker-email=xx@qq.com 1) harbor: 指定密钥的键名称，可自行定义 2）–docker-server：指定docker仓库地址 3）–docker-username：指定docker仓库帐号 4) –docker-password：指定docker仓库密码 5) –docker-email：指定邮件地址（选填）` 查看密钥可以看到当前除了默认的密钥, 还有我们刚才生成的. 另外要注意的是, 该密钥只能在对应namespace使用, 也就是这里的default, 如果需要用到其他namespace, 比如说test, 就需要在生成的时候指定参数 -n test。1234# kubectl get secretsNAME TYPE DATA AGEdefault-token-mzmtj kubernetes.io/service-account-token 3 22mharbor kubernetes.io/dockerconfigjson 1 22m YAML例子其中imagePullSecrets是声明拉取镜像时需要指定密钥, harbor必须和上面生成密钥的键名一致, 另外检查一下pod和密钥是否在同一个namespace, 之后k8s便可以拉取镜像。1234567891011121314151617apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deploy namespace: harborspec: replicas: 3 template: metadata: labels: app: web_server spec: containers: - name: nginx image: harbor.station.com/library/nginx:latest imagePullSecrets: - name: harbor]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Harbor</tag>
      </tags>
  </entry>
</search>
