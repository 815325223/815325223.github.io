<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr.Cheng</title>
  
  <subtitle>目标星辰大海，自当日夜兼程</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-16T01:04:06.716Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Mr.Cheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>集群常用设置</title>
    <link href="http://yoursite.com/2019/05/15/%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/"/>
    <id>http://yoursite.com/2019/05/15/集群常用设置/</id>
    <published>2019-05-15T15:35:00.000Z</published>
    <updated>2019-05-16T01:04:06.716Z</updated>
    
    <content type="html"><![CDATA[<h1 id="服务器CentOS系统安装完毕后的基本配置"><a href="#服务器CentOS系统安装完毕后的基本配置" class="headerlink" title="服务器CentOS系统安装完毕后的基本配置"></a>服务器CentOS系统安装完毕后的基本配置</h1><p>使用root用户在管理节点和计算节点上进行以下操作：</p><ul><li><p>修改/etc/profile.d/perl-homedir.sh配置文件，以免每次登录用户，自动在家目录下生成perl5文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perl -p -i -e <span class="string">'s/PERL_HOMEDIR=1/PERL_HOMEDIR=0/'</span> /etc/profile.d/perl-homedir.sh</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'eval "$(perl -Mlocal::lib=$HOME/.perl5)"'</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>修改/etc/sudoers配置文件，将自己的用户（例如 train）变成超级管理员用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl -i.bak -e <span class="string">'while (&lt;&gt;) &#123; if (/^root/) &#123; print; print "train   ALL=(ALL)       NOPASSWD:ALL\n"; last; &#125; else &#123; print &#125; &#125;'</span> /etc/sudoers</span><br></pre></td></tr></table></figure></li><li><p>修改/etc/selinux/config配置文件，永久关闭linux的一个安全机制，开启该安全机制会对很多操作造成阻碍。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perl -p -i -e <span class="string">'s/SELINUX=enforcing/SELINUX=disabled/'</span> /etc/selinux/config</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure></li><li><p>修改/etc/ssh/sshd_config配置文件，使openssh远程登录更安全，更快速</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">perl -p -i -e <span class="string">'s/#RSAAuthentication/RSAAuthentication/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/#PubkeyAuthentication/PubkeyAuthentication/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/#AuthorizedKeysFile/AuthorizedKeysFile/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/.*PermitRootLogin.*/PermitRootLogin no/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/.*Protocol\s+2.*/Protocol 2/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/.*ClientAliveInterval.*/ClientAliveInterval 60/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/.*ClientAliveCountMax.*/ClientAliveCountMax 10/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/.*UseDNS.*/UseDNS no/'</span> /etc/ssh/sshd_config</span><br><span class="line">perl -p -i -e <span class="string">'s/GSSAPIAuthentication yes/GSSAPIAuthentication no/'</span> /etc/ssh/sshd_config</span><br><span class="line">systemctl restart sshd.service</span><br></pre></td></tr></table></figure></li><li><p>增加系统资源权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">perl -p -i -e <span class="string">'s/^\*.*\n$//'</span> /etc/security/limits.conf</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/security/limits.conf</span><br><span class="line">*       soft    nofile  10240</span><br><span class="line">*       hard    nofile  102400</span><br><span class="line">*       soft    stack   10240</span><br><span class="line">*       hard    stack   102400</span><br><span class="line">*       soft    core    unlimited</span><br><span class="line">*       hard    core    unlimited</span><br><span class="line">*       soft    nproc   10240</span><br><span class="line">*       hard    nproc   102400</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h1 id="配置集群中各服务器的主机名和IP地址"><a href="#配置集群中各服务器的主机名和IP地址" class="headerlink" title="配置集群中各服务器的主机名和IP地址"></a>配置集群中各服务器的主机名和IP地址</h1><p>使用root用户在管理节点 和计算节点服务器上对infiniband网口进行配置，修改 /etc/sysconfig/network-scripts/ifcfg-ib0 配置文件内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BOOTPROTO=none</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.1.12</span><br><span class="line">PREFIX=24</span><br><span class="line">GATEWAY=192.168.1.1</span><br></pre></td></tr></table></figure></p><p>修改好ifcfg文件后，重启网络服务，使生效：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure></p><p>各节点服务器在infiniband网络之间的联通需要在控制节点node1上安装一些相关的系统软件，并启用相应服务：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install opensm* opensm-devel* infiniband-diags perftest* gperf* opensm*</span><br><span class="line">systemctl restart opensm.service</span><br><span class="line">systemctl <span class="built_in">enable</span> rdma.service</span><br><span class="line">systemctl <span class="built_in">enable</span> opensm.service</span><br></pre></td></tr></table></figure></p><p>然后将所有节点服务器的 /etc/hosts 文件内容修改成同样的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; /etc/hosts</span><br><span class="line">192.168.1.12    master</span><br><span class="line">192.168.1.13    node01</span><br><span class="line">192.168.1.14    node02</span><br><span class="line">192.168.1.15    node03</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p><h1 id="将控制节点的以太网共享给计算节点"><a href="#将控制节点的以太网共享给计算节点" class="headerlink" title="将控制节点的以太网共享给计算节点"></a>将控制节点的以太网共享给计算节点</h1><p>控制节点通过电信100M宽带连接外网，通过网线将master控制节点连接到电信网关（光猫和路由器合一的电信盒子）上。设置网口自动使用DHCP方法分配IP地址即可。在外网可以正常连接的情况，可以将该网络通过infiniband网卡共享给其它计算节点。</p><p>在master控制节点上使用root用户进行操作：</p><ul><li>开启NAT转发</li><li>开放DNS使用的53端口并重启防火墙，否则可能导致内网服务器虽然设置正确的DNS，但是依然无法进行域名解析。</li><li><p>控制节点上是在eth0网口连接外网，对其网络进行共享。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> firewall-cmd --permanent --zone=public --add-masquerade</span><br><span class="line"></span><br><span class="line"> firewall-cmd --zone=public --add-port=53/tcp --permanent</span><br><span class="line">systemctl restart firewalld.service</span><br><span class="line"></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">'net.ipv4.ip_forward=1'</span> &gt;&gt; /etc/sysctl.conf</span><br><span class="line"> sysctl -p</span><br><span class="line"> firewall-cmd --permanent --direct --passthrough ipv4 -t nat -I POSTROUTING -o eth0 -j MASQUERADE -s 12.12.12.0/24</span><br><span class="line"> systemctl restart firewalld.service</span><br></pre></td></tr></table></figure></li></ul><p>在计算节点上对infiniband网卡进行IP设置时，将网关设置成提供网络的主机IP即可，即将网关设置成master管理节点的IP地址。</p><h1 id="将控制节点的存储共享给计算节点"><a href="#将控制节点的存储共享给计算节点" class="headerlink" title="将控制节点的存储共享给计算节点"></a>将控制节点的存储共享给计算节点</h1><p>在控制节点master服务器上，修改NFS配置文件/etc/sysconfig/nfs配置文件，打开所有带有PORT的注释行，表示使用相应的防火墙端口，并修改防火墙配置，开放对应端口：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">perl -p -i -e <span class="string">'s/^#(.*PORT)/$1/'</span> /etc/sysconfig/nfs</span><br><span class="line"></span><br><span class="line">firewall-cmd --add-port=32803/udp --permanent</span><br><span class="line">firewall-cmd --add-port=32803/tcp --permanent</span><br><span class="line">firewall-cmd --add-port=32769/udp --permanent</span><br><span class="line">firewall-cmd --add-port=32769/tcp --permanent</span><br><span class="line">firewall-cmd --add-port=892/udp --permanent</span><br><span class="line">firewall-cmd --add-port=892/tcp --permanent</span><br><span class="line">firewall-cmd --add-port=662/udp --permanent</span><br><span class="line">firewall-cmd --add-port=662/tcp --permanent</span><br><span class="line">firewall-cmd --add-port=2020/udp --permanent</span><br><span class="line">firewall-cmd --add-port=2020/tcp --permanent</span><br><span class="line">firewall-cmd --add-port=875/udp --permanent</span><br><span class="line">firewall-cmd --add-port=875/tcp --permanent</span><br><span class="line"></span><br><span class="line">systemctl restart firewalld.service</span><br></pre></td></tr></table></figure></p><p>然后，在控制节点master服务器上，启动NFS服务，并设置成开机启动：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart rpcbind.service</span><br><span class="line">systemctl restart nfs.service</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind.service</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs.service</span><br></pre></td></tr></table></figure></p><p>继续，在控制节点master服务器上， 修改/etc/exports文件内容，添加被共享的文件夹信息，并使配置生效：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/exports</span><br><span class="line">/disk   192.168.1.0/24(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/opt    192.168.1.0/24(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">exportfs -rv</span><br></pre></td></tr></table></figure></p><p>在各计算节点服务器上，使用root用户修改配置文件/etc/fstab，对master的共享文件夹进行挂载：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir /disk</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/fstab</span><br><span class="line">192.168.1.12:/disk        /disk   nfs     defaults        0       0</span><br><span class="line">192.168.1.12:/opt /opt    nfs     defaults        0       0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">mount -a</span><br></pre></td></tr></table></figure></p><h1 id="在集群计算机上创建新用户"><a href="#在集群计算机上创建新用户" class="headerlink" title="在集群计算机上创建新用户"></a>在集群计算机上创建新用户</h1><p>首先，生成文件/disk/users.txt。该文件每行一个待生成的用户名。</p><p>然后，在所有节点服务器中进行操作，生成用户并使create_random_passwd.pl命令赋予随机密码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /disk</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat users.txt`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    useradd <span class="variable">$i</span> 2&gt; /dev/null</span><br><span class="line">    ./create_random_passwd.pl <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>在控制节点master服务器中进行操作：在大容量存储对应的共享文件夹中建立新用户的专属文件夹；使用root用户生成新用户的ssh密钥对数据和授权文件信息并放入到各新用户的家目录下。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/bin/rm /disk/ssh_info/ -rf</span><br><span class="line">mkdir -p /disk/ssh_info/</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat users.txt`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    mkdir /disk/ssh_info//<span class="variable">$i</span> /disk/<span class="variable">$i</span></span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /disk/<span class="variable">$i</span></span><br><span class="line">    chmod 700 /disk/<span class="variable">$i</span></span><br><span class="line">    ssh-keygen -t dsa -P <span class="string">''</span> -f /disk/ssh_info/<span class="variable">$i</span>/id_dsa</span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /disk/ssh_info/<span class="variable">$i</span></span><br><span class="line">    mkdir /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    /bin/cp -a /disk/ssh_info/<span class="variable">$i</span>/* /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    chmod 700 /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    cat /disk/ssh_info/<span class="variable">$i</span>/id_dsa.pub &gt;&gt; /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line">    chmod 600 /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>在各个计算节点服务器中使用root用户将上一步生成的ssh密钥对数据和授权文件信息放入到计算节点服务器中各新用户的家目录下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /disk</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat users.txt`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    useradd <span class="variable">$i</span> 2&gt; /dev/null</span><br><span class="line">    ./create_random_passwd.pl <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat users.txt`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    mkdir /home/<span class="variable">$i</span>/.ssh </span><br><span class="line">    /bin/cp -a /disk/ssh_info/<span class="variable">$i</span>/* /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    chmod 700 /home/<span class="variable">$i</span>/.ssh</span><br><span class="line">    cat /disk/ssh_info/<span class="variable">$i</span>/id_dsa.pub &gt;&gt; /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line">    chown -R <span class="variable">$i</span>:<span class="variable">$i</span> /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line">    chmod 600 /home/<span class="variable">$i</span>/.ssh/authorized_keys</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>create_random_passwd.pl程序代码：<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/perl</span></span><br><span class="line"><span class="comment">#use strict;</span></span><br><span class="line"><span class="keyword">use</span> Getopt::Long;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $usage = &lt;&lt;USAGE;</span><br><span class="line">Usage:</span><br><span class="line">    $0 [options] username</span><br><span class="line"></span><br><span class="line">    使用root用户执行该程序，输入用户名，则能调用passwd命令给该用户创建一个随机密码。并将用户名及其密码输出到标准输出。</span><br><span class="line">    --<span class="keyword">length</span> &lt;<span class="keyword">int</span>&gt;    default:<span class="number">10</span></span><br><span class="line">    设置生成密码的字符长度。</span><br><span class="line"></span><br><span class="line">USAGE</span><br><span class="line"><span class="keyword">if</span> (@ARGV==<span class="number">0</span>) &#123; <span class="keyword">die</span> $usage &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $length;</span><br><span class="line">GetOptions(</span><br><span class="line">    <span class="string">"length:i"</span> =&gt; \$length,</span><br><span class="line">);</span><br><span class="line">$length ||= <span class="number">10</span>;</span><br><span class="line"><span class="keyword">my</span> @cha = (<span class="string">'!'</span>, <span class="string">'@'</span>, <span class="string">'#'</span>, <span class="string">'$'</span>, <span class="string">'%'</span>, <span class="string">'^'</span>, <span class="string">'&amp;'</span>, <span class="string">'*'</span>, <span class="string">'.'</span>, <span class="string">'_'</span>);</span><br><span class="line"><span class="keyword">foreach</span> (<span class="number">0</span>..<span class="number">9</span>) &#123;</span><br><span class="line">    <span class="keyword">push</span> @cha, $_;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">foreach</span> (a..z) &#123;</span><br><span class="line">    <span class="keyword">push</span> @cha, $_;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">foreach</span> (A..Z) &#123;</span><br><span class="line">    <span class="keyword">push</span> @cha, $_;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $passwd;</span><br><span class="line"><span class="keyword">for</span> (<span class="number">1</span>..$length) &#123;</span><br><span class="line">    <span class="keyword">my</span> $cha_num = <span class="keyword">rand</span>(@cha);</span><br><span class="line">    $passwd .= $cha[$cha_num];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">print</span> <span class="string">"$ARGV[0]\t$passwd\n"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $cmdString = <span class="string">"echo \'$passwd\' | passwd --stdin $ARGV[0] &amp;&gt; /dev/null"</span>;</span><br><span class="line">(<span class="keyword">system</span> $cmdString) == <span class="number">0</span> <span class="keyword">or</span> <span class="keyword">die</span> <span class="string">"Faield to excute: $cmdString, $!\n"</span>;</span><br></pre></td></tr></table></figure></p><h1 id="远程桌面软件vncserver安装和使用"><a href="#远程桌面软件vncserver安装和使用" class="headerlink" title="远程桌面软件vncserver安装和使用"></a>远程桌面软件vncserver安装和使用</h1><p>由于控制节点master是连接到了电信网关上，没有固定IP地址，推荐使用vnc来对内网服务器使用图形化桌面方法进行控制。</p><p>首先，使用root用户在master服务器上进行操作，安装vncserver软件并开放相应的防火墙5901，5902，5903端口：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install vcn vnc-server</span><br><span class="line"></span><br><span class="line">firewall-cmd --zone=pulic --add-port=5901/tcp --permanent</span><br><span class="line">firewall-cmd --zone=pulic --add-port=5902/tcp --permanent</span><br><span class="line">firewall-cmd --zone=pulic --add-port=5903/tcp --permanent</span><br><span class="line">systemctl restart firewalld.service</span><br></pre></td></tr></table></figure></p><p>然后，使用普通用户（例如，train）开启vncserver服务：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vncserver</span><br><span class="line"><span class="comment"># 第一次启动需要输入密码</span></span><br></pre></td></tr></table></figure></p><p>进行其它vnc操作并修改桌面分辨率，提供更好的vnc体验：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">查看当前开启的vncserver桌面列表</span><br><span class="line">vncserver -list</span><br><span class="line"></span><br><span class="line">查看第一个vncserver桌面的端口号</span><br><span class="line">cat ~/.vnc/node1\:1.log</span><br><span class="line"></span><br><span class="line">关闭第一个vncserver桌面 </span><br><span class="line">vncserver -<span class="built_in">kill</span> :1</span><br><span class="line"></span><br><span class="line">修改vncserver桌面的分辨率</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; .vnc/config</span><br><span class="line">geometry=2000x1052</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">关闭后再次启动vncserver桌面，则分辨率变得更好了</span><br><span class="line">vncserve</span><br></pre></td></tr></table></figure></p><p>为了让vnc能在外网对master进行控制。需要将master控制节点服务器和公网服务器使用ssh进行连接，开启反向隧道，并进行端口转发，在master服务器上进行操作。以下命令将master服务器VNC服务对应的5901端口映射到公网服务器xxx.xx.xxx.xx的4497端口上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -R 4497:localhost:5901 train@xxx.xx.xxx.xx</span><br></pre></td></tr></table></figure></p><p>注意，以上命令需要在公网服务器xxx.xx.xxx.xx上拥有train用户的密码，才能ssh连接成功；并且，还需要使用该公网服务器的root用户开启4497防火墙端口，同时在ssh配置文件设置允许端口转发，才能使vnc访问生效。</p><p>最后，在windows系统下下载vncviewer软件，然后安装并打开软件，输入xxx.xx.xxx.xx:4497，再输入之前设置的密码，即可访问远程桌面。</p><h1 id="在控制节点上控制计算节点的开机和关机"><a href="#在控制节点上控制计算节点的开机和关机" class="headerlink" title="在控制节点上控制计算节点的开机和关机"></a>在控制节点上控制计算节点的开机和关机</h1><p>在控制节点上，对计算节点可以使用ssh连接并导入shutdown指令的方法进关机。基于此原理，编写名为poweroff的Perl程序来对指定的节点进行关机。该程序代码：<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/perl</span></span><br><span class="line"><span class="keyword">use</span> strict;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $usage = &lt;&lt;USAGE;</span><br><span class="line">Usage:</span><br><span class="line">    $0 node1<span class="number">0</span> node11 node12 ...</span><br></pre></td></tr></table></figure></p><p>使用此命令关闭目标节点。该命令后可以输入1个或多个主机名，关闭相应的计算节点。若命令后输入的主机名中有一个是all，则会关闭所有的计算节点（从node11到node20）。此外，支持node11-node15这样中间带有中划线的输入方法，表示多个连续的节点。<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">For example:</span><br><span class="line">    $0 node11 node13-node16 node2<span class="number">0</span></span><br><span class="line"></span><br><span class="line">USAGE</span><br><span class="line"><span class="keyword">if</span> (@ARGV==<span class="number">0</span>)&#123;<span class="keyword">die</span> $usage&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> @node = <span class="keyword">qw</span>/node1<span class="number">0</span> node11 node12 node13 node14 node15 node16 node17 node18 node19 node2<span class="number">0</span>/;</span><br><span class="line"><span class="keyword">my</span> %node;</span><br><span class="line"><span class="keyword">foreach</span> (@node) &#123; $node&#123;$_&#125; = <span class="number">1</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> %target;</span><br><span class="line"><span class="keyword">foreach</span> (@ARGV) &#123;</span><br><span class="line">    <span class="keyword">if</span> ($_ eq <span class="string">"all"</span>) &#123;</span><br><span class="line">        <span class="keyword">foreach</span> (@node) &#123; $target&#123;$_&#125; = <span class="number">1</span>; &#125;</span><br><span class="line">        <span class="keyword">last</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">elsif</span> (<span class="regexp">m/(\d+)-node(\d+)/</span>) &#123;</span><br><span class="line">        <span class="keyword">foreach</span> ($1 .. $2) &#123;</span><br><span class="line">            $target&#123;<span class="string">"node$_"</span>&#125; = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">exists</span> $node&#123;$_&#125;) &#123;</span><br><span class="line">            $target&#123;$_&#125; = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">print</span> STDERR <span class="string">"Warning: $_不是能控制的目标节点。\n"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">foreach</span> (<span class="keyword">sort</span> <span class="keyword">keys</span> %target) &#123;</span><br><span class="line">    &amp;guanji($_);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">sub</span> <span class="title">guanji</span> </span>&#123;</span><br><span class="line">    <span class="keyword">print</span> STDERR <span class="string">"正在检测到 $_ 的连接\n"</span>;</span><br><span class="line">    <span class="keyword">my</span> $ping = <span class="string">`ping $_ -c 1`</span>;</span><br><span class="line">    <span class="keyword">if</span> ($ping =~ <span class="regexp">m/Unreachable/</span>) &#123;</span><br><span class="line">        <span class="keyword">print</span> STDERR <span class="string">"Warning: $_连接失败，可能已经处于关机状态。\n"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">my</span> $cmdString = <span class="string">"ssh $_ 'sudo shutdown -h now' &amp;&gt; /dev/null"</span>;</span><br><span class="line">        <span class="keyword">system</span> $cmdString;</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"对主机 $_ 已经发送关机指令\n"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在控制节点node1上，可以使用<a href="http://www.chenlianfu.com/?p=2874" target="_blank" rel="noopener">wol软件基于网络唤醒的方法对计算节点进行开机</a>。基于此原理，编写名为 kaiji 的Perl程序对指定节点进行开机。该程序代码：<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/perl</span></span><br><span class="line"><span class="keyword">use</span> strict;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> $usage = &lt;&lt;USAGE;</span><br><span class="line">Usage:</span><br><span class="line">    $0 node1<span class="number">0</span> node11 node12 ...</span><br></pre></td></tr></table></figure></p><p>使用此命令开启目标节点。该命令后可以输入1个或多个主机名，开启相应的计算节点。若命令后输入的主机名中有一个是all，则会开启所有的计算节点（从node11到node20）。此外，支持node11-node15这样中间带有中划线的输入方法，表示多个连续的节点。<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">For example:</span><br><span class="line">    $0 node11 node13-node16 node2<span class="number">0</span></span><br><span class="line"></span><br><span class="line">USAGE</span><br><span class="line"><span class="keyword">if</span> (@ARGV==<span class="number">0</span>)&#123;<span class="keyword">die</span> $usage&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> @node = <span class="keyword">qw</span>/node1<span class="number">0</span> node11 node12 node13 node14 node15 node16 node17 node18 node19 node2<span class="number">0</span>/;</span><br><span class="line"><span class="keyword">my</span> %node = (<span class="string">"node10"</span> =&gt; <span class="string">"00:e0:ec:27:e9:f0"</span>,</span><br><span class="line"><span class="string">"node11"</span> =&gt; <span class="string">"e8:61:1f:11:e9:4b"</span>,</span><br><span class="line"><span class="string">"node12"</span> =&gt; <span class="string">"e8:61:1f:11:e8:3f"</span>,</span><br><span class="line"><span class="string">"node13"</span> =&gt; <span class="string">"e8:61:1f:1b:ec:80"</span>,</span><br><span class="line"><span class="string">"node14"</span> =&gt; <span class="string">"e8:61:1f:1b:ed:84"</span>,</span><br><span class="line"><span class="string">"node15"</span> =&gt; <span class="string">"e8:61:1f:1b:ec:9e"</span>,</span><br><span class="line"><span class="string">"node16"</span> =&gt; <span class="string">"e8:61:1f:1b:ed:0e"</span>,</span><br><span class="line"><span class="string">"node17"</span> =&gt; <span class="string">"e8:61:1f:1b:ed:b4"</span>,</span><br><span class="line"><span class="string">"node18"</span> =&gt; <span class="string">"e8:61:1f:1b:ec:94"</span>,</span><br><span class="line"><span class="string">"node19"</span> =&gt; <span class="string">"e8:61:1f:1b:ec:5a"</span>,</span><br><span class="line"><span class="string">"node20"</span> =&gt; <span class="string">"e8:61:1f:1b:eb:d0"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">my</span> %target;</span><br><span class="line"><span class="keyword">foreach</span> (@ARGV) &#123;</span><br><span class="line">    <span class="keyword">if</span> ($_ eq <span class="string">"all"</span>) &#123;</span><br><span class="line">        <span class="keyword">foreach</span> (@node) &#123; $target&#123;$_&#125; = <span class="number">1</span>; &#125;</span><br><span class="line">        <span class="keyword">last</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">elsif</span> (<span class="regexp">m/(\d+)-node(\d+)/</span>) &#123;</span><br><span class="line">        <span class="keyword">foreach</span> ($1 .. $2) &#123;</span><br><span class="line">            $target&#123;<span class="string">"node$_"</span>&#125; = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">exists</span> $node&#123;$_&#125;) &#123;</span><br><span class="line">            $target&#123;$_&#125; = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">print</span> STDERR <span class="string">"Warning: $_不是能控制的目标节点。\n"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">foreach</span> (<span class="keyword">sort</span> <span class="keyword">keys</span> %target) &#123;</span><br><span class="line">        &amp;kaiji($_);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">sub</span> <span class="title">kaiji</span> </span>&#123;</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"对主机 $_ 已经发送开机指令\n"</span>;</span><br><span class="line">        <span class="keyword">my</span> $cmdString = <span class="string">"/opt/sysoft/wol-0.7.1/bin/wol --host=10.10.10.255 $node&#123;$_&#125;"</span>;</span><br><span class="line">        <span class="keyword">system</span> $cmdString;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;服务器CentOS系统安装完毕后的基本配置&quot;&gt;&lt;a href=&quot;#服务器CentOS系统安装完毕后的基本配置&quot; class=&quot;headerlink&quot; title=&quot;服务器CentOS系统安装完毕后的基本配置&quot;&gt;&lt;/a&gt;服务器CentOS系统安装完毕后的基本配置&lt;/
      
    
    </summary>
    
      <category term="HPC" scheme="http://yoursite.com/categories/HPC/"/>
    
    
  </entry>
  
  <entry>
    <title>在Centos7部署SGE</title>
    <link href="http://yoursite.com/2019/05/15/%E5%9C%A8Centos7%E9%83%A8%E7%BD%B2SGE/"/>
    <id>http://yoursite.com/2019/05/15/在Centos7部署SGE/</id>
    <published>2019-05-15T14:41:00.000Z</published>
    <updated>2019-05-15T15:06:29.637Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设置防火墙，放行SGE所需端口"><a href="#设置防火墙，放行SGE所需端口" class="headerlink" title="设置防火墙，放行SGE所需端口"></a>设置防火墙，放行SGE所需端口</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># firewall-cmd --add-port=992/udp --permanent</span></span><br><span class="line"><span class="comment"># firewall-cmd --add-port=6444/tcp --permanent</span></span><br><span class="line"><span class="comment"># firewall-cmd --add-port=6445/tcp --permanent</span></span><br><span class="line"><span class="comment"># systemctl restart firewalld.service</span></span><br></pre></td></tr></table></figure><h1 id="从SGE官网下载最新版本的SGE源码包并进行编译和安装"><a href="#从SGE官网下载最新版本的SGE源码包并进行编译和安装" class="headerlink" title="从SGE官网下载最新版本的SGE源码包并进行编译和安装"></a>从SGE官网下载最新版本的SGE源码包并进行编译和安装</h1><h2 id="安装依赖的系统软件"><a href="#安装依赖的系统软件" class="headerlink" title="安装依赖的系统软件"></a>安装依赖的系统软件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install csh java-1.8.0-openjdk java-1.8.0-openjdk-devel gcc ant automake hwloc-devel openssl-devel libdb-devel pam-devel libXt-devel motif-devel ncurses-libs ncurses-devel</span></span><br><span class="line"><span class="comment"># yum install ant-junit junit javacc</span></span><br></pre></td></tr></table></figure><h2 id="下载SGE软件并进行编译"><a href="#下载SGE软件并进行编译" class="headerlink" title="下载SGE软件并进行编译"></a>下载SGE软件并进行编译</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://arc.liv.ac.uk/downloads/SGE/releases/8.1.9/sge-8.1.9.tar.gz -P ~/software/</span><br><span class="line">$ tar zxf ~/software/sge-8.1.9.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> sge-8.1.9/<span class="built_in">source</span></span><br><span class="line">$ ./scripts/bootstrap.sh</span><br><span class="line">$ ./aimk -no-herd -no-java</span><br></pre></td></tr></table></figure><h2 id="将编译好的SGE安装到指定的文件夹"><a href="#将编译好的SGE安装到指定的文件夹" class="headerlink" title="将编译好的SGE安装到指定的文件夹"></a>将编译好的SGE安装到指定的文件夹</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir /opt/sysoft/sge</span></span><br><span class="line"><span class="comment"># export SGE_ROOT=/opt/sysoft/sge</span></span><br><span class="line"><span class="comment"># ./scripts/distinst -local -allall -noexit</span></span><br><span class="line"><span class="comment"># cd ../../ &amp;&amp; rm sge-8.1.9/ -rf</span></span><br><span class="line"><span class="comment"># echo 'export SGE_ROOT=/opt/sysoft/sge' &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="comment"># echo 'PATH=$PATH:/opt/sysoft/sge/bin/:/opt/sysoft/sge/bin/lx-amd64/' &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="comment"># source ~/.bashrc</span></span><br></pre></td></tr></table></figure><h1 id="部署SGE前设置主机名"><a href="#部署SGE前设置主机名" class="headerlink" title="部署SGE前设置主机名"></a>部署SGE前设置主机名</h1><p>部署SGE前，需要设置好各个节点的主机名，需要修改3个文件。修改配置文件 /etc/sysconfig/network 内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=master</span><br></pre></td></tr></table></figure></p><p>修改配置文件 /proc/sys/kernel/hostname 内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure></p><p>修改配置文件 /etc/hosts 内容（注意删除掉127.0.0.1和localhost的行）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.30.1 master</span><br><span class="line">192.168.30.2 node1</span><br><span class="line">192.168.30.3 node2</span><br><span class="line">192.168.30.4 node3</span><br></pre></td></tr></table></figure></p><h1 id="在所有节点上部署SGE"><a href="#在所有节点上部署SGE" class="headerlink" title="在所有节点上部署SGE"></a>在所有节点上部署SGE</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$SGE_ROOT</span></span><br><span class="line">./install_qmaster</span><br></pre></td></tr></table></figure><p>运行部署命令后，会进入交互式界面。基本上全部都按Enter键使用默认设置即可。需要注意的事项是：</p><div class="note warning">            <ol><li>有一步骤是启动Grid Engine qmasster服务，可能会启动不了导致失败。原因是多次运行该命令进行部署，第一次会成功运行qmaster daemon，以后重新运行该程序进行部署则会失败。需要删除相应的sge_qmaster进程再进行部署。 </li><li>启动Grid Engine qmasster服务，要提供部署SGE的节点主机名信息，按y和Enter键使用一个文件来提供主机信息，输入文件路径/etc/hosts提供主机信息。</li></ol>          </div><p>只有先进行一个控制节点部署后，才能对各个计算节点进行部署。计算节点的部署比较简单，交互过程全部按Enter即可。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./install_execd</span><br></pre></td></tr></table></figure></p><h1 id="启动SGE软件"><a href="#启动SGE软件" class="headerlink" title="启动SGE软件"></a>启动SGE软件</h1><p>部署完毕后，若需要使用SGE软件，则执行如下命令载入SGE的环境变量信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> /opt/sysoft/sge/default/common/settings.sh</span><br></pre></td></tr></table></figure></p><p>或将该信息添加到~/.bashrc从而永久生效：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'source /opt/sysoft/sge/default/common/settings.sh'</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></p><p>启动SGE软件方法：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/sysoft/sge/default/common/sgemaster    <span class="comment"># 控制节点启动</span></span><br><span class="line">$ /opt/sysoft/sge/default/common/sgeexecd     <span class="comment"># 计算节点启动</span></span><br></pre></td></tr></table></figure></p><p>查看SGE软件运行日志文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Qmaster:      /opt/sysoft/sge/default/spool/qmaster/messages</span><br><span class="line">Exec daemon:  /opt/sysoft/sge/default/spool/&lt;hostname&gt;/messages</span><br></pre></td></tr></table></figure></p><h1 id="使用SGE软件"><a href="#使用SGE软件" class="headerlink" title="使用SGE软件"></a>使用SGE软件</h1><p>部署完毕SGE后，会生成一个默认主机用户组@allhosts，它包含所有的执行节点；生成一个默认的all.q队列名，它包含所有节点所有计算资源。默认的队列包含的计算资源是最大的。 通过使用命令qconf -mq queuename来对队列进行配置。修改hostlist来配置该队列可以使用执行主机；修改slots来配置各台执行主机可使用的线程数。从而对队列的计算资源进行设置。</p><p>使用qconf命令对SGE进行配置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">qconf -ae hostname</span><br><span class="line">    添加执行主机</span><br><span class="line">qconf -de hostname</span><br><span class="line">    删除执行主机</span><br><span class="line">qconf -sel</span><br><span class="line">    显示执行主机列表</span><br><span class="line"></span><br><span class="line">qconf -ah hostname</span><br><span class="line">    添加管理主机</span><br><span class="line">qconf -dh hostname</span><br><span class="line">    删除管理主机</span><br><span class="line">qconf -sh</span><br><span class="line">    显示管理主机列表</span><br><span class="line"></span><br><span class="line">qconf -as hostname</span><br><span class="line">    添加提交主机</span><br><span class="line">qconf -ds hostname</span><br><span class="line">    删除提交主机</span><br><span class="line">qconf -ss</span><br><span class="line">    显示提交主机列表</span><br><span class="line"></span><br><span class="line">qconf -ahgrp groupname</span><br><span class="line">    添加主机用户组</span><br><span class="line">qconf -mhgrp groupname</span><br><span class="line">    修改主机用户组</span><br><span class="line">qconf -shgrp groupname</span><br><span class="line">    显示主机用户组成员</span><br><span class="line">qconf -shgrpl</span><br><span class="line">    显示主机用户组列表</span><br><span class="line"></span><br><span class="line">qconf -aq queuename</span><br><span class="line">    添加集群队列</span><br><span class="line">qconf -dq queuename</span><br><span class="line">    删除集群队列</span><br><span class="line">qconf -mq queuename</span><br><span class="line">    修改集群队列配置</span><br><span class="line">qconf -sq queuename</span><br><span class="line">    显示集群队列配置</span><br><span class="line">qconf -sql</span><br><span class="line">    显示集群队列列表</span><br><span class="line"></span><br><span class="line">qconf -ap PE_name</span><br><span class="line">    添加并行化环境</span><br><span class="line">qconf -mp PE_name</span><br><span class="line">    修改并行化环境</span><br><span class="line">qconf -dp PE_name</span><br><span class="line">    删除并行化环境</span><br><span class="line">qconf -sp PE_name</span><br><span class="line">    显示并行化环境</span><br><span class="line">qconf -spl</span><br><span class="line">    显示并行化环境名称列表</span><br><span class="line"></span><br><span class="line">qstat -f</span><br><span class="line">    显示执行主机状态</span><br><span class="line">qstat -u user</span><br><span class="line">    查看用户的作业</span><br><span class="line">qhost</span><br><span class="line">    显示执行主机资源信息</span><br></pre></td></tr></table></figure></p><p>使用qsub提交作业<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">qsub简单示例：</span><br><span class="line">$ qsub -V -cwd -o stdout.txt -e stderr.txt run.sh</span><br><span class="line"></span><br><span class="line">其中run.sh中包含需要运行的程序，其内容示例为如下三行：</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#$ -S /bin/bash</span></span><br><span class="line">perl -e <span class="string">'print "abc\n";print STDERR "123\n";'</span></span><br><span class="line"></span><br><span class="line">qsub的常用参数：</span><br><span class="line">-V</span><br><span class="line">    将当前shell中的环境变量输出到本次提交的任务中。</span><br><span class="line">-cwd</span><br><span class="line">    在当前工作目录下运行程序。默认设置下，程序的运行目录是当前用户在其计算节点的家目录。</span><br><span class="line">-o</span><br><span class="line">    将标准输出添加到指定文件尾部。默认输出文件名是<span class="variable">$job_name</span>.o<span class="variable">$job_id</span>。</span><br><span class="line">-e</span><br><span class="line">    将标准错误输出添加到指定文件尾部。默认输出文件名是<span class="variable">$job_name</span>.e<span class="variable">$job_id</span>。</span><br><span class="line">-q</span><br><span class="line">    指定投递的队列，若不指定，则会尝试寻找最小负荷且有权限的队列开始任务。</span><br><span class="line">-S</span><br><span class="line">    指定运行run.sh中命令行的软件，默认是tcsh。推荐使用bash，设置该参数的值为 /bin/bash 即可，或者在run.sh文件首部添加一行<span class="comment">#$ -S /bin/bash。若不设置为bash，则会在标准输出中给出警告信息：Warning: no access to tty (Bad file descriptor)。</span></span><br><span class="line">-hold_jid</span><br><span class="line">    后接多个使用逗号分隔的job_id，表示只有在这些job运行完毕后，才开始运行此任务。</span><br><span class="line">-N</span><br><span class="line">    设置任务名称。默认的job name为qsub的输入文件名。</span><br><span class="line">-p</span><br><span class="line">    设置任务优先级。其参数值范围为 -1023 ~ 1024 ，该值越高，越优先运行。但是该参数设置为正数需要较高的权限，系统普通用户不能设置为正数。</span><br><span class="line">-j y|n</span><br><span class="line">    设置是否将标准输出和标准错误输出流合并到 -o 参数结果中。</span><br><span class="line">-pe</span><br><span class="line">    设置并行化环境。</span><br></pre></td></tr></table></figure></p><p>任务提交后的管理：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ qstat -f</span><br><span class="line">    查看当前用户在当前节点提交的所有任务，任务的状态有4中情况：qw，等待状态，刚提交任务的时候是该状态，一旦有计算资源了会马上运行；hqw，该任务依赖于其它正在运行的job，待前面的job执行完毕后再开始运行，qsub提交任务的时候使用-hold_jid参数则会是该状态；Eqw，投递任务出错；r，任务正在运行；s，被暂时挂起，往往是由于优先级更高的任务抢占了资源；dr，节点挂掉后，删除任务就会出现这个状态，只有节点重启后，任务才会消失。</span><br><span class="line"></span><br><span class="line">$ qstat -j jobID</span><br><span class="line">    按照任务id查看</span><br><span class="line"></span><br><span class="line">$ qstat -u user</span><br><span class="line">    按照用户查看</span><br><span class="line"></span><br><span class="line">$ qdel -j jobID</span><br><span class="line">    删除任务</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;设置防火墙，放行SGE所需端口&quot;&gt;&lt;a href=&quot;#设置防火墙，放行SGE所需端口&quot; class=&quot;headerlink&quot; title=&quot;设置防火墙，放行SGE所需端口&quot;&gt;&lt;/a&gt;设置防火墙，放行SGE所需端口&lt;/h1&gt;&lt;figure class=&quot;highli
      
    
    </summary>
    
      <category term="HPC" scheme="http://yoursite.com/categories/HPC/"/>
    
    
  </entry>
  
  <entry>
    <title>cobbler批量部署系统</title>
    <link href="http://yoursite.com/2019/05/12/cobbler%E6%89%B9%E9%87%8F%E9%83%A8%E7%BD%B2%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2019/05/12/cobbler批量部署系统/</id>
    <published>2019-05-12T14:24:53.000Z</published>
    <updated>2019-05-12T14:34:07.906Z</updated>
    
    <content type="html"><![CDATA[<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler ~]<span class="comment"># sed -i s#SELINUX=enforcing#SELINUX=disabled# /etc/selinux/config</span></span><br><span class="line">[root@cobbler ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[root@cobbler ~]<span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure><h2 id="修改网卡信息"><a href="#修改网卡信息" class="headerlink" title="修改网卡信息"></a>修改网卡信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler ~]<span class="comment"># nmcli connection modify eth0 ipv4.addresses 192.168.221.10/24 ipv4.gateway 192.168.221.2 ipv4.dns 192.168.221.2 ipv4.method manual connection.autoconnect yes connection.interface-name eth0</span></span><br></pre></td></tr></table></figure><h2 id="安装cobbler相关程序包"><a href="#安装cobbler相关程序包" class="headerlink" title="安装cobbler相关程序包"></a>安装cobbler相关程序包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler ~]<span class="comment"># yum install cobbler cobbler-web pykickstart httpd dhcp tftp-server -y</span></span><br></pre></td></tr></table></figure><h2 id="启动cobbler和httpd服务"><a href="#启动cobbler和httpd服务" class="headerlink" title="启动cobbler和httpd服务"></a>启动cobbler和httpd服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler ~]<span class="comment"># systemctl start httpd cobblerd</span></span><br><span class="line">[root@cobbler ~]<span class="comment"># systemctl enable httpd cobblerd</span></span><br></pre></td></tr></table></figure><h2 id="检查cobbler配置"><a href="#检查cobbler配置" class="headerlink" title="检查cobbler配置"></a>检查cobbler配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler ~]<span class="comment"># cobbler check</span></span><br><span class="line">The following are potential configuration items that you may want to fix:</span><br><span class="line"> </span><br><span class="line">1 : The <span class="string">'server'</span> field <span class="keyword">in</span> /etc/cobbler/settings must be <span class="built_in">set</span> to something other than localhost, or kickstarting features will not work.  This should be a resolvable hos</span><br><span class="line">tname or IP <span class="keyword">for</span> the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the <span class="string">'next_server'</span> field <span class="keyword">in</span> /etc/cobbler/settings must be <span class="built_in">set</span> to something other than 127.0.0.1, and should match the IP of the boot serve</span><br><span class="line">r on the PXE network.3 : change <span class="string">'disable'</span> to <span class="string">'no'</span> <span class="keyword">in</span> /etc/xinetd.d/tftp</span><br><span class="line">4 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run <span class="string">'cobbler get-loaders'</span> to download them, or, <span class="keyword">if</span> you only want to handle x86/x86_64 </span><br><span class="line">netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely.  Files <span class="keyword">in</span> this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The <span class="string">'cobbler get-loaders'</span> <span class="built_in">command</span> is the easiest way to resolve these requirements.5 : <span class="built_in">enable</span> and start rsyncd.service with systemctl</span><br><span class="line">6 : debmirror package is not installed, it will be required to manage debian deployments and repositories</span><br><span class="line">7 : The default password used by the sample templates <span class="keyword">for</span> newly installed machines (default_password_crypted <span class="keyword">in</span> /etc/cobbler/settings) is still <span class="built_in">set</span> to <span class="string">'cobbler'</span> and sh</span><br><span class="line">ould be changed, try: <span class="string">"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'"</span> to generate new one</span><br><span class="line">8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them</span><br><span class="line"> </span><br><span class="line">Restart cobblerd and <span class="keyword">then</span> run <span class="string">'cobbler sync'</span> to apply changes.</span><br></pre></td></tr></table></figure><h1 id="Cobbler相关问题"><a href="#Cobbler相关问题" class="headerlink" title="Cobbler相关问题"></a>Cobbler相关问题</h1><h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相应的IP地址或主机名<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># cp /etc/cobbler/settings&#123;,.ori&#125;</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i 's/server: 127.0.0.1/server: 192.168.221.10/' /etc/cobbler/settings</span></span><br></pre></td></tr></table></figure></p><h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机相应的IP地址<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i 's/next_server: 127.0.0.1/next_server: 192.168.221.10/' /etc/cobbler/settings</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># grep "server: 192.168.221.10" /etc/cobbler/settings</span></span><br><span class="line">next_server: 192.168.221.10</span><br><span class="line">server: 192.168.221.10</span><br></pre></td></tr></table></figure></p><h2 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h2><p>修改/etc/xinetd.d/tftp文件中的disable参数修改为 disable = no<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># cp /etc/xinetd.d/tftp&#123;,.bak&#125;</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i 's/disable.*= yes/disable                 = no/g' /etc/xinetd.d/tftp</span></span><br></pre></td></tr></table></figure></p><h2 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h2><p>执行 cobbler get-loaders 命令即可；否则，需要安装syslinux程序包，而后复制/usr/share/syslinux/{pxelinux.0,memu.c32}等文件至/var/lib/cobbler/loaders/目录中<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># cobbler get-loaders</span></span><br><span class="line">task started: 2018-08-30_170803_get_loaders</span><br><span class="line">task started (id=Download Bootloader Content, time=Thu Aug 30 17:08:03 2018)</span><br><span class="line">downloading https://cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.elilo to /var/lib/cobbler/loaders/COPYING.elilo</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.yaboot to /var/lib/cobbler/loaders/COPYING.yaboot</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.syslinux to /var/lib/cobbler/loaders/COPYING.syslinux</span><br><span class="line">downloading https://cobbler.github.io/loaders/elilo-3.8-ia64.efi to /var/lib/cobbler/loaders/elilo-ia64.efi</span><br><span class="line">downloading https://cobbler.github.io/loaders/yaboot-1.3.17 to /var/lib/cobbler/loaders/yaboot</span><br><span class="line">downloading https://cobbler.github.io/loaders/pxelinux.0-3.86 to /var/lib/cobbler/loaders/pxelinux.0</span><br><span class="line">downloading https://cobbler.github.io/loaders/menu.c32-3.86 to /var/lib/cobbler/loaders/menu.c32</span><br><span class="line">downloading https://cobbler.github.io/loaders/grub-0.97-x86.efi to /var/lib/cobbler/loaders/grub-x86.efi</span><br><span class="line">downloading https://cobbler.github.io/loaders/grub-0.97-x86_64.efi to /var/lib/cobbler/loaders/grub-x86_64.efi</span><br><span class="line">*** TASK COMPLETE ***</span><br></pre></td></tr></table></figure></p><h2 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># systemctl start rsyncd</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># systemctl enable rsyncd</span></span><br><span class="line">问题6</span><br></pre></td></tr></table></figure><h2 id="问题6"><a href="#问题6" class="headerlink" title="问题6"></a>问题6</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># yum install debmirror -y</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># vi /etc/debmirror.conf</span></span><br><span class="line"><span class="comment">#@dists="sid";</span></span><br><span class="line"><span class="comment">#@arches="i386";</span></span><br></pre></td></tr></table></figure><h2 id="问题7"><a href="#问题7" class="headerlink" title="问题7"></a>问题7</h2><p>生成密码来取代默认的密码，前者为干扰码，后者为真正的密码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># openssl passwd -1 -salt 'jay.cheng' '123456'</span></span><br><span class="line"><span class="variable">$1</span><span class="variable">$jay</span>.chen<span class="variable">$1Ktf4J</span>.R.RsFfY3mz63Ro/</span><br><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i s/'default_password_crypted:.*'/'default_password_crypted: "$1$jay.chen$1Ktf4J.R.RsFfY3mz63Ro\/"'/g /etc/cobbler/settings</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># grep -n default_pass /etc/cobbler/settings</span></span><br><span class="line">101:default_password_crypted: <span class="string">"<span class="variable">$1</span><span class="variable">$jay</span>.chen<span class="variable">$1Ktf4J</span>.R.RsFfY3mz63Ro/"</span></span><br></pre></td></tr></table></figure></p><h2 id="问题8"><a href="#问题8" class="headerlink" title="问题8"></a>问题8</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># yum install -y fence-agents</span></span><br></pre></td></tr></table></figure><h2 id="由cobbler管理DHCP和防止循环装系统"><a href="#由cobbler管理DHCP和防止循环装系统" class="headerlink" title="由cobbler管理DHCP和防止循环装系统"></a>由cobbler管理DHCP和防止循环装系统</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i 's/manage_dhcp: 0/manage_dhcp: 1/g' /etc/cobbler/settings</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># grep -n manage_dhcp /etc/cobbler/settings</span></span><br><span class="line">242:manage_dhcp: 1</span><br><span class="line">269:<span class="comment"># if using cobbler with manage_dhcp, put the IP address</span></span><br><span class="line">355:<span class="comment"># Note that if manage_dhcp and manage_dns are disabled, the respective</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># sed -i 's/pxe_just_once: 0/pxe_just_once: 1/' /etc/cobbler/settings</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># grep -n pxe_just_once /etc/cobbler/settings</span></span><br><span class="line">292:pxe_just_once: 1</span><br></pre></td></tr></table></figure><h2 id="重启cobbler服务后，再次运行检查配置命令"><a href="#重启cobbler服务后，再次运行检查配置命令" class="headerlink" title="重启cobbler服务后，再次运行检查配置命令"></a>重启cobbler服务后，再次运行检查配置命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@cobbler cobbler]<span class="comment"># systemctl restart cobblerd.service</span></span><br><span class="line">[root@cobbler cobbler]<span class="comment"># cobbler check</span></span><br><span class="line">No configuration problems found.  All systems go.</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h1&gt;&lt;h2 id=&quot;关闭防火墙和selinux&quot;&gt;&lt;a href=&quot;#关闭防火墙和selinux&quot; class=&quot;headerlink
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>kubeadm HA部署方案</title>
    <link href="http://yoursite.com/2019/05/10/kubeadm-HA%E6%96%B9%E6%A1%88/"/>
    <id>http://yoursite.com/2019/05/10/kubeadm-HA方案/</id>
    <published>2019-05-10T09:31:00.000Z</published>
    <updated>2019-05-12T12:09:31.818Z</updated>
    
    <content type="html"><![CDATA[<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="关闭防火墙和selinux"><a href="#关闭防火墙和selinux" class="headerlink" title="关闭防火墙和selinux"></a>关闭防火墙和selinux</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> --now firewalld NetworkManager</span><br><span class="line">setenforce 0</span><br><span class="line">sed -ri <span class="string">'/^[^#]*SELINUX=/s#=.+$#=disabled#'</span> /etc/selinux/config</span><br></pre></td></tr></table></figure><h2 id="关闭dnsmasq"><a href="#关闭dnsmasq" class="headerlink" title="关闭dnsmasq"></a>关闭dnsmasq</h2><p>linux系统开启了dnsmasq后(如 GUI 环境)，将系统DNS Server设置为127.0.0.1，这会导致docker容器无法解析域名，需要关闭它。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> --now dnsmasq</span><br></pre></td></tr></table></figure></p><h2 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h2><p>Kubernetes v1.8+要求关闭系统Swap,若不关闭则需要修改kubelet设定参数( –fail-swap-on 设置为 false 来忽略 swap on),在<code>所有机器</code>使用以下指令关闭swap并注释掉“/etc/fstab”中swap的行。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">sed -ri <span class="string">'/^[^#]*swap/s@^@#@'</span> /etc/fstab</span><br></pre></td></tr></table></figure></p><h2 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h2><p>因为目前市面上包管理下内核版本会很低,安装docker后无论centos还是ubuntu会有如下bug，4.15的内核依然存在<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel:unregister_netdevice: waiting <span class="keyword">for</span> lo to become free. Usage count = 1</span><br></pre></td></tr></table></figure></p><p>perl是内核的依赖包，需要安装它<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ ! -f /usr/bin/perl ] &amp;&amp; yum install perl -y</span><br></pre></td></tr></table></figure></p><ul><li><p>升级内核需要使用 elrepo 的yum 源，首先我们导入 elrepo 的 key并安装 elrepo 源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure></li><li><p>查看可用的内核（在yum的ELRepo源中，mainline为最新版本的内核，安装kernel）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available  --showduplicates</span><br></pre></td></tr></table></figure></li><li><p>自选版本内核安装方法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> Kernel_Version=4.18.9-1</span><br><span class="line">wget  http://mirror.rc.usf.edu/compute_lock/elrepo/kernel/el7/x86_64/RPMS/kernel-ml&#123;,-devel&#125;-<span class="variable">$&#123;Kernel_Version&#125;</span>.el7.elrepo.x86_64.rpm</span><br><span class="line">yum localinstall -y kernel-ml*</span><br></pre></td></tr></table></figure></li><li><p>最新版本安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available  --showduplicates | grep -Po <span class="string">'^kernel-ml.x86_64\s+\K\S+(?=.el7)'</span></span><br><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=elrepo-kernel install -y kernel-ml&#123;,-devel&#125;</span><br></pre></td></tr></table></figure><ul><li><p>修改内核启动顺序,默认启动的顺序应该为1,升级以后内核是往前面插入,为0（如果每次启动时需要手动选择哪个内核,该步骤可以省略）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grub2-set-default 0 &amp;&amp; grub2-mkconfig -o /etc/grub2.cfg</span><br></pre></td></tr></table></figure></li><li><p>使用下面命令看看确认下是否启动默认内核指向上面安装的内核</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grubby --default-kernel</span><br></pre></td></tr></table></figure></li><li><p>docker官方的内核检查脚本建议<code>(RHEL7/CentOS7: User namespaces disabled; add &#39;user_namespace.enable=1&#39; to boot command line)</code>,使用下面命令开启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grubby --args=<span class="string">"user_namespace.enable=1"</span> --update-kernel=<span class="string">"<span class="variable">$(grubby --default-kernel)</span>"</span></span><br></pre></td></tr></table></figure></li><li><p>重启加载新内核</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="安装ipvs"><a href="#安装ipvs" class="headerlink" title="安装ipvs"></a>安装ipvs</h2><p>ipvs性能甩iptables几条街并且排错更直观<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br></pre></td></tr></table></figure></p><p>启用IPVS相关内核module<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">module=(ip_vs</span><br><span class="line">        ip_vs_rr</span><br><span class="line">        ip_vs_wrr</span><br><span class="line">        ip_vs_sh</span><br><span class="line">        nf_conntrack)</span><br><span class="line"><span class="keyword">for</span> kernel_module <span class="keyword">in</span> <span class="variable">$&#123;module[@]&#125;</span>;<span class="keyword">do</span></span><br><span class="line">    /sbin/modinfo -F filename <span class="variable">$kernel_module</span> |&amp; grep -qv ERROR &amp;&amp; <span class="built_in">echo</span> <span class="variable">$kernel_module</span> &gt;&gt; /etc/modules-load.d/ipvs.conf || :</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">systemctl <span class="built_in">enable</span> --now systemd-modules-load.service</span><br></pre></td></tr></table></figure></p><p>表示成功加载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep ip_vs</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 151552  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          143360  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure></p><h2 id="内核参数调整"><a href="#内核参数调整" class="headerlink" title="内核参数调整"></a>内核参数调整</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line"><span class="comment"># https://github.com/moby/moby/issues/31208 </span></span><br><span class="line"><span class="comment"># ipvsadm -l --timout</span></span><br><span class="line"><span class="comment"># 修复ipvs模式下长连接timeout问题 小于900即可</span></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 10</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 1</span><br><span class="line">net.ipv4.neigh.default.gc_stale_time = 120</span><br><span class="line">net.ipv4.conf.all.rp_filter = 0</span><br><span class="line">net.ipv4.conf.default.rp_filter = 0</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 5000</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 1024</span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line"><span class="comment"># 要求iptables不对bridge的数据进行处理</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.netfilter.nf_conntrack_max = 2310720</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">fs.file-max = 52706963</span><br><span class="line">fs.nr_open = 52706963</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># sysctl --system</span></span><br></pre></td></tr></table></figure><h2 id="安装Docker-CE"><a href="#安装Docker-CE" class="headerlink" title="安装Docker CE"></a>安装Docker CE</h2><p>在官方查看K8s支持的docker版本 <a href="https://github.com/kubernetes/kubernetes" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes</a> 里进对应版本的changelog里搜“The list of validated docker versions remain”。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget -P /etc/yum.repos.d/ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line">yum -y install docker-ce-18.06.3.ce-3.el7</span><br></pre></td></tr></table></figure></p><p>配置加速源并配置docker的启动参数使用systemd，使用systemd是官方的建议,详见<a href="https://kubernetes.io/docs/setup/cri/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/cri/</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/docker/</span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">    <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"100m"</span>,</span><br><span class="line">    <span class="string">"max-file"</span>: <span class="string">"3"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"live-restore"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"max-concurrent-downloads"</span>: 10,</span><br><span class="line">    <span class="string">"max-concurrent-uploads"</span>: 10,</span><br><span class="line">    <span class="string">"registry-mirrors"</span>: [<span class="string">"https://ib9xyhrv.mirror.aliyuncs.com"</span>],</span><br><span class="line">    <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line">    <span class="string">"storage-opts"</span>: [</span><br><span class="line">    <span class="string">"overlay2.override_kernel_check=true"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p><p>设置docker开机启动，CentOS安装完成后docker需要手动设置docker命令补全<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl restart docker</span><br><span class="line">yum install -y epel-release bash-completion &amp;&amp; cp /usr/share/bash-completion/completions/docker /etc/bash_completion.d/</span><br></pre></td></tr></table></figure></p><h1 id="部署Nginx-local-Proxy"><a href="#部署Nginx-local-Proxy" class="headerlink" title="部署Nginx local Proxy"></a>部署Nginx local Proxy</h1><p>本地nginx代理的主要主要是代理访问所有的master节点。</p><p>nginx.conf 配置如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/nginx</span><br><span class="line">cat &gt; /etc/nginx/nginx.conf &lt;&lt; EOF</span><br><span class="line">worker_processes auto;</span><br><span class="line">user root;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  20240;</span><br><span class="line">    use epoll;</span><br><span class="line">&#125;</span><br><span class="line">error_log /var/<span class="built_in">log</span>/nginx_error.log info;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">    upstream kube-servers &#123;</span><br><span class="line">        <span class="built_in">hash</span> <span class="variable">$remote_addr</span> consistent;</span><br><span class="line">        server k8s-m1.local:6443 weight=5 max_fails=1 fail_timeout=10s;</span><br><span class="line">        server k8s-m2.local:6443 weight=5 max_fails=1 fail_timeout=10s;</span><br><span class="line">        server k8s-m3.local:6443 weight=5 max_fails=1 fail_timeout=10s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 8443;</span><br><span class="line">        proxy_connect_timeout 1s;</span><br><span class="line">        proxy_timeout 3s;</span><br><span class="line">        proxy_pass kube-servers;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p><p>启动Nginx<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run --restart=always \</span><br><span class="line">-v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf \</span><br><span class="line">--name kube_server_proxy \</span><br><span class="line">--net host \</span><br><span class="line">-it \</span><br><span class="line">-d \</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure></p><h1 id="部署etcd集群"><a href="#部署etcd集群" class="headerlink" title="部署etcd集群"></a>部署etcd集群</h1><p>关于ETCD要不要使用TLS？<br>首先TLS的目的是为了鉴权为了防止别人任意的连接上你的etcd集群。其实意思就是说如果你要放到公网上的ETCD集群，并开放端口，我建议你一定要用TLS。<br>如果你的ETCD集群跑在一个内网环境比如（VPC环境），而且你也不会开放ETCD端口，你的ETCD跑在防火墙之后，一个安全的局域网中，那么你用不用TLS，都行。<br><div class="note warning">            <ul><li>–auto-compaction-retention：由于ETCD数据存储多版本数据，随着写入的主键增加历史版本需要定时清理，默认的历史数据是不会清理的，数据达到2G就不能写入，必须要清理压缩历史数据才能继续写入;所以根据业务需求，在上生产环境之前就提前确定，历史数据多长时间压缩一次;推荐一小时压缩一次数据这样可以极大的保证集群稳定，减少内存和磁盘占用。</li><li>–max-request-bytes：etcd Raft消息最大字节数，ETCD默认该值为1.5M; 但是很多业务场景发现同步数据的时候1.5M完全没法满足要求，所以提前确定初始值很重要;由于1.5M导致我们线上的业务无法写入元数据的问题，我们紧急升级之后把该值修改为默认32M，但是官方推荐的是10M，大家可以根据业务情况自己调整。</li><li>–quota-backend-bytes：ETCD db数据大小，默认是2G，当数据达到2G的时候就不允许写入，必须对历史数据进行压缩才能继续写入;参加1里面说的，我们启动的时候就应该提前确定大小，官方推荐是8G，这里我们也使用8G的配置。</li></ul>          </div></p><h2 id="docker安装集群"><a href="#docker安装集群" class="headerlink" title="docker安装集群"></a>docker安装集群</h2><p>在k8s-m1上运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/etcd</span><br><span class="line">docker run --restart=always --net host -it --name etcd1 -d \</span><br><span class="line">-v /var/etcd:/var/etcd \</span><br><span class="line">-v /etc/localtime:/etc/localtime \</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.2.24 \</span><br><span class="line">etcd --name etcd-s1 \</span><br><span class="line">--auto-compaction-retention=1 --max-request-bytes=33554432 --quota-backend-bytes=8589934592 \</span><br><span class="line">--data-dir=/var/etcd/etcd-data \</span><br><span class="line">--listen-client-urls http://0.0.0.0:2379 \</span><br><span class="line">--listen-peer-urls http://0.0.0.0:2380 \</span><br><span class="line">--initial-advertise-peer-urls http://k8s-m1.local:2380 \</span><br><span class="line">--advertise-client-urls http://k8s-m1.local:2379,http://k8s-m1.local:2380 \</span><br><span class="line">-initial-cluster-token etcd-cluster \</span><br><span class="line">-initial-cluster <span class="string">"etcd-s1=http://k8s-m1.local:2380,etcd-s2=http://k8s-m2.local:2380,etcd-s3=http://k8s-m3.local:2380"</span> \</span><br><span class="line">-initial-cluster-state new</span><br></pre></td></tr></table></figure><p>在k8s-m2上运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/etcd</span><br><span class="line">docker run --restart=always --net host -it --name etcd2 -d \</span><br><span class="line">-v /var/etcd:/var/etcd \</span><br><span class="line">-v /etc/localtime:/etc/localtime \</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.2.24 \</span><br><span class="line">etcd --name etcd-s2 \</span><br><span class="line">--auto-compaction-retention=1 --max-request-bytes=33554432 --quota-backend-bytes=8589934592 \</span><br><span class="line">--data-dir=/var/etcd/etcd-data \</span><br><span class="line">--listen-client-urls http://0.0.0.0:2379 \</span><br><span class="line">--listen-peer-urls http://0.0.0.0:2380 \</span><br><span class="line">--initial-advertise-peer-urls http://k8s-m2.local:2380 \</span><br><span class="line">--advertise-client-urls http://k8s-m2.local:2379,http://k8s-m2.local:2380 \</span><br><span class="line">-initial-cluster-token etcd-cluster \</span><br><span class="line">-initial-cluster <span class="string">"etcd-s1=http://k8s-m1.local:2380,etcd-s2=http://k8s-m2.local:2380,etcd-s3=http://k8s-m3.local:2380"</span> \</span><br><span class="line">-initial-cluster-state new</span><br></pre></td></tr></table></figure><p>在k8s-m3上运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/etcd</span><br><span class="line">docker run --restart=always --net host -it --name etcd3 -d \</span><br><span class="line">-v /var/etcd:/var/etcd \</span><br><span class="line">-v /etc/localtime:/etc/localtime \</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.2.24 \</span><br><span class="line">etcd --name etcd-s3 \</span><br><span class="line">--auto-compaction-retention=1 --max-request-bytes=33554432 --quota-backend-bytes=8589934592 \</span><br><span class="line">--data-dir=/var/etcd/etcd-data \</span><br><span class="line">--listen-client-urls http://0.0.0.0:2379 \</span><br><span class="line">--listen-peer-urls http://0.0.0.0:2380 \</span><br><span class="line">--initial-advertise-peer-urls http://k8s-m3.local:2380 \</span><br><span class="line">--advertise-client-urls http://k8s-m3.local:2379,http://k8s-m3.local:2380 \</span><br><span class="line">-initial-cluster-token etcd-cluster \</span><br><span class="line">-initial-cluster <span class="string">"etcd-s1=http://k8s-m1.local:2380,etcd-s2=http://k8s-m2.local:2380,etcd-s3=http://k8s-m3.local:2380"</span> \</span><br><span class="line">-initial-cluster-state new</span><br></pre></td></tr></table></figure><h2 id="检查etcd集群"><a href="#检查etcd集群" class="headerlink" title="检查etcd集群"></a>检查etcd集群</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.2.24/etcd-v3.2.24-linux-amd64.tar.gz</span><br><span class="line">cp etcd-v3.2.24-linux-amd64/etcdctl /usr/bin</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl member list</span><br><span class="line">1ea7c4c273506571, started, etcd-s2, http://k8s-m2.local:2380, http://k8s-m2.local:2379,http://k8s-m2.local:2380</span><br><span class="line">3a6836afd0d18e55, started, etcd-s1, http://k8s-m1.local:2380, http://k8s-m1.local:2379,http://k8s-m1.local:2380</span><br><span class="line">e38ee06f8fe64ee0, started, etcd-s3, http://k8s-m3.local:2380, http://k8s-m3.local:2379,http://k8s-m3.local:2380</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=2 etcdctl cluster-health</span><br><span class="line">member 1ea7c4c273506571 is healthy: got healthy result from http://k8s-m2.local:2379</span><br><span class="line">member 3a6836afd0d18e55 is healthy: got healthy result from http://k8s-m1.local:2379</span><br><span class="line">member e38ee06f8fe64ee0 is healthy: got healthy result from http://k8s-m3.local:2379</span><br><span class="line">cluste is healthy</span><br></pre></td></tr></table></figure><h1 id="部署Master"><a href="#部署Master" class="headerlink" title="部署Master"></a>部署Master</h1><h2 id="重新编译源码"><a href="#重新编译源码" class="headerlink" title="重新编译源码"></a>重新编译源码</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull registry.cn-hangzhou.aliyuncs.com/buildtools/kubernetes-build:v1.0</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/kubernetes/kubernetes</span><br><span class="line">$ docker run --rm -v /opt/required/kubernetes-1.13.5:/go/src/k8s.io/kubernetes -it registry.cn-hangzhou.aliyuncs.com/buildtools/kubernetes-build:v1.0 bash</span><br><span class="line">root@cdf870129efb:/go<span class="comment"># cd /go/src/k8s.io/kubernetes</span></span><br><span class="line">root@cdf870129efb:/go<span class="comment"># vim vendor/k8s.io/client-go/util/cert/cert.go</span></span><br><span class="line">修改NotAfter，NotAfter:  validFrom.Add(duration365d * 99)</span><br><span class="line">root@cdf870129efb:/go<span class="comment"># make all WHAT=cmd/kubeadm GOFLAGS=-v</span></span><br><span class="line">编译后的产物在：_output/<span class="built_in">local</span>/bin/linux/amd64</span><br></pre></td></tr></table></figure><h2 id="设置国内镜像源"><a href="#设置国内镜像源" class="headerlink" title="设置国内镜像源"></a>设置国内镜像源</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">yum install -y kubelet-1.13.5 kubeadm-1.13.5 kubectl-1.13.5</span><br><span class="line">cp _output/<span class="built_in">local</span>/bin/linux/amd64/kubeadm /usr/bin/kubeadm（如果手动编译的kubeadm，需要替换）</span><br></pre></td></tr></table></figure><h2 id="设置kubelet的pause镜像"><a href="#设置kubelet的pause镜像" class="headerlink" title="设置kubelet的pause镜像"></a>设置kubelet的pause镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/default/kubelet &lt;&lt; EOF</span><br><span class="line">KUBELET_EXTRA_ARGS=<span class="string">"--cgroup-driver=cgroupfs --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1"</span></span><br><span class="line">EOF</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure><h2 id="kubeadm-config-yaml"><a href="#kubeadm-config-yaml" class="headerlink" title="kubeadm-config.yaml"></a>kubeadm-config.yaml</h2><ul><li><p>查看 ClusterConfiguration 的默认配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config <span class="built_in">print</span>-default --api-objects ClusterConfiguration</span><br></pre></td></tr></table></figure></li><li><p>查看 KubeProxyConfiguration 的默认配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config <span class="built_in">print</span>-default --api-objects KubeProxyConfiguration</span><br></pre></td></tr></table></figure></li><li><p>查看 KubeletConfiguration 的默认配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config <span class="built_in">print</span>-default --api-objects KubeletConfiguration</span><br></pre></td></tr></table></figure></li><li><p>kubeadm-config.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm init --config=</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.13.5</span></span><br><span class="line"><span class="comment">#useHyperKubeImage: true</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"><span class="attr">  certSANs:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"server.k8s.local"</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line"></span><br><span class="line"><span class="attr">controlPlaneEndpoint:</span> <span class="string">server.k8s.local:8443</span></span><br><span class="line"></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line"><span class="attr"> external:</span></span><br><span class="line"><span class="attr">   endpoints:</span></span><br><span class="line"><span class="attr">     - http:</span><span class="string">//k8s-m1.local:2379</span></span><br><span class="line"><span class="attr">     - http:</span><span class="string">//k8s-m2.local:2379</span></span><br><span class="line"><span class="attr">     - http:</span><span class="string">//k8s-m3.local:2379</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeProxyConfiguration</span></span><br><span class="line"><span class="attr">mode:</span> <span class="string">ipvs</span></span><br><span class="line"><span class="attr">ipvs:</span></span><br><span class="line"><span class="attr">  scheduler:</span> <span class="string">rr</span></span><br><span class="line"><span class="attr">  syncPeriod:</span> <span class="number">10</span><span class="string">s</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="预先拉取镜像"><a href="#预先拉取镜像" class="headerlink" title="预先拉取镜像"></a>预先拉取镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images pull --config kubeadm-config.yaml</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.13.5</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.13.5</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.13.5</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.13.5</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6</span><br></pre></td></tr></table></figure><h2 id="初始化Master"><a href="#初始化Master" class="headerlink" title="初始化Master"></a>初始化Master</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config kubeadm-config.yaml</span><br><span class="line">[init] Using Kubernetes version: v1.13.5</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] External etcd mode: Skipping etcd/ca certificate authority generation</span><br><span class="line">[certs] External etcd mode: Skipping apiserver-etcd-client certificate authority generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/healthcheck-client certificate authority generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/server certificate authority generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/peer certificate authority generation</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [k8s-m1.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local server.k8s.local server.k8s.local] and IPs [10.96.0.1 10.105.26.201]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 26.004617 seconds</span><br><span class="line">[uploadconfig] storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">"kubelet-config-1.13"</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[patchnode] Uploading the CRI Socket information <span class="string">"/var/run/dockershim.sock"</span> to the Node API object <span class="string">"k8s-m1.local"</span> as an annotation</span><br><span class="line">[mark-control-plane] Marking the node k8s-m1.local as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node k8s-m1.local as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 7ub1sg.pjcsar2pv8pdz60u</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstraptoken] creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join server.k8s.local:8443 --token 7ub1sg.pjcsar2pv8pdz60u --discovery-token-ca-cert-hash sha256:13c7d2e9c6c4298a6433fd73dc73403aaf7a99309ac1ad786bf668ffab8c76f8</span><br></pre></td></tr></table></figure><h2 id="验证证书有效期"><a href="#验证证书有效期" class="headerlink" title="验证证书有效期"></a>验证证书有效期</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># openssl x509 -in /etc/kubernetes/pki/ca.crt -noout -text</span></span><br><span class="line">Certificate:</span><br><span class="line">    Data:</span><br><span class="line">        Version: 3 (0x2)</span><br><span class="line">        Serial Number: 0 (0x0)</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">        Issuer: CN=kubernetes</span><br><span class="line">        Validity</span><br><span class="line">            Not Before: Apr 18 07:42:25 2019 GMT</span><br><span class="line">            Not After : Mar 25 07:42:25 2118 GMT</span><br><span class="line"><span class="comment"># openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -text</span></span><br><span class="line"><span class="comment"># openssl x509 -in /etc/kubernetes/pki/apiserver-kubelet-client.crt -noout -text</span></span><br><span class="line"><span class="comment"># openssl x509 -in /etc/kubernetes/pki/front-proxy-ca.crt -noout -text</span></span><br></pre></td></tr></table></figure><h1 id="部署高可用Master"><a href="#部署高可用Master" class="headerlink" title="部署高可用Master"></a>部署高可用Master</h1><p>分发证书到其他master节点<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br><span class="line">USER=root</span><br><span class="line">CONTROL_PLANE_IPS=<span class="string">"k8s-m2.local k8s-m3.local"</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$&#123;CONTROL_PLANE_IPS&#125;</span>; <span class="keyword">do</span></span><br><span class="line">    scp /etc/kubernetes/pki/ca.crt <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/ca.key <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.key <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.pub <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.crt <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.key <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/admin.conf <span class="string">"<span class="variable">$&#123;USER&#125;</span>"</span>@<span class="variable">$host</span>:/etc/kubernetes/</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><h2 id="加入Master节点（k8s-m2，k8s-m3）"><a href="#加入Master节点（k8s-m2，k8s-m3）" class="headerlink" title="加入Master节点（k8s-m2，k8s-m3）"></a>加入Master节点（k8s-m2，k8s-m3）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm join server.k8s.local:8443 --token 7ub1sg.pjcsar2pv8pdz60u --discovery-token-ca-cert-hash sha256:13c7d2e9c6c4298a6433fd73dc73403aaf7a99309ac1ad786bf668ffab8c76f8 --experimental-control-plane</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[discovery] Trying to connect to API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[discovery] Created cluster-info discovery client, requesting info from <span class="string">"https://server.k8s.local:8443"</span></span><br><span class="line">[discovery] Requesting info from <span class="string">"https://server.k8s.local:8443"</span> again to validate TLS against the pinned public key</span><br><span class="line">[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[discovery] Successfully established connection with API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[join] Reading configuration from the cluster...</span><br><span class="line">[join] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[join] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [k8s-m2.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local server.k8s.local server.k8s.local] and IPs [10.96.0.1 10.105.26.202]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] valid certificates and keys now exist <span class="keyword">in</span> <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Using the existing <span class="string">"sa"</span> key</span><br><span class="line">[endpoint] WARNING: port specified <span class="keyword">in</span> controlPlaneEndpoint overrides bindPort <span class="keyword">in</span> the controlplane address</span><br><span class="line">[kubeconfig] Using existing up-to-date kubeconfig file: <span class="string">"/etc/kubernetes/admin.conf"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[kubelet] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.13"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[tlsbootstrap] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[patchnode] Uploading the CRI Socket information <span class="string">"/var/run/dockershim.sock"</span> to the Node API object <span class="string">"k8s-m2.local"</span> as an annotation</span><br><span class="line">[uploadconfig] storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[mark-control-plane] Marking the node k8s-m2.local as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node k8s-m2.local as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Master label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> to see this node join the cluster.</span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><ul><li><p>设置kubeconfig</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure></li><li><p>查看node状态，status是NotReady，因为网络addons没启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME           STATUS     ROLES    AGE     VERSION</span><br><span class="line">k8s-m1.local   NotReady   master   22m     v1.13.5</span><br><span class="line">k8s-m2.local   NotReady   master   8m19s   v1.13.5</span><br><span class="line">k8s-m3.local   NotReady   master   7m59s   v1.13.5</span><br></pre></td></tr></table></figure></li><li><p>手动部署flannel addons</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></li><li><p>三节点高可用部署完成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-89cc84847-6m8rw                1/1     Running   0          88m</span><br><span class="line">coredns-89cc84847-lkfcx                1/1     Running   0          87m</span><br><span class="line">kube-apiserver-k8s-m1.local            1/1     Running   0          87m</span><br><span class="line">kube-apiserver-k8s-m2.local            1/1     Running   0          73m</span><br><span class="line">kube-apiserver-k8s-m3.local            1/1     Running   0          73m</span><br><span class="line">kube-controller-manager-k8s-m1.local   1/1     Running   1          87m</span><br><span class="line">kube-controller-manager-k8s-m2.local   1/1     Running   0          73m</span><br><span class="line">kube-controller-manager-k8s-m3.local   1/1     Running   1          73m</span><br><span class="line">kube-flannel-ds-amd64-6sd98            1/1     Running   0          29m</span><br><span class="line">kube-flannel-ds-amd64-rlffk            1/1     Running   0          29m</span><br><span class="line">kube-flannel-ds-amd64-z6swc            1/1     Running   0          29m</span><br><span class="line">kube-proxy-9qrl6                       1/1     Running   0          73m</span><br><span class="line">kube-proxy-thnn5                       1/1     Running   0          88m</span><br><span class="line">kube-proxy-v6l8x                       1/1     Running   0          73m</span><br><span class="line">kube-scheduler-k8s-m1.local            1/1     Running   1          87m</span><br><span class="line">kube-scheduler-k8s-m2.local            1/1     Running   0          73m</span><br><span class="line">kube-scheduler-k8s-m3.local            1/1     Running   0          73m</span><br></pre></td></tr></table></figure></li></ul><h1 id="Node加入集群"><a href="#Node加入集群" class="headerlink" title="Node加入集群"></a>Node加入集群</h1><p>节点均需要做如下操作：kernel、ipvs、内核参数调整、docker、nginx、kubelet、替换编译过的kubeadm、拉取镜像（kube-proxy、pause、flannel）</p><h2 id="token有效期未超过24小时"><a href="#token有效期未超过24小时" class="headerlink" title="token有效期未超过24小时"></a>token有效期未超过24小时</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm join server.k8s.local:8443 --token 7ub1sg.pjcsar2pv8pdz60u --discovery-token-ca-cert-hash sha256:13c7d2e9c6c4298a6433fd73dc73403aaf7a99309ac1ad786bf668ffab8c76f8</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[discovery] Trying to connect to API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[discovery] Created cluster-info discovery client, requesting info from <span class="string">"https://server.k8s.local:8443"</span></span><br><span class="line">[discovery] Requesting info from <span class="string">"https://server.k8s.local:8443"</span> again to validate TLS against the pinned public key</span><br><span class="line">[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[discovery] Successfully established connection with API Server <span class="string">"server.k8s.local:8443"</span></span><br><span class="line">[join] Reading configuration from the cluster...</span><br><span class="line">[join] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[kubelet] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.13"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[tlsbootstrap] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[patchnode] Uploading the CRI Socket information <span class="string">"/var/run/dockershim.sock"</span> to the Node API object <span class="string">"k8s-n1.local"</span> as an annotation</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the master to see this node join the cluster.</span><br></pre></td></tr></table></figure><h2 id="token有效期已超过24小时"><a href="#token有效期已超过24小时" class="headerlink" title="token有效期已超过24小时"></a>token有效期已超过24小时</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm token create //重新生成新token</span></span><br><span class="line">gsjgma.k0qgtgbhb89f3yns</span><br><span class="line"><span class="comment"># kubeadm token list</span></span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION   EXTRA GROUPS</span><br><span class="line">gsjgma.k0qgtgbhb89f3yns   23h       2019-05-06T08:51:58+08:00   authentication,signing   &lt;none&gt;        system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"><span class="comment"># openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' （获取ca证书sha256编码hash值）</span></span><br><span class="line">13c7d2e9c6c4298a6433fd73dc73403aaf7a99309ac1ad786bf668ffab8c76f8</span><br><span class="line"><span class="comment"># kubeadm join server.k8s.local:8443 --token gsjgma.k0qgtgbhb89f3yns --discovery-token-ca-cert-hash sha256:13c7d2e9c6c4298a6433fd73dc73403aaf7a99309ac1ad786bf668ffab8c76f8</span></span><br></pre></td></tr></table></figure><h2 id="设置和取消master节点上的污点"><a href="#设置和取消master节点上的污点" class="headerlink" title="设置和取消master节点上的污点"></a>设置和取消master节点上的污点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl taint nodes k8s-m1.local node-role.kubernetes.io/master="":NoSchedule</span></span><br><span class="line"><span class="comment"># kubectl taint node k8s-master node-role.kubernetes.io/master-</span></span><br></pre></td></tr></table></figure><h2 id="worker节点打标签声明role"><a href="#worker节点打标签声明role" class="headerlink" title="worker节点打标签声明role"></a>worker节点打标签声明role</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node k8s-n1 node-role.kubernetes.io/worker=worker</span><br></pre></td></tr></table></figure><h2 id="查看集群最终状态"><a href="#查看集群最终状态" class="headerlink" title="查看集群最终状态"></a>查看集群最终状态</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME           STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-m1.local   Ready    master   30m     v1.13.5</span><br><span class="line">k8s-m2.local   Ready    master   20m     v1.13.5</span><br><span class="line">k8s-m3.local   Ready    master   20m     v1.13.5</span><br><span class="line">k8s-n1.local   Ready    worker   6m1s    v1.13.5</span><br><span class="line">k8s-n2.local   Ready    worker   5m46s   v1.13.5</span><br><span class="line"><span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-89cc84847-6m8rw                  1/1     Running   0          16d</span><br><span class="line">coredns-89cc84847-lkfcx                  1/1     Running   0          16d</span><br><span class="line">kube-apiserver-k8s-m1.local              1/1     Running   0          16d</span><br><span class="line">kube-apiserver-k8s-m2.local              1/1     Running   0          16d</span><br><span class="line">kube-apiserver-k8s-m3.local              1/1     Running   0          16d</span><br><span class="line">kube-controller-manager-k8s-m1.local     1/1     Running   2          16d</span><br><span class="line">kube-controller-manager-k8s-m2.local     1/1     Running   2          16d</span><br><span class="line">kube-controller-manager-k8s-m3.local     1/1     Running   3          16d</span><br><span class="line">kube-flannel-ds-amd64-6sd98              1/1     Running   0          16d</span><br><span class="line">kube-flannel-ds-amd64-rlffk              1/1     Running   0          16d</span><br><span class="line">kube-flannel-ds-amd64-tgsdl              1/1     Running   0          16d</span><br><span class="line">kube-flannel-ds-amd64-xjvns              1/1     Running   0          22s</span><br><span class="line">kube-flannel-ds-amd64-z6swc              1/1     Running   0          16d</span><br><span class="line">kube-proxy-6rgb6                         1/1     Running   0          22s</span><br><span class="line">kube-proxy-9qrl6                         1/1     Running   0          16d</span><br><span class="line">kube-proxy-jhttz                         1/1     Running   0          16d</span><br><span class="line">kube-proxy-thnn5                         1/1     Running   0          16d</span><br><span class="line">kube-proxy-v6l8x                         1/1     Running   0          16d</span><br><span class="line">kube-scheduler-k8s-m1.local              1/1     Running   3          16d</span><br><span class="line">kube-scheduler-k8s-m2.local              1/1     Running   1          16d</span><br><span class="line">kube-scheduler-k8s-m3.local              1/1     Running   2          16d</span><br><span class="line">metrics-server-v0.3.2-75bdb997c6-6pnzc   2/2     Running   0          18s</span><br></pre></td></tr></table></figure><h1 id="移除节点"><a href="#移除节点" class="headerlink" title="移除节点"></a>移除节点</h1><h2 id="在master上的操作"><a href="#在master上的操作" class="headerlink" title="在master上的操作"></a>在master上的操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl drain k8s-n2 --delete-local-data --force --ignore-daemonsets</span></span><br><span class="line">node/k8s-n2 cordoned</span><br><span class="line">WARNING: Ignoring DaemonSet-managed pods: kube-flannel-ds-amd64-298db, kube-proxy-5vn99</span><br><span class="line">node/k8s-n2 drained</span><br><span class="line"><span class="comment"># kubectl delete node k8s-n2</span></span><br><span class="line">node <span class="string">"k8s-n2"</span> deleted</span><br></pre></td></tr></table></figure><h2 id="在node上的操作"><a href="#在node上的操作" class="headerlink" title="在node上的操作"></a>在node上的操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm reset</span></span><br><span class="line">[reset] WARNING: changes made to this host by <span class="string">'kubeadm init'</span> or <span class="string">'kubeadm join'</span> will be reverted.</span><br><span class="line">[reset] are you sure you want to proceed? [y/N]: y</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">[reset] no etcd config found. Assuming external etcd</span><br><span class="line">[reset] please manually reset etcd to prevent further issues</span><br><span class="line">[reset] stopping the kubelet service</span><br><span class="line">[reset] unmounting mounted directories <span class="keyword">in</span> <span class="string">"/var/lib/kubelet"</span></span><br><span class="line">[reset] deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes]</span><br><span class="line">[reset] deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]</span><br><span class="line">[reset] deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]</span><br><span class="line"></span><br><span class="line">The reset process does not reset or clean up iptables rules or IPVS tables.</span><br><span class="line">If you wish to reset iptables, you must <span class="keyword">do</span> so manually.</span><br><span class="line">For example:</span><br><span class="line">iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span><br><span class="line"></span><br><span class="line">If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)</span><br><span class="line">to reset your system<span class="string">'s IPVS tables.</span></span><br><span class="line"><span class="string"># iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span></span><br><span class="line"><span class="string"># ipvsadm --clear</span></span><br><span class="line"><span class="string"># kubeadm reset</span></span><br><span class="line"><span class="string"># ifconfig cni0 down</span></span><br><span class="line"><span class="string"># ip link delete cni0</span></span><br><span class="line"><span class="string"># ifconfig flannel.1 down</span></span><br><span class="line"><span class="string"># ip link delete flannel.1</span></span><br><span class="line"><span class="string"># rm -rf /var/lib/cni/</span></span><br></pre></td></tr></table></figure><h1 id="自动补全kubectl"><a href="#自动补全kubectl" class="headerlink" title="自动补全kubectl"></a>自动补全kubectl</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y bash-completion</span></span><br><span class="line"><span class="comment"># source /usr/share/bash-completion/bash_completion</span></span><br><span class="line"><span class="comment"># source &lt;(kubectl completion bash)</span></span><br><span class="line"><span class="comment"># echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h1&gt;&lt;h2 id=&quot;关闭防火墙和selinux&quot;&gt;&lt;a href=&quot;#关闭防火墙和selinux&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://yoursite.com/categories/Kubernetes/"/>
    
    
  </entry>
  
  <entry>
    <title>二进制Kubernetes HA部署方案</title>
    <link href="http://yoursite.com/2019/05/07/%E5%88%B6%E9%83%A8%E7%BD%B2Kubernetes-HA/"/>
    <id>http://yoursite.com/2019/05/07/制部署Kubernetes-HA/</id>
    <published>2019-05-07T09:09:00.000Z</published>
    <updated>2019-05-10T15:47:47.497Z</updated>
    
    <content type="html"><![CDATA[<p>&#9742;</p><h1 id="软件安装版本预览"><a href="#软件安装版本预览" class="headerlink" title="软件安装版本预览"></a>软件安装版本预览</h1><div class="note warning">            <ul><li>Kubernetes v1.13.5 (v1.13.4有kubectl cp的bug)</li><li>CNI v0.7.5</li><li>Etcd v3.2.24</li><li>Flannel v0.11.0 or Calico v3.4</li><li>Docker CE 18.06.03</li></ul>          </div><p>在官方的支持版本里，1.13.5并未支持18.09，为此这里使用的是18.06.03。</p><h1 id="网络信息"><a href="#网络信息" class="headerlink" title="网络信息"></a>网络信息</h1><div class="note warning">            <ul><li>Cluster IP CIDR: 10.244.0.0/16</li><li>Service Cluster IP CIDR: 10.96.0.0/12</li><li>Service DNS IP: 10.96.0.10</li><li>DNS DN: cluster.local</li><li>Kubernetes API VIP: 10.0.6.155</li><li>Kubernetes Ingress VIP: 10.0.6.156</li></ul>          </div><p><img src="/images/pasted-15.png" alt="upload successful"></p><h1 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h1><table><thead><tr><th style="text-align:center">IP</th><th style="text-align:center">Hostname</th><th style="text-align:center">CPU</th><th style="text-align:center">Memory</th></tr></thead><tbody><tr><td style="text-align:center">10.0.6.166</td><td style="text-align:center">k8s-m1</td><td style="text-align:center">2</td><td style="text-align:center">2G</td></tr><tr><td style="text-align:center">10.0.6.167</td><td style="text-align:center">k8s-m2</td><td style="text-align:center">2</td><td style="text-align:center">2G</td></tr><tr><td style="text-align:center">10.0.6.168</td><td style="text-align:center">k8s-m3</td><td style="text-align:center">2</td><td style="text-align:center">2G</td></tr><tr><td style="text-align:center">10.0.6.169</td><td style="text-align:center">k8s-n1</td><td style="text-align:center">2</td><td style="text-align:center">3G</td></tr><tr><td style="text-align:center">10.0.6.170</td><td style="text-align:center">k8s-n2</td><td style="text-align:center">2</td><td style="text-align:center">3G</td></tr></tbody></table><p>另外vip为10.0.6.155，由所有master节点的keepalived+haproxy来选择vip的归属保持高可用。</p><div class="note warning">            <ul><li>高可用一般建议为3、5、7台的奇数台</li></ul>          </div><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul><li>所有机器网络互通，并且k8s-m1可以免密码登陆。</li><li><p>所有防火墙和selinux关闭，否则k8s挂载目录时会报错Permission denied。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> --now firewalld NetworkManager</span><br><span class="line">setenforce 0</span><br><span class="line">sed -ri <span class="string">'/^[^#]*SELINUX=/s#=.+$#=disabled#'</span> /etc/selinux/config</span><br></pre></td></tr></table></figure></li><li><p>如果为GUI环境的Linux，dns server地址为127.0.0.1，会导致docker无法解析域名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> --now dnsmasq</span><br></pre></td></tr></table></figure></li><li><p>Kubernetes v1.8后，要求关闭系统swap，若不关闭的话，则需要修改kubelet参数来忽略swap on，–fail-swap-on=false，关闭所有机器的swap。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">sed -ri <span class="string">'/^[^#]*swap/s@^@#@'</span> /etc/fstab</span><br></pre></td></tr></table></figure></li><li><p>选择1：升级至保守内核</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install epel-release -y</span><br><span class="line">yum update -y</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></li><li><p>选择2：升级至较新的内核（市面上发行版linux内核版本普遍较低，4.15都存在一些bug）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel:unregister_netdevice: waiting <span class="keyword">for</span> lo to become free. Usage count = 1</span><br></pre></td></tr></table></figure><p>安装elrepo源，导入key和查看可安装的内核版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available --showduplicates</span><br></pre></td></tr></table></figure><div class="note warning">            <p>显示mainline为最新版本的内核。</p>          </div><ul><li><p>最新版本内核安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available --showduplicates | grep -Po <span class="string">'^kernel-ml.x86_64\s+\K\S+(?=.el7)'</span></span><br><span class="line">yum --disablerepo=<span class="string">"*"</span> --enablerepo=elrepo-kernel install -y kernel-ml&#123;,-devel&#125;</span><br></pre></td></tr></table></figure></li><li><p>自定义版本内核安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> Kernel_Version=4.18.9-1</span><br><span class="line">wget http://mirror.rc.usf.edu/compute_lock/elrepo/kernel/el7/x86_64/RPMS/kernel-ml&#123;,-devel&#125;-<span class="variable">$&#123;Kernel_Version&#125;</span>.el7.elrepo.x86_64.rpm</span><br><span class="line">yum localinstall -y kernel-ml*</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>修改内核启动顺序，并验证是否为默认内核</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub2-set-default 0 &amp;&amp; grub2-mkconfig -o /etc/grub2.cfg</span><br><span class="line">grubby --default-kernel</span><br></pre></td></tr></table></figure></li><li><p>开启user namespace，并重启加载新内核</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grubby --args=<span class="string">"user_namespace.enable=1"</span> --update-kernel=<span class="string">"<span class="variable">$(grubby --default-kernel)</span>"</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></li><li><p>安装ipvs</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br></pre></td></tr></table></figure></li><li><p>加载内核模块并设置开机自动加载</p><p>ipvs依赖于nf_conntrack_ipv4内核模块，4.19包括之后内核里改名为nf_conntrack，1.13.1之前的 kube-proxy的代码里没有加判断，一直用的nf_conntrack_ipv4，1.13.1后的kube-proxy代码里增加了判断，可以顺利加载nf_conntrack，使用ipvs正常。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">:&gt; /etc/modules-load.d/ipvs.conf</span><br><span class="line">module=(</span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">br_netfilter</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> kernel_module <span class="keyword">in</span> <span class="variable">$&#123;module[@]&#125;</span>;<span class="keyword">do</span></span><br><span class="line">/sbin/modinfo -F filename <span class="variable">$kernel_module</span> |&amp; grep -qv ERROR &amp;&amp; <span class="built_in">echo</span> <span class="variable">$kernel_module</span> &gt;&gt; /etc/modules-load.d/ipvs.conf || :</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">systemctl <span class="built_in">enable</span> --now systemd-modules-load.service</span><br></pre></td></tr></table></figure></li><li><p>针对Kubernetes的参数调优</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line"><span class="comment"># 修复ipvs模式下长连接timeout问题 小于900即可</span></span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 10</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 1</span><br><span class="line">net.ipv4.neigh.default.gc_stale_time = 120</span><br><span class="line">net.ipv4.conf.all.rp_filter = 0</span><br><span class="line">net.ipv4.conf.default.rp_filter = 0</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 5000</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 1024</span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line"><span class="comment"># 要求iptables不对bridge的数据进行处理</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.netfilter.nf_conntrack_max = 2310720</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">fs.file-max = 52706963</span><br><span class="line">fs.nr_open = 52706963</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure></li><li><p>检查Docker安装必要条件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> curl https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh &gt; check-config.sh</span><br><span class="line">bash ./check-config.sh</span><br></pre></td></tr></table></figure></li><li><p>安装Docker</p><p>在Kubernetes官方<a href="https://github.com/kubernetes/kubernetes/" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/</a> 的对应版本changelog里搜索The list of validated docker versions remain查看支持的docker版本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> VERSION=18.06</span><br><span class="line">curl -fsSL <span class="string">"https://get.docker.com/"</span> | bash -s -- --mirror Aliyun</span><br></pre></td></tr></table></figure></li><li><p>配置Docker国内加速源并设置systemd启动参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/docker/</span><br><span class="line">cat&gt;/etc/docker/daemon.json&lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line"> <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line"> <span class="string">"registry-mirrors"</span>: [<span class="string">"https://fz5yth0r.mirror.aliyuncs.com"</span>],</span><br><span class="line"> <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line"> <span class="string">"storage-opts"</span>: [</span><br><span class="line">   <span class="string">"overlay2.override_kernel_check=true"</span></span><br><span class="line"> ],</span><br><span class="line"> <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line"> <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">   <span class="string">"max-size"</span>: <span class="string">"100m"</span>,</span><br><span class="line">   <span class="string">"max-file"</span>: <span class="string">"3"</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>设置Docker开机启动和命令补全</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y bash-completion</span><br><span class="line">cp /usr/share/bash-completion/completions/docker /etc/bash_completion.d/</span><br><span class="line">systemctl <span class="built_in">enable</span> --now docker</span><br></pre></td></tr></table></figure></li></ul><ul><li>申明集群环境变量</li></ul><p>为了后续安装方便，避免大量重复，根据自己环境声明环境变量，建议写入文件，避免ssh断开导致变量丢失后可以source。默认kubelet向集群注册时，使用hostname或者–hostname-override选项去注册信息。haproxy占用每台机器的8443端口去负载到每台master上的api-server的6443端口，keepalived保证vip飘在可用的master上所有管理组件和kubelet都会去访问vip:8443，即使某一台master宕机，也能访问api-server。如果云上环境建议使用LB代替haproxy和keepalived，vip选择同一个局域网未使用的ip。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 声明集群成员信息</span></span><br><span class="line"><span class="built_in">declare</span> -A MasterArray otherMaster NodeArray AllNode Other</span><br><span class="line">MasterArray=([<span class="string">'k8s-m1'</span>]=10.0.6.166 [<span class="string">'k8s-m2'</span>]=10.0.6.167 [<span class="string">'k8s-m3'</span>]=10.0.6.168)</span><br><span class="line">otherMaster=([<span class="string">'k8s-m2'</span>]=10.0.6.167 [<span class="string">'k8s-m3'</span>]=10.0.6.168)</span><br><span class="line">NodeArray=([<span class="string">'k8s-n1'</span>]=10.0.6.169 [<span class="string">'k8s-n2'</span>]=10.0.6.170)</span><br><span class="line"><span class="comment"># 下面复制上面的信息粘贴即可</span></span><br><span class="line">AllNode=([<span class="string">'k8s-m1'</span>]=10.0.6.166 [<span class="string">'k8s-m2'</span>]=10.0.6.167 [<span class="string">'k8s-m3'</span>]=10.0.6.168 [<span class="string">'k8s-n1'</span>]=10.0.6.169 [<span class="string">'k8s-n2'</span>]=10.0.6.170)</span><br><span class="line">Other=([<span class="string">'k8s-m2'</span>]=10.0.6.167 [<span class="string">'k8s-m3'</span>]=10.0.6.168 [<span class="string">'k8s-n1'</span>]=10.0.6.169 [<span class="string">'k8s-n2'</span>]=10.0.6.170)</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> VIP=10.0.6.155</span><br><span class="line"></span><br><span class="line">[ <span class="string">"<span class="variable">$&#123;#MasterArray[@]&#125;</span>"</span> -eq 1 ] &amp;&amp; <span class="built_in">export</span> VIP=<span class="variable">$&#123;MasterArray[@]&#125;</span> || <span class="built_in">export</span> API_PORT=8443</span><br><span class="line"><span class="built_in">export</span> KUBE_APISERVER=https://<span class="variable">$&#123;VIP&#125;</span>:<span class="variable">$&#123;API_PORT:=6443&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#声明需要安装的的k8s版本</span></span><br><span class="line"><span class="built_in">export</span> KUBE_VERSION=v1.13.5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网卡名</span></span><br><span class="line"><span class="built_in">export</span> interface=eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># cni</span></span><br><span class="line"><span class="built_in">export</span> CNI_URL=<span class="string">"https://github.com/containernetworking/plugins/releases/download"</span></span><br><span class="line"><span class="built_in">export</span> CNI_VERSION=v0.7.5</span><br><span class="line"><span class="comment"># etcd</span></span><br><span class="line"><span class="built_in">export</span> ETCD_version=v3.2.24</span><br></pre></td></tr></table></figure></p><ul><li><p>设置所有机器的hostname</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> <span class="variable">$&#123;!AllNode[@]&#125;</span>;<span class="keyword">do</span> </span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$name</span> <span class="variable">$&#123;AllNode[$name]&#125;</span> ---"</span></span><br><span class="line">  ssh <span class="variable">$&#123;AllNode[$name]&#125;</span> <span class="string">"hostnamectl set-hostname <span class="variable">$name</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li><li><p>在k8s-m1通过git获取相关二进制配置文件和yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/zhangguanzhang/k8s-manual-files.git ~/k8s-manual-files -b v1.13.4</span><br><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/</span><br></pre></td></tr></table></figure></li><li><p>无需翻墙获取所有二进制文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/</span><br><span class="line">docker pull zhangguanzhang/k8s_bin:<span class="variable">$KUBE_VERSION</span>-full</span><br><span class="line">docker run --rm -d --name temp zhangguanzhang/k8s_bin:<span class="variable">$KUBE_VERSION</span>-full sleep 10</span><br><span class="line">docker cp temp:/kubernetes-server-linux-amd64.tar.gz .</span><br><span class="line">tar -zxvf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/<span class="built_in">local</span>/bin kubernetes/server/bin/kube&#123;<span class="built_in">let</span>,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br></pre></td></tr></table></figure></li><li><p>分发master相关组件的二进制文件到其他master上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!otherMaster[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;otherMaster[$NODE]&#125;</span> ---"</span></span><br><span class="line">    scp /usr/<span class="built_in">local</span>/bin/kube&#123;<span class="built_in">let</span>,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; <span class="variable">$&#123;otherMaster[$NODE]&#125;</span>:/usr/<span class="built_in">local</span>/bin/ </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li><li><p>分发node相关组件的二进制文件到所有node上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!NodeArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;NodeArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    scp /usr/<span class="built_in">local</span>/bin/kube&#123;<span class="built_in">let</span>,-proxy&#125; <span class="variable">$&#123;NodeArray[$NODE]&#125;</span>:/usr/<span class="built_in">local</span>/bin/ </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li><li><p>分发CNI到其他机器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br><span class="line">wget <span class="string">"<span class="variable">$&#123;CNI_URL&#125;</span>/<span class="variable">$&#123;CNI_VERSION&#125;</span>/cni-plugins-amd64-<span class="variable">$&#123;CNI_VERSION&#125;</span>.tgz"</span> </span><br><span class="line">tar -zxf cni-plugins-amd64-<span class="variable">$&#123;CNI_VERSION&#125;</span>.tgz -C /opt/cni/bin</span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!Other[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;Other[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;Other[$NODE]&#125;</span> <span class="string">'mkdir -p /opt/cni/bin'</span></span><br><span class="line">    scp /opt/cni/bin/* <span class="variable">$&#123;Other[$NODE]&#125;</span>:/opt/cni/bin/</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="建立集群CA-keys-与Certificates"><a href="#建立集群CA-keys-与Certificates" class="headerlink" title="建立集群CA keys 与Certificates"></a>建立集群CA keys 与Certificates</h1><p>在这个部分，需要生成多个组件的Certificates，包含etcd、kubernetes组件等。并且每个集群都会有一个根数位凭证认证机构（Root Certificate Authority）被用在认证API Server与kubelet端的凭证。</p><div class="note warning">            <ul><li>注意的是CA中的CN（Common Name）与O（Organization）等内容是会影响Kubernetes组件认证的。<ul><li>CN，apiserver会从证书中提取该字段作为请求的用户名（UserName）</li><li>O，apiserver会从证书中提取该字段作为请求用户所属的组（Group）</li></ul></li><li>CA是自签名的根证书，用来签名后续创建的其他证书</li><li>以下所有证书都由openssl创建</li></ul>          </div><p>etcd可以使用官方提供的在线工具生成，<a href="http://play.etcd.io" target="_blank" rel="noopener">http://play.etcd.io</a></p><h2 id="准备openssl证书的配置文件"><a href="#准备openssl证书的配置文件" class="headerlink" title="准备openssl证书的配置文件"></a>准备openssl证书的配置文件</h2><ul><li><p>注入IP信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki/etcd</span><br><span class="line">sed -i <span class="string">"/IP.2/a IP.3 = <span class="variable">$VIP</span>"</span> ~/k8s-manual-files/pki/openssl.cnf</span><br><span class="line">sed -ri <span class="string">'/IP.3/r '</span>&lt;( paste -d <span class="string">''</span> &lt;(seq -f <span class="string">'IP.%g = '</span> 4 $[<span class="variable">$&#123;#AllNode[@]&#125;</span>+3])  &lt;(xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;AllNode[@]&#125;</span> | sort) ) ~/k8s-manual-files/pki/openssl.cnf</span><br><span class="line">sed -ri <span class="string">'$r '</span>&lt;( paste -d <span class="string">''</span> &lt;(seq -f <span class="string">'IP.%g = '</span> 2 $[<span class="variable">$&#123;#MasterArray[@]&#125;</span>+1])  &lt;(xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;MasterArray[@]&#125;</span> | sort) ) ~/k8s-manual-files/pki/openssl.cnf</span><br><span class="line">cp ~/k8s-manual-files/pki/openssl.cnf /etc/kubernetes/pki/</span><br><span class="line"><span class="built_in">cd</span> /etc/kubernetes/pki</span><br></pre></td></tr></table></figure><h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2></li></ul><table><thead><tr><th style="text-align:center">path</th><th style="text-align:center">Default CN</th><th style="text-align:center">description</th></tr></thead><tbody><tr><td style="text-align:center">ca.crt,key</td><td style="text-align:center">kubernetes-ca</td><td style="text-align:center">kubernetes general CA</td></tr><tr><td style="text-align:center">etcd/ca.crt,key</td><td style="text-align:center">etcd-ca</td><td style="text-align:center">For all etcd-related functions</td></tr><tr><td style="text-align:center">front-proxy-ca.crt,key</td><td style="text-align:center">kubernetes-front-proxy-ca</td><td style="text-align:center">For the front-end proxy</td></tr></tbody></table><p> kubernetes-ca<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -config openssl.cnf -subj <span class="string">"/CN=kubernetes-ca"</span> -extensions v3_ca -out ca.crt -days 10000</span><br></pre></td></tr></table></figure></p><p> etcd-ca<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out etcd/ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key etcd/ca.key -config openssl.cnf -subj <span class="string">"/CN=etcd-ca"</span> -extensions v3_ca -out etcd/ca.crt -days 10000</span><br></pre></td></tr></table></figure></p><p> front-proxy-ca<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out front-proxy-ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key front-proxy-ca.key -config openssl.cnf -subj <span class="string">"/CN=kubernetes-ca"</span> -extensions v3_ca -out front-proxy-ca.crt -days 10000</span><br></pre></td></tr></table></figure></p><p>生成所有的证书信息</p><table><thead><tr><th style="text-align:center">Default CN</th><th style="text-align:center">Parent CA</th><th style="text-align:center">O（in Subject）</th><th style="text-align:center">kind</th></tr></thead><tbody><tr><td style="text-align:center">kube-etcd</td><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">server,client</td></tr><tr><td style="text-align:center">kube-etcd-peer</td><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">server,client</td></tr><tr><td style="text-align:center">kube-etcd-healthcheck-client</td><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">client</td></tr><tr><td style="text-align:center">kube-apiserver-etcd-client</td><td style="text-align:center">etcd-ca</td><td style="text-align:center">system:masters</td><td style="text-align:center">client</td></tr><tr><td style="text-align:center">kube-apiserver</td><td style="text-align:center">kubernetes-ca</td><td style="text-align:center"></td><td style="text-align:center">server</td></tr><tr><td style="text-align:center">kube-apiserver-kubelet-client</td><td style="text-align:center">kubernetes-ca</td><td style="text-align:center">system:masters</td><td style="text-align:center">client</td></tr><tr><td style="text-align:center">front-proxy-client</td><td style="text-align:center">kubernetes-front-proxy-ca</td><td style="text-align:center"></td><td style="text-align:center">client</td></tr></tbody></table><p>证书路径</p><table><thead><tr><th style="text-align:center">Default CN</th><th style="text-align:center">recommend key path</th><th style="text-align:center">recommended</th><th style="text-align:center">command</th><th style="text-align:center">key argument</th><th style="text-align:center">cert argument</th></tr></thead><tbody><tr><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">etcd/ca.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center"></td><td style="text-align:center">-etcd-cafile</td></tr><tr><td style="text-align:center">etcd-client</td><td style="text-align:center">apiserver-etcd-client.key</td><td style="text-align:center">apiserver-etcd-client.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center">-etcd-keyfile</td><td style="text-align:center">-etcd-certfile</td></tr><tr><td style="text-align:center">kubernetes-ca</td><td style="text-align:center"></td><td style="text-align:center">ca.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center"></td><td style="text-align:center">-client-ca-file</td></tr><tr><td style="text-align:center">kube-apiserver</td><td style="text-align:center">apiserver.key</td><td style="text-align:center">apiserver.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center">–tls-private-key-file</td><td style="text-align:center">–tls-cert-file</td></tr><tr><td style="text-align:center">apiserver-kubelet-client</td><td style="text-align:center"></td><td style="text-align:center">apiserver-kubelet-client.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center"></td><td style="text-align:center">–kubelet-client-certificate</td></tr><tr><td style="text-align:center">front-proxy-ca</td><td style="text-align:center"></td><td style="text-align:center">front-proxy-ca.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center"></td><td style="text-align:center">–requestheader-client-ca-file</td></tr><tr><td style="text-align:center">front-proxy-client</td><td style="text-align:center">front-proxy-client.key</td><td style="text-align:center">front-proxy-client.crt</td><td style="text-align:center">kube-apiserver</td><td style="text-align:center">–proxy-client-key-file</td><td style="text-align:center">–proxy-client-cert-file</td></tr><tr><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">etcd/ca.crt</td><td style="text-align:center">etcd</td><td style="text-align:center"></td><td style="text-align:center">–trusted-ca-file,–peer-trusted-ca-file</td></tr><tr><td style="text-align:center">kube-etcd</td><td style="text-align:center">etcd/server.key</td><td style="text-align:center">etcd/server.crt</td><td style="text-align:center">etcd</td><td style="text-align:center">–key-file</td><td style="text-align:center">–cert-file</td></tr><tr><td style="text-align:center">kube-etcd-peer</td><td style="text-align:center">etcd/peer.key</td><td style="text-align:center">etcd/peer.crt</td><td style="text-align:center">etcd</td><td style="text-align:center">–peer-key-file</td><td style="text-align:center">–peer-cert-file</td></tr><tr><td style="text-align:center">etcd-ca</td><td style="text-align:center"></td><td style="text-align:center">etcd/ca.crt</td><td style="text-align:center">etcdctl[2]</td><td style="text-align:center"></td><td style="text-align:center">–cacert</td></tr><tr><td style="text-align:center">kube-etcd-healthcheck-client</td><td style="text-align:center">etcd/healthcheck-client.key</td><td style="text-align:center">etcd/healthcheck-client.crt</td><td style="text-align:center">etcdctl[2]</td><td style="text-align:center">–key</td><td style="text-align:center">–cert</td></tr></tbody></table><p>生成证书</p><p>apiserver-etcd-client<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out apiserver-etcd-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-etcd-client.key -subj <span class="string">"/CN=apiserver-etcd-client/O=system:masters"</span> -out apiserver-etcd-client.csr</span><br><span class="line">openssl x509 -<span class="keyword">in</span> apiserver-etcd-client.csr -req -CA etcd/ca.crt -CAkey etcd/ca.key -CAcreateserial -extensions v3_req_etcd -extfile openssl.cnf -out apiserver-etcd-client.crt -days 10000</span><br></pre></td></tr></table></figure></p><p>kube-etcd<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out etcd/server.key 2048</span><br><span class="line">openssl req -new -key etcd/server.key -subj <span class="string">"/CN=etcd-server"</span> -out etcd/server.csr</span><br><span class="line">openssl x509 -<span class="keyword">in</span> etcd/server.csr -req -CA etcd/ca.crt -CAkey etcd/ca.key -CAcreateserial -extensions v3_req_etcd -extfile openssl.cnf -out etcd/server.crt -days 10000</span><br></pre></td></tr></table></figure></p><p>kube-etcd-peer<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out etcd/peer.key 2048</span><br><span class="line">openssl req -new -key etcd/peer.key -subj <span class="string">"/CN=etcd-peer"</span> -out etcd/peer.csr</span><br><span class="line">openssl x509 -<span class="keyword">in</span> etcd/peer.csr -req -CA etcd/ca.crt -CAkey etcd/ca.key -CAcreateserial -extensions v3_req_etcd -extfile openssl.cnf -out etcd/peer.crt -days 10000</span><br></pre></td></tr></table></figure></p><p>kube-etcd-healthcheck-client<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out etcd/healthcheck-client.key 2048</span><br><span class="line">openssl req -new -key etcd/healthcheck-client.key -subj <span class="string">"/CN=etcd-client"</span> -out etcd/healthcheck-client.csr</span><br><span class="line">openssl x509 -<span class="keyword">in</span> etcd/healthcheck-client.csr -req -CA etcd/ca.crt -CAkey etcd/ca.key -CAcreateserial -extensions v3_req_etcd -extfile openssl.cnf -out etcd/healthcheck-client.crt -days 10000</span><br></pre></td></tr></table></figure></p><p>kube-apiserver<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out apiserver.key 2048</span><br><span class="line">openssl req -new -key apiserver.key -subj <span class="string">"/CN=kube-apiserver"</span> -config openssl.cnf -out apiserver.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 10000 -extensions v3_req_apiserver -extfile openssl.cnf -out apiserver.crt</span><br></pre></td></tr></table></figure></p><p>apiserver-kubelet-client<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out  apiserver-kubelet-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-kubelet-client.key -subj <span class="string">"/CN=apiserver-kubelet-client/O=system:masters"</span> -out apiserver-kubelet-client.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> apiserver-kubelet-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 10000 -extensions v3_req_client -extfile openssl.cnf -out apiserver-kubelet-client.crt</span><br></pre></td></tr></table></figure></p><p>front-proxy-client<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out  front-proxy-client.key 2048</span><br><span class="line">openssl req -new -key front-proxy-client.key -subj <span class="string">"/CN=front-proxy-client"</span> -out front-proxy-client.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> front-proxy-client.csr -CA front-proxy-ca.crt -CAkey front-proxy-ca.key -CAcreateserial -days 10000 -extensions v3_req_client -extfile openssl.cnf -out front-proxy-client.crt</span><br></pre></td></tr></table></figure></p><p>kube-scheduler<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out  kube-scheduler.key 2048</span><br><span class="line">openssl req -new -key kube-scheduler.key -subj <span class="string">"/CN=system:kube-scheduler"</span> -out kube-scheduler.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> kube-scheduler.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 10000 -extensions v3_req_client -extfile openssl.cnf -out kube-scheduler.crt</span><br></pre></td></tr></table></figure></p><p>sa.pub sa.key<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out  sa.key 2048</span><br><span class="line">openssl ecparam -name secp521r1 -genkey -noout -out sa.key</span><br><span class="line">openssl ec -<span class="keyword">in</span> sa.key -outform PEM -pubout -out sa.pub</span><br><span class="line">openssl req -new -sha256 -key sa.key -subj <span class="string">"/CN=system:kube-controller-manager"</span> -out sa.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> sa.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 10000 -extensions v3_req_client -extfile openssl.cnf -out sa.crt</span><br></pre></td></tr></table></figure></p><p>admin<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out  admin.key 2048</span><br><span class="line">openssl req -new -key admin.key -subj <span class="string">"/CN=kubernetes-admin/O=system:masters"</span> -out admin.csr</span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> admin.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 10000 -extensions v3_req_client -extfile openssl.cnf -out admin.crt</span><br></pre></td></tr></table></figure></p><p>清理 csr srl(csr只要key不变那每次生成都是一样的,所以可以删除,如果后期根据ca重新生成证书来添加ip的话可以此处不删除)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -name <span class="string">"*.csr"</span> -o -name <span class="string">"*.srl"</span>|xargs  rm -f</span><br></pre></td></tr></table></figure></p><h2 id="利用证书生成组件的kubeconfig"><a href="#利用证书生成组件的kubeconfig" class="headerlink" title="利用证书生成组件的kubeconfig"></a>利用证书生成组件的kubeconfig</h2><table><thead><tr><th style="text-align:center">filename</th><th style="text-align:center">credential name</th><th style="text-align:center">Default CN</th><th style="text-align:center">O（in Subject）</th></tr></thead><tbody><tr><td style="text-align:center">admin.conf</td><td style="text-align:center">default-admin</td><td style="text-align:center">kubernetes-admin</td><td style="text-align:center">system:masters</td></tr><tr><td style="text-align:center">kubelet.conf</td><td style="text-align:center">default-auth</td><td style="text-align:center">system:node:<nodename> (see note)</nodename></td><td style="text-align:center">system:nodes</td></tr><tr><td style="text-align:center">controller-manager.conf</td><td style="text-align:center">default-controller-manager</td><td style="text-align:center">system:kube-controller-manager</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">scheduler.conf</td><td style="text-align:center">default-manager</td><td style="text-align:center">system:kube-scheduler</td></tr></tbody></table><p>kubectl的参数意义为</p><ul><li>-certificate-authority: 验证根证书</li><li>-client-certificate, -client-key: 生成的组件证书和私钥，连接kube-apiserver时会用到</li><li>-embed-certs=true: 将ca.pem和组件.pem证书内容嵌入生成的kubeconfig文件中（不添加该参数，默认写入证书文件路径）</li></ul><p>kube-controller-manager<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER_NAME=<span class="string">"kubernetes"</span></span><br><span class="line">KUBE_USER=<span class="string">"system:kube-controller-manager"</span></span><br><span class="line">KUBE_CERT=<span class="string">"sa"</span></span><br><span class="line">KUBE_CONFIG=<span class="string">"controller-manager.kubeconfig"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials <span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.crt \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.key \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --cluster=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --user=<span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置当前使用的上下文</span></span><br><span class="line">kubectl config use-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的配置文件</span></span><br><span class="line">kubectl config view --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure></p><p>kube-scheduler<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER_NAME=<span class="string">"kubernetes"</span></span><br><span class="line">KUBE_USER=<span class="string">"system:kube-scheduler"</span></span><br><span class="line">KUBE_CERT=<span class="string">"kube-scheduler"</span></span><br><span class="line">KUBE_CONFIG=<span class="string">"scheduler.kubeconfig"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials <span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.crt \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.key \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --cluster=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --user=<span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置当前使用的上下文</span></span><br><span class="line">kubectl config use-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的配置文件</span></span><br><span class="line">kubectl config view --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure></p><p>admin(kubectl)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER_NAME=<span class="string">"kubernetes"</span></span><br><span class="line">KUBE_USER=<span class="string">"kubernetes-admin"</span></span><br><span class="line">KUBE_CERT=<span class="string">"admin"</span></span><br><span class="line">KUBE_CONFIG=<span class="string">"admin.kubeconfig"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials <span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.crt \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/<span class="variable">$&#123;KUBE_CERT&#125;</span>.key \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --cluster=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --user=<span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置当前使用的上下文</span></span><br><span class="line">kubectl config use-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的配置文件</span></span><br><span class="line">kubectl config view --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure></p><h2 id="分发kubeconfig及证书到其它master节点"><a href="#分发kubeconfig及证书到其它master节点" class="headerlink" title="分发kubeconfig及证书到其它master节点"></a>分发kubeconfig及证书到其它master节点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!otherMaster[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;otherMaster[$NODE]&#125;</span> ---"</span></span><br><span class="line">    scp -r /etc/kubernetes <span class="variable">$&#123;otherMaster[$NODE]&#125;</span>:/etc</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="配置etcd"><a href="#配置etcd" class="headerlink" title="配置etcd"></a>配置etcd</h2><p>&#9730; <a href="https://github.com/etcd-io/etcd/releases" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/releases</a></p><div class="note warning">            <ul><li>etcd用来保存集群所有状态key/value的存储系统，所有kubernetes组件会通过 apiserver会跟etcd进行沟通，从而保存或读取资源状态。</li><li>一般etcd跟master在一起，也可以单独做集群，但必须得配置apiserver指向etcd集群。</li></ul>          </div><h2 id="etcd二进制文件"><a href="#etcd二进制文件" class="headerlink" title="etcd二进制文件"></a>etcd二进制文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ETCD_version=v3.1.9</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/<span class="variable">$&#123;ETCD_version&#125;</span>/etcd-<span class="variable">$&#123;ETCD_version&#125;</span>-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf etcd-<span class="variable">$&#123;ETCD_version&#125;</span>-linux-amd64.tar.gz --strip-components=1 -C /usr/<span class="built_in">local</span>/bin etcd-<span class="variable">$&#123;ETCD_version&#125;</span>-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"></span><br><span class="line">docker pull quay.io/coreos/etcd:<span class="variable">$ETCD_version</span></span><br><span class="line">docker run --rm -d --name temp quay.io/coreos/etcd:<span class="variable">$ETCD_version</span> sleep 10</span><br><span class="line">docker cp temp:/usr/<span class="built_in">local</span>/bin/etcd /usr/<span class="built_in">local</span>/bin</span><br><span class="line">docker cp temp:/usr/<span class="built_in">local</span>/bin/etcdctl /usr/<span class="built_in">local</span>/bin</span><br></pre></td></tr></table></figure><p>分发etcd的二进制文件到其他master上<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!otherMaster[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;otherMaster[$NODE]&#125;</span> ---"</span></span><br><span class="line">    scp /usr/<span class="built_in">local</span>/bin/etcd* <span class="variable">$&#123;otherMaster[$NODE]&#125;</span>:/usr/<span class="built_in">local</span>/bin/</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>在k8s-m1上配置etcd配置文件并分发相关文件,配置文件路径为/etc/etcd/etcd.config.yml,参考官方 <a href="https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample</a></p><p>注入基础变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/master/</span><br><span class="line">etcd_servers=$( xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;MasterArray[@]&#125;</span> | sort | sed <span class="string">'s#^#https://#;s#$#:2379#;$s#\n##'</span> | paste -d, -s - )</span><br><span class="line">etcd_initial_cluster=$( <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;!MasterArray[@]&#125;</span>;<span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$i</span>=https://<span class="variable">$&#123;MasterArray[$i]&#125;</span>:2380; <span class="keyword">done</span> | sort | paste -d, -s - )</span><br><span class="line">sed -ri <span class="string">"/initial-cluster:/s#'.+'#'<span class="variable">$&#123;etcd_initial_cluster&#125;</span>'#"</span> etc/etcd/config.yml</span><br></pre></td></tr></table></figure></p><p>分发systemd和配置文件到其他master上<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">"mkdir -p /etc/etcd /var/lib/etcd"</span></span><br><span class="line">    scp systemd/etcd.service <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>:/usr/lib/systemd/system/etcd.service</span><br><span class="line">    scp etc/etcd/config.yml <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>:/etc/etcd/etcd.config.yml</span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">"sed -i "</span>s/&#123;HOSTNAME&#125;/<span class="variable">$NODE</span>/g<span class="string">" /etc/etcd/etcd.config.yml"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">"sed -i "</span>s/&#123;PUBLIC_IP&#125;/<span class="variable">$&#123;MasterArray[$NODE]&#125;</span>/g<span class="string">" /etc/etcd/etcd.config.yml"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'systemctl daemon-reload'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>在k8s-m1上启动所有etcd，etcd进程首次启动时会等待其它节点的etcd加入集群，命令 systemctl start etcd 会卡住一段时间，为正常现象，可以全部启动后，使用etcdctl命令验证健康状态。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'systemctl enable --now etcd'</span> &amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br></pre></td></tr></table></figure></p><p>查看etcd集群状态和集群的键值<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">etcdctl \</span><br><span class="line">  --cert-file /etc/kubernetes/pki/etcd/healthcheck-client.crt \</span><br><span class="line">  --key-file /etc/kubernetes/pki/etcd/healthcheck-client.key \</span><br><span class="line">  --ca-file /etc/kubernetes/pki/etcd/ca.crt \</span><br><span class="line">   --endpoints <span class="variable">$etcd_servers</span> cluster-health</span><br><span class="line"></span><br><span class="line">...下面是输出</span><br><span class="line">member 4f15324b6756581c is healthy: got healthy result from https://10.0.6.166:2379</span><br><span class="line">member cce1303a6b6dd443 is healthy: got healthy result from https://10.0.6.167:2379</span><br><span class="line">member ead42f3e6c9bb295 is healthy: got healthy result from https://10.0.6.168:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 \</span><br><span class="line">    etcdctl   \</span><br><span class="line">   --cert /etc/kubernetes/pki/etcd/healthcheck-client.crt \</span><br><span class="line">   --key /etc/kubernetes/pki/etcd/healthcheck-client.key \</span><br><span class="line">   --cacert /etc/kubernetes/pki/etcd/ca.crt \</span><br><span class="line">    --endpoints <span class="variable">$etcd_servers</span> get / --prefix --keys-only</span><br></pre></td></tr></table></figure></p><div class="note warning">            <ul><li>如果想了解更多etcdctl操作，可以访问官网的<a href="https://coreos.com/etcd/docs/3.3.1/demo.html" target="_blank" rel="noopener">etcdctl command</a>文章</li></ul>          </div><h1 id="Kubernetes-Master"><a href="#Kubernetes-Master" class="headerlink" title="Kubernetes Master"></a>Kubernetes Master</h1><p>本部分将说明如何建立与设定Kubernetes Master角色，过程中会部署以下组件：</p><p>kubelet</p><div class="note warning">            <ul><li>负责管理容器的生命周期，定期从API Server获取节点上的预期状态(如网络、存储等配置)资源，并让对应的容器插件(CRI、CNI等)来达成这个状态。任何 Kubernetes节点(node)都会拥有这个组件。</li><li>关闭只读端口，在安全端口10250接收https请求，对请求进行认证和授权，拒绝匿名访问和非授权访问。</li><li>使用 kubeconfig访问apiserver的安全端口。</li></ul>          </div><p>kube-apiserver</p><div class="note warning">            <ul><li>以REST APIs提供Kubernetes资源的CRUD，如授权、认证、存取控制与API 注册等机制。</li><li>关闭非安全端口，在安全端口6443接收https请求。</li><li>严格的认证和授权策略(x509、token、RBAC)。</li><li>开启bootstrap token认证，支持kubelet TLS bootstrapping。</li><li>使用https访问kubelet、etcd，加密通信。</li></ul>          </div><p>kube-controller-manager</p><div class="note warning">            <ul><li>通过核心控制循环(Core Control Loop)监听Kubernetes API的资源来维护集群的状态，这些资源会被不同的控制器所管理，如 Replication Controller、Namespace Controller等等。而这些控制器会处理着自动扩展、滚动更新等功能。</li><li>关闭非安全端口，在安全端口10252接收https请求。</li><li>使用kubeconfig访问apiserver的安全端口。</li></ul>          </div><p>kube-scheduler</p><div class="note warning">            <ul><li>负责将一个或多个容器依据调度策略分配到对应节点上让容器引擎(如 Docker)执行。而调度受到QoS要求、软硬性约束、亲和性(Affinity)等因素影响。</li></ul>          </div><p>HAProxy</p><div class="note warning">            <ul><li>提供多个API Server的负载均衡(Load Balance)，确保haproxy的端口负载到所有的apiserver的6443端口。</li></ul>          </div><p>Keepalived</p><div class="note warning">            <ul><li>提供虚拟IP位址(vip)，来让vip落在可用的master主机上供所有组件都能访问到可用的master，结合haproxy能访问到master上的apiserver的6443端口。</li></ul>          </div><h2 id="部署和设定"><a href="#部署和设定" class="headerlink" title="部署和设定"></a>部署和设定</h2><div class="note warning">            <ul><li>export interface=eth0，改为宿主机的网卡名。</li><li>若cluster dns或domain有改变的话，需要修改kubelet-conf.yml。</li></ul>          </div><h3 id="在master上安装haproxy-keepalived"><a href="#在master上安装haproxy-keepalived" class="headerlink" title="在master上安装haproxy+keepalived"></a>在master上安装haproxy+keepalived</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">   ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'yum install haproxy keepalived -y'</span> &amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br></pre></td></tr></table></figure><p>在k8s-m1节点下把相关配置文件配置后再分发<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/master/etc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改haproxy.cfg配置文件</span></span><br><span class="line">sed -i <span class="string">'$r '</span>&lt;(paste &lt;( seq -f<span class="string">'  server k8s-api-%g'</span>  <span class="variable">$&#123;#MasterArray[@]&#125;</span> ) &lt;( xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;MasterArray[@]&#125;</span> | sort | sed <span class="string">'s#$#:6443  check#'</span>)) haproxy/haproxy.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改keepalived(网卡和VIP写进去,使用下面命令)</span></span><br><span class="line"></span><br><span class="line">sed -ri <span class="string">"s#\&#123;\&#123; VIP \&#125;\&#125;#<span class="variable">$&#123;VIP&#125;</span>#"</span> keepalived/*</span><br><span class="line">sed -ri <span class="string">"s#\&#123;\&#123; interface \&#125;\&#125;#<span class="variable">$&#123;interface&#125;</span>#"</span> keepalived/keepalived.conf </span><br><span class="line">sed -i <span class="string">'/unicast_peer/r '</span>&lt;(xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;MasterArray[@]&#125;</span> | sort | sed <span class="string">'s#^#\t#'</span>) keepalived/keepalived.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分发文件</span></span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    scp -r haproxy/ <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>:/etc</span><br><span class="line">    scp -r keepalived/ <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>:/etc</span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'systemctl enable --now haproxy keepalived'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>等待keepalived和haproxy服务启动后，尝试ping下vip<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping <span class="variable">$VIP</span></span><br></pre></td></tr></table></figure></p><p>如果失败的话，可以在节点上查看/etc/keepalived/keepalived.conf里网卡名和ip是否注入成功或者尝试restart服务<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>  <span class="string">'systemctl restart haproxy keepalived'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><h3 id="Master组件"><a href="#Master组件" class="headerlink" title="Master组件"></a>Master组件</h3><p>在k8s-m1节点下把相关配置文件配置后再分发<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/master/</span><br><span class="line">etcd_servers=$( xargs -n1&lt;&lt;&lt;<span class="variable">$&#123;MasterArray[@]&#125;</span> | sort | sed <span class="string">'s#^#https://#;s#$#:2379#;$s#\n##'</span> | paste -d, -s - )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注入VIP和etcd_servers,apiserver数量</span></span><br><span class="line">sed -ri <span class="string">'/--etcd-servers/s#=.+#='</span><span class="string">"<span class="variable">$etcd_servers</span>"</span><span class="string">' \\#'</span> systemd/kube-apiserver.service</span><br><span class="line">sed -ri <span class="string">'/apiserver-count/s#=[^\]+#='</span><span class="string">"<span class="variable">$&#123;#MasterArray[@]&#125;</span>"</span><span class="string">' #'</span> systemd/kube-apiserver.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分发文件</span></span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'mkdir -p /etc/kubernetes/manifests /var/lib/kubelet /var/log/kubernetes'</span></span><br><span class="line">    scp systemd/kube-*.service <span class="variable">$&#123;MasterArray[$NODE]&#125;</span>:/usr/lib/systemd/system/</span><br><span class="line">    <span class="comment">#注入网卡ip</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">"sed -ri '/bind-address/s#=[^\]+#=<span class="variable">$&#123;MasterArray[$NODE]&#125;</span> #' /usr/lib/systemd/system/kube-apiserver.service &amp;&amp; sed -ri '/--advertise-address/s#=[^\]+#=<span class="variable">$&#123;MasterArray[$NODE]&#125;</span> #' /usr/lib/systemd/system/kube-apiserver.service"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>在k8s-m1上给所有master机器启动kubelet服务并设置kubectl补全脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!MasterArray[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;MasterArray[$NODE]&#125;</span> <span class="string">'systemctl enable --now  kube-apiserver kube-controller-manager kube-scheduler;</span></span><br><span class="line"><span class="string">    mkdir -p ~/.kube/</span></span><br><span class="line"><span class="string">    cp /etc/kubernetes/admin.kubeconfig ~/.kube/config;</span></span><br><span class="line"><span class="string">    kubectl completion bash &gt; /etc/bash_completion.d/kubectl'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><h3 id="验证组件"><a href="#验证组件" class="headerlink" title="验证组件"></a>验证组件</h3><p>完成后,在任意一台master节点通过简单指令验证<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get cs</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-2               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125; </span><br><span class="line"></span><br><span class="line">$ kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   36s</span><br></pre></td></tr></table></figure></p><h2 id="配置bootstrap"><a href="#配置bootstrap" class="headerlink" title="配置bootstrap"></a>配置bootstrap</h2><p>由于本次安装启用了TLS认证,因此每个节点的kubelet都必须使用kube-apiserver的CA的凭证后，才能与kube-apiserver进行沟通,而该过程需要手动针对每台节点单独签署凭证是一件繁琐的事情，而且一旦节点增加会延伸出管理不易问题。而TLS bootstrapping目标就是解决该问题，通过让kubelet先使用一个预定低权限使用者连接到kube-apiserver，然后在对kube-apiserver申请凭证签署，当授权Token一致时，Node节点的kubelet凭证将由kube-apiserver动态签署提供。具体做法可以参考<a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/" target="_blank" rel="noopener">TLS Bootstrapping</a>与<a href="https://kubernetes.io/docs/admin/bootstrap-tokens/" target="_blank" rel="noopener">Authenticating with Bootstrap Tokens</a>。</p><p>首先在k8s-m1建立一个变数来生产BOOTSTRAP_TOKEN，并建立bootstrap的kubeconfig文件，然后在k8s-m1建立TLS bootstrap secret来提供自动签证使用。（只需在任何一台master执行即可）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TOKEN_PUB=$(openssl rand -hex 3)</span><br><span class="line">TOKEN_SECRET=$(openssl rand -hex 8)</span><br><span class="line">BOOTSTRAP_TOKEN=<span class="string">"<span class="variable">$&#123;TOKEN_PUB&#125;</span>.<span class="variable">$&#123;TOKEN_SECRET&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system create secret generic bootstrap-token-<span class="variable">$&#123;TOKEN_PUB&#125;</span> \</span><br><span class="line">        --<span class="built_in">type</span> <span class="string">'bootstrap.kubernetes.io/token'</span> \</span><br><span class="line">        --from-literal description=<span class="string">"cluster bootstrap token"</span> \</span><br><span class="line">        --from-literal token-id=<span class="variable">$&#123;TOKEN_PUB&#125;</span> \</span><br><span class="line">        --from-literal token-secret=<span class="variable">$&#123;TOKEN_SECRET&#125;</span> \</span><br><span class="line">        --from-literal usage-bootstrap-authentication=<span class="literal">true</span> \</span><br><span class="line">        --from-literal usage-bootstrap-signing=<span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>建立bootstrap的kubeconfig文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER_NAME=<span class="string">"kubernetes"</span></span><br><span class="line">KUBE_USER=<span class="string">"kubelet-bootstrap"</span></span><br><span class="line">KUBE_CONFIG=<span class="string">"bootstrap.kubeconfig"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --cluster=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --user=<span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials <span class="variable">$&#123;KUBE_USER&#125;</span> \</span><br><span class="line">  --token=<span class="variable">$&#123;BOOTSTRAP_TOKEN&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置当前使用的上下文</span></span><br><span class="line">kubectl config use-context <span class="variable">$&#123;KUBE_USER&#125;</span>@<span class="variable">$&#123;CLUSTER_NAME&#125;</span> --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的配置文件</span></span><br><span class="line">kubectl config view --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure></p><div class="note warning">            <ul><li>若想要用手动签署凭证来进行授权的话，可以参考<a href="https://kubernetes.io/docs/concepts/cluster-administration/certificates/" target="_blank" rel="noopener">Certificate</a>。</li></ul>          </div><p>授权 kubelet可以创建csr<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubeadm:kubelet-bootstrap \</span><br><span class="line"> --clusterrole system:node-bootstrapper --group system:bootstrappers</span><br></pre></td></tr></table></figure></p><p>批准csr请求<br><div class="note warning">            <ul><li>允许system:bootstrappers组的所有csr</li></ul>          </div></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | kubectl apply -f -</span><br><span class="line"><span class="comment"># Approve all CSRs for the group "system:bootstrappers"</span></span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-csrs-for-group</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>允许 kubelet 能够更新自己的证书<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | kubectl apply -f -</span><br><span class="line"><span class="comment"># Approve renewal CSRs for the group "system:nodes"</span></span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-renewals-for-nodes</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p><h2 id="Kubernetes-Nodes"><a href="#Kubernetes-Nodes" class="headerlink" title="Kubernetes Nodes"></a>Kubernetes Nodes</h2><p>本部分将说明如何建立与设定Kubernetes Node角色，Node是主要执行Pod的工作节点。</p><p>在k8s-m1将需要的文件分发到其他节点上，这里值得一提的是，官方建议大多数写一个yaml里用–config指定kubelet配置。<a href="https://godoc.org/k8s.io/kubernetes/pkg/kubelet/apis/config#KubeletConfiguration" target="_blank" rel="noopener">https://godoc.org/k8s.io/kubernetes/pkg/kubelet/apis/config#KubeletConfiguration</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!Other[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;Other[$NODE]&#125;</span> ---"</span></span><br><span class="line">    ssh <span class="variable">$&#123;Other[$NODE]&#125;</span> <span class="string">"mkdir -p /etc/kubernetes/pki /etc/kubernetes/manifests /var/lib/kubelet/"</span></span><br><span class="line">    <span class="keyword">for</span> FILE <span class="keyword">in</span> /etc/kubernetes/pki/ca.crt /etc/kubernetes/bootstrap.kubeconfig; <span class="keyword">do</span></span><br><span class="line">      scp <span class="variable">$&#123;FILE&#125;</span> <span class="variable">$&#123;Other[$NODE]&#125;</span>:<span class="variable">$&#123;FILE&#125;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>部署与设定</p><p>这边建议healthzBindAddresskubeadm生成的是127，我建议设置成网卡ip方便后续检测curl <a href="http://10.0.6.166:10248/healthz" target="_blank" rel="noopener">http://10.0.6.166:10248/healthz</a></p><p>在k8s-m1节点分发kubelet.service文件和配置文件到每台上去管理kubelet<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/</span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!AllNode[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;AllNode[$NODE]&#125;</span> ---"</span></span><br><span class="line">   scp master/systemd/kubelet.service <span class="variable">$&#123;AllNode[$NODE]&#125;</span>:/lib/systemd/system/kubelet.service</span><br><span class="line">   scp master/etc/kubelet/kubelet-conf.yml <span class="variable">$&#123;AllNode[$NODE]&#125;</span>:/etc/kubernetes/kubelet-conf.yml</span><br><span class="line">   ssh <span class="variable">$&#123;AllNode[$NODE]&#125;</span> <span class="string">"sed -ri '/0.0.0.0/s#\S+\$#<span class="variable">$&#123;MasterArray[$NODE]&#125;</span>#' /etc/kubernetes/kubelet-conf.yml"</span></span><br><span class="line">   ssh <span class="variable">$&#123;AllNode[$NODE]&#125;</span> <span class="string">"sed -ri '/127.0.0.1/s#\S+\$#<span class="variable">$&#123;MasterArray[$NODE]&#125;</span>#' /etc/kubernetes/kubelet-conf.yml"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>最后在k8s-m1上去启动每个node节点的kubelet服务<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!AllNode[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;AllNode[$NODE]&#125;</span> ---"</span></span><br><span class="line">   ssh <span class="variable">$&#123;AllNode[$NODE]&#125;</span> <span class="string">'systemctl enable --now kubelet.service'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><h2 id="验证集群"><a href="#验证集群" class="headerlink" title="验证集群"></a>验证集群</h2><p>完成后，在任意一台master节点并通过简单指令验证<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME     STATUS     ROLES    AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">k8s-m1   NotReady   &lt;none&gt;   22s     v1.13.4   10.0.6.166    &lt;none&gt;        CentOS Linux 7 (Core)   4.20.13-1.el7.elrepo.x86_64   docker://18.6.3</span><br><span class="line">k8s-m2   NotReady   &lt;none&gt;   24s     v1.13.4   10.0.6.167    &lt;none&gt;        CentOS Linux 7 (Core)   4.20.13-1.el7.elrepo.x86_64   docker://18.6.3</span><br><span class="line">k8s-m3   NotReady   &lt;none&gt;   21s     v1.13.4   10.0.6.168    &lt;none&gt;        CentOS Linux 7 (Core)   4.20.13-1.el7.elrepo.x86_64   docker://18.6.3</span><br><span class="line">k8s-n1   NotReady   &lt;none&gt;   22s     v1.13.4   10.0.6.169    &lt;none&gt;        CentOS Linux 7 (Core)   4.20.13-1.el7.elrepo.x86_64   docker://18.6.3</span><br><span class="line">k8s-n2   NotReady   &lt;none&gt;   22s     v1.13.4   10.0.6.170    &lt;none&gt;        CentOS Linux 7 (Core)   4.20.13-1.el7.elrepo.x86_64   docker://18.6.3</span><br><span class="line"><span class="comment"># csr自动被授权</span></span><br><span class="line">$ kubectl get csr</span><br><span class="line">NAME                                                   AGE   REQUESTOR                 CONDITION</span><br><span class="line">node-csr-4fCDrNulc_btdBiRgev0JO4EorZ0rMuyJ756wrn9NqQ   27s   system:bootstrap:e860ec   Approved,Issued</span><br><span class="line">node-csr-P3Y_knryQNaQWDDYFObtcdfXB4XAl9IB2Be2YJ-b-dA   27s   system:bootstrap:e860ec   Approved,Issued</span><br><span class="line">node-csr-r_4ZDnanqBw2HPTSn6bSL50r-kJkTPjix6SY1n9UmjY   28s   system:bootstrap:e860ec   Approved,Issued</span><br><span class="line">node-csr-vy-6tgMI9vUiIzR3Ogv6bPVGA2_gZrd7aMIWMSuHrME   27s   system:bootstrap:e860ec   Approved,Issued</span><br><span class="line">node-csr-zOvVxSaY1iMco2LnOHmwqiBDwPUaLix7cSqUfZWTGFo   26s   system:bootstrap:e860ec   Approved,Issued</span><br></pre></td></tr></table></figure></p><p>设定master节点加上污点Taint不让(没有声明容忍该污点的)pod跑在master节点上<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes <span class="variable">$&#123;!MasterArray[@]&#125;</span> node-role.kubernetes.io/master=<span class="string">""</span>:NoSchedule</span><br><span class="line"><span class="comment"># 下面是输出</span></span><br><span class="line">node <span class="string">"k8s-m1"</span> tainted</span><br><span class="line">node <span class="string">"k8s-m2"</span> tainted</span><br><span class="line">node <span class="string">"k8s-m3"</span> tainted</span><br></pre></td></tr></table></figure></p><p>node打标签声明role<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node <span class="variable">$&#123;!MasterArray[@]&#125;</span> node-role.kubernetes.io/master=<span class="string">""</span></span><br><span class="line">kubectl label node <span class="variable">$&#123;!NodeArray[@]&#125;</span> node-role.kubernetes.io/worker=worker</span><br></pre></td></tr></table></figure></p><h1 id="Kubernetes-Core-Addons"><a href="#Kubernetes-Core-Addons" class="headerlink" title="Kubernetes Core Addons"></a>Kubernetes Core Addons</h1><p>完成master与nodes的部署后，kubernetes dns与kubernetes proxy等addons也是极为重要的。</p><h2 id="Kubernetes-Proxy"><a href="#Kubernetes-Proxy" class="headerlink" title="Kubernetes Proxy"></a>Kubernetes Proxy</h2><p>kube-proxy是实现Service的关键插件，kube-proxy会在每台节点上执行，然后监听API Server的Service与Endpoint资源的改变，然后来依据变化执行iptables来实现网路的转发。</p><ul><li><p>二进制部署</p><ul><li><p>创建一个kube-proxy的service account</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br></pre></td></tr></table></figure></li><li><p>将kube-proxy的serviceaccount绑定到clusterrole system:node-proxier以允许RBAC</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubeadm:kube-proxy \</span><br><span class="line"> --clusterrole system:node-proxier \</span><br><span class="line"> --serviceaccount kube-system:kube-proxy</span><br></pre></td></tr></table></figure></li><li><p>创建kube-proxy的kubeconfig</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">CLUSTER_NAME=<span class="string">"kubernetes"</span></span><br><span class="line">KUBE_CONFIG=<span class="string">"kube-proxy.kubeconfig"</span></span><br><span class="line"></span><br><span class="line">SECRET=$(kubectl -n kube-system get sa/kube-proxy \</span><br><span class="line">  --output=jsonpath=<span class="string">'&#123;.secrets[0].name&#125;'</span>)</span><br><span class="line"></span><br><span class="line">JWT_TOKEN=$(kubectl -n kube-system get secret/<span class="variable">$SECRET</span> \</span><br><span class="line">  --output=jsonpath=<span class="string">'&#123;.data.token&#125;'</span> | base64 -d)</span><br><span class="line"></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line">kubectl config <span class="built_in">set</span>-context <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --cluster=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --user=<span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials <span class="variable">$&#123;CLUSTER_NAME&#125;</span> \</span><br><span class="line">  --token=<span class="variable">$&#123;JWT_TOKEN&#125;</span> \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context <span class="variable">$&#123;CLUSTER_NAME&#125;</span> --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config view --kubeconfig=/etc/kubernetes/<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>在k8s-m1分发kube-proxy的相关文件到所有节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files/</span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!Other[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;Other[$NODE]&#125;</span> ---"</span></span><br><span class="line">  scp /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$&#123;Other[$NODE]&#125;</span>:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!AllNode[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;AllNode[$NODE]&#125;</span> ---"</span></span><br><span class="line">  scp addons/kube-proxy/kube-proxy.conf <span class="variable">$&#123;AllNode[$NODE]&#125;</span>:/etc/kubernetes/kube-proxy.conf</span><br><span class="line">  scp addons/kube-proxy/kube-proxy.service <span class="variable">$&#123;AllNode[$NODE]&#125;</span>:/usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">  ssh <span class="variable">$&#123;AllNode[$NODE]&#125;</span> <span class="string">"sed -ri '/0.0.0.0/s#\S+\$#<span class="variable">$&#123;MasterArray[$NODE]&#125;</span>#' /etc/kubernetes/kube-proxy.conf"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li><li><p>在k8s-m1上启动所有节点的kube-proxy服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> NODE <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!AllNode[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"--- <span class="variable">$NODE</span> <span class="variable">$&#123;AllNode[$NODE]&#125;</span> ---"</span></span><br><span class="line">  ssh <span class="variable">$&#123;AllNode[$NODE]&#125;</span> <span class="string">'systemctl enable --now kube-proxy'</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>daemonSet方式部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/k8s-manual-files</span><br><span class="line"><span class="comment"># 注入变量</span></span><br><span class="line">sed -ri <span class="string">"/server:/s#(: ).+#\1<span class="variable">$&#123;KUBE_APISERVER&#125;</span>#"</span> addons/kube-proxy/kube-proxy.yml</span><br><span class="line">sed -ri <span class="string">"/image:.+kube-proxy/s#:[^:]+\$#:<span class="variable">$KUBE_VERSION</span>#"</span> addons/kube-proxy/kube-proxy.yml</span><br><span class="line">kubectl apply -f addons/kube-proxy/kube-proxy.yml</span><br><span class="line"><span class="comment"># 下面是输出</span></span><br><span class="line">serviceaccount <span class="string">"kube-proxy"</span> created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io <span class="string">"system:kube-proxy"</span> created</span><br><span class="line">configmap <span class="string">"kube-proxy"</span> created</span><br><span class="line">daemonset.apps <span class="string">"kube-proxy"</span> created</span><br></pre></td></tr></table></figure><ul><li><p>正常输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get po -l k8s-app=kube-proxy</span><br><span class="line">NAME               READY     STATUS    RESTARTS   AGE</span><br><span class="line">kube-proxy-dd2m7   1/1       Running   0          8m</span><br><span class="line">kube-proxy-fwgx8   1/1       Running   0          8m</span><br><span class="line">kube-proxy-kjn57   1/1       Running   0          8m</span><br><span class="line">kube-proxy-vp47w   1/1       Running   0          8m</span><br></pre></td></tr></table></figure></li><li><p>通过ipvsadm查看proxy规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ipvsadm -ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">-&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  10.96.0.1:443 rr</span><br><span class="line">-&gt; 10.0.6.155:6443            Masq    1      0          0</span><br></pre></td></tr></table></figure></li><li><p>确认使用ipvs模式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl localhost:10249/proxyMode</span><br><span class="line">ipvs</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="集群网络"><a href="#集群网络" class="headerlink" title="集群网络"></a>集群网络</h2><p>Kubernetes在默认情況下与Docker的网络有所不同。在Kubernetes中有四个问题是需要被解決的，分別为：</p><ul><li>高耦合的容器到容器通信：通过Pods内localhost的來解決。</li><li>Pod到Pod的通信：通过实现网络模型来解决。</li><li>Pod到Service通信：由Service objects结合kube-proxy解決。</li><li>外部到Service 通信：一样由Service objects结合kube-proxy解決。</li></ul><p>而Kubernetes对于任何网络的实现都需要满足以下基本要求(除非是有意调整的网络分段策略)：</p><ul><li>所有容器能够在沒有NAT的情況下与其他容器通信。</li><li>所有节点能夠在沒有 NAT 情況下与所有容器通信(反之亦然)。</li><li>容器看到的IP与其他人看到的IP是一样的。</li></ul><p>目前Kubernetes已经有非常多种的<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model" target="_blank" rel="noopener">网络模型</a>作为<a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/" target="_blank" rel="noopener">网络插件(Network Plugins)</a>方式被实现，因此可以选用满足自己需求的网络功能来使用。另外Kubernetes中的网络插件有以下两种形式：</p><ul><li>CNI plugins：以appc/CNI标准规范所实现的网络，详细可以阅读<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">CNI Specification</a></li><li>Kubenet plugin：使用CNI plugins的bridge与host-local来实现基本的cbr0。这通常被用在公有云服务上的Kubernetes集群网络。</li></ul><div class="note warning">            <ul><li>如果想了解如何选择可以如阅读<a href="https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/" target="_blank" rel="noopener">Chris Love的Choosing a CNI Network Provider for Kubernetes</a>文章。</li></ul>          </div><h2 id="网络部署与设定-flannel或者calico任选其一"><a href="#网络部署与设定-flannel或者calico任选其一" class="headerlink" title="网络部署与设定(flannel或者calico任选其一)"></a>网络部署与设定(flannel或者calico任选其一)</h2><p>如果是公有云不在一个vpc里建议用flannel，因为公有云是SDN，只有vxlan才能到达目标，每个node上的flannel.1充当了vtep身份。另外完成到集群可以使用后会发现只有pod所在的node能访问到它这台上面的clusterIP，是因为kubelet上报的节点的node public IP是取网卡的ip，公有云网卡ip都是内网ip，所以当flannel包要发到目标机器的flannel上的时候会发到目标机器的内网ip上，根本发不出去。</p><ul><li>flannel</li></ul><p>flannel使用vxlan技术为各节点创建一个可以互通的Pod网络，使用的端口为 UDP 8472，需要开放该端口（如公有云 AWS 等）。</p><p>flannel第一次启动时，从etcd获取Pod网段信息，为本节点分配一个未使用的 /24段地址，然后创建flannel.1（也可能是其它名称，如 flannel1等）接口。</p><p>官方手动部署方法，采用ds创建<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></p><p>验证是否正常启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get po -l k8s-app=flannel</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE</span><br><span class="line">kube-flannel-ds-27jwl   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-4fgv6   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-mvrt7   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-p2q9g   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-zchsz   2/2       Running   0          59s</span><br></pre></td></tr></table></figure></p><ul><li>Calico</li></ul><p>Calico是一款纯 Layer3的网络，其好处是它整合了各种云原生平台(Docker、Mesos与OpenStack等)，且Calico不采用 vSwitch，而是在每个Kubernetes节点使用vRouter功能，并通过Linux Kernel既有的L3 forwarding功能，而当数据中心复杂度增加时，Calico也可以利用BGP route reflector來达成。</p><div class="note warning">            <ul><li>想了解Caclio与传统overlay networks的差异，可以阅读<a href="https://www.projectcalico.org/learn/" target="_blank" rel="noopener">Difficulties with traditional overlay networks</a>文章</li></ul>          </div><p>由于Calico提供了Kubernetes resources YAML文件来快速以容器方式部署网络插件至所有节点上，因此只需要在k8s-m1使用kubectl执行下面指令來建立<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.7/manifests/calico.yaml</span><br></pre></td></tr></table></figure></p><p>验证是否正常启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get po -l k8s-app=calico-node</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE</span><br><span class="line">calico-node-bv7r9   2/2       Running   4          5m</span><br><span class="line">calico-node-cmh2w   2/2       Running   3          5m</span><br><span class="line">calico-node-klzrz   2/2       Running   4          5m</span><br><span class="line">calico-node-n4c9j   2/2       Running   4          5m</span><br></pre></td></tr></table></figure></p><p>查找calicoctl的pod名字<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get po -l k8s-app=calicoctl</span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">calicoctl-6b5bf7cb74-d9gv8   1/1       Running   0          5m</span><br><span class="line">通过 kubectl <span class="built_in">exec</span> calicoctl pod 执行命令来检查功能是否正常</span><br></pre></td></tr></table></figure></p><p>通过 kubectl exec calicoctl pod 执行命令来检查功能是否正常<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system <span class="built_in">exec</span> calicoctl-6b5bf7cb74-d9gv8 -- calicoctl get profiles -o wide</span><br><span class="line">NAME              LABELS   </span><br><span class="line">kns.default       map[]    </span><br><span class="line">kns.kube-public   map[]    </span><br><span class="line">kns.kube-system   map[]    </span><br><span class="line"></span><br><span class="line">$ kubectl -n kube-system <span class="built_in">exec</span> calicoctl-6b5bf7cb74-d9gv8 -- calicoctl get node -o wide</span><br><span class="line">NAME     ASN         IPV4                 IPV6   </span><br><span class="line">k8s-m1   (unknown)   192.168.88.111/24          </span><br><span class="line">k8s-m2   (unknown)   192.168.88.112/24          </span><br><span class="line">k8s-m3   (unknown)   192.168.88.113/24          </span><br><span class="line">k8s-n1   (unknown)   10.244.3.1/24</span><br></pre></td></tr></table></figure></p><h2 id="CoreDNS"><a href="#CoreDNS" class="headerlink" title="CoreDNS"></a>CoreDNS</h2><p>1.11后CoreDNS已完全取代Kube DNS作为集群服务发现组件，由于Kubernetes需要让Pod与Pod之间能夠互相通信，然而要能够通信需要知道彼此的IP才行，而这种做法通常是通过Kubernetes API来获取，但是 Pod IP会因为生命周期变化而改变，因此这种做法无法弹性使用，且还会增加API Server负担，基于此问题Kubernetes提供了DNS服务来作为查询，让Pod能夠以Service名称作为域名来查询IP地址，因此使用者就再不需要关心实际Pod IP，而DNS也会根据Pod变化更新资源记录(Record resources)。</p><p>CoreDNS是由CNCF维护的开源DNS方案，该方案前身是SkyDNS，其采用了Caddy 的一部分来开发伺服器框架，使其能够建立一套快速灵活的DNS，而CoreDNS每个功能都可以被当作成一个插件的中介软体，如 Log、Cache、Kubernetes等功能，甚至能够将源记录存储在Redis、Etcd中。</p><p><a href="https://github.com/coredns/deployment/tree/master/kubernetes" target="_blank" rel="noopener">项目地址</a></p><p>官方部署方式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./deploy.sh | kubectl apply -f -</span><br></pre></td></tr></table></figure></p><p>验证是否正常启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get po -l k8s-app=kube-dns</span><br><span class="line">NAMESPACE     NAME                              READY     STATUS              RESTARTS   AGE</span><br><span class="line">kube-system   coredns-6975654877-jjqkg          1/1       Running   0          1m</span><br><span class="line">kube-system   coredns-6975654877-ztqjh          1/1       Running   0          1m</span><br></pre></td></tr></table></figure></p><p>完成后检查节点状态是否为Ready，以及Pod是否已经不再是Pending<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME      STATUS     ROLES     AGE       VERSION</span><br><span class="line">k8s-m1    Ready      master    17m       v1.13.5</span><br><span class="line">k8s-m2    Ready      master    16m       v1.13.5</span><br><span class="line">k8s-m3    Ready      master    16m       v1.13.5</span><br><span class="line">k8s-n1    Ready      node      6m        v1.13.5</span><br></pre></td></tr></table></figure></p><p>验证CoreDNS域名解析，nslookup是否能返回地址<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - sleep</span><br><span class="line">      - <span class="string">"3600"</span></span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="built_in">exec</span> -ti busybox -- nslookup kubernetes</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure></p><p>目前CoreDNS有部分BUG，官方无解，<a href="https://github.com/coredns/coredns/issues/2289" target="_blank" rel="noopener">issue地址</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">nslookup: can<span class="string">'t resolve '</span>kubernetes<span class="string">'</span></span><br><span class="line"><span class="string">command terminated with exit code 1</span></span><br></pre></td></tr></table></figure></p><h2 id="KubeDNS"><a href="#KubeDNS" class="headerlink" title="KubeDNS"></a>KubeDNS</h2><p>Kube DNS是Kubernetes集群内部Pod之间互相沟通的重要Addon，它允许Pod可以通过Domain Name方式来连接Service，其主要由Kube DNS与Sky DNS组合而成，通过Kube DNS监听Service与Endpoint变化，来提供给Sky DNS资讯，已更新解析位址。</p><p>如果CoreDNS工作不正常,先删掉它,删掉后确保coredns的pod和svc不存在。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f addons/coredns/coredns.yml</span><br><span class="line">$ kubectl -n kube-system get pod,svc -l k8s-app=kube-dns</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure></p><p>创建Kube DNS<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f addons/Kubedns/kubedns.yml</span><br><span class="line">serviceaccount/kube-dns created</span><br><span class="line">service/kube-dns created</span><br><span class="line">deployment.extensions/kube-dns create</span><br></pre></td></tr></table></figure></p><p>查看Pod状态<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system get pod,svc -l k8s-app=kube-dns</span><br><span class="line"></span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/kube-dns-59c677cb95-pxcbc   3/3     Running   0          3m</span><br><span class="line">pod/kube-dns-59c677cb95-wlprb   3/3     Running   0          3m</span><br><span class="line"></span><br><span class="line">NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">service/kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP   3m</span><br></pre></td></tr></table></figure></p><p>验证集群解析是否正常<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> -ti busybox -- nslookup kubernetes</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure></p><p>等官方修复BUG后，可以使用先创建CoreDNS的deployment，svc会负载到CoreDNS之后，再删掉KubeDNS的deployment。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ./deploy.sh | kubectl apply -f -</span><br><span class="line">$ kubectl delete --namespace=kube-system deployment kube-dns</span><br></pre></td></tr></table></figure></p><h2 id="Metrics-Server"><a href="#Metrics-Server" class="headerlink" title="Metrics Server"></a>Metrics Server</h2><p>Metrics Server是实现了Metrics API的组件，其目标是取代Heapster作为Pod 与Node提供资源的Usage metrics，该组件会从每个Kubernetes节点上的kubelet所公开的Summary API中收集Metrics。但我认为prometheus的监控功能更强大，完全可以代替Metrics，当然如果你非要使用kubetcl top nodes，可以按照官方教程安装Metrics。&#10003;<a href="https://github.com/kubernetes-incubator/metrics-server/tree/master/deploy/1.8+" target="_blank" rel="noopener">项目地址</a></p><ul><li>Metrics API只可以查询当前的度量数据，并不保存历史数据。</li><li>Metrics API URI为/apis/metrics.k8s.io/，在k8s.io/metrics维护。</li><li>Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。</li><li>HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒），周期性监控目标Pod的CPU使用率，并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整，以符合用户定义的平均Pod CPU使用率。</li></ul><p>未部署前<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl top node</span><br><span class="line">Error from server (NotFound): the server could not find the requested resource (get services http:heapster:)</span><br></pre></td></tr></table></figure></p><p>部署Metrics Server<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> metrics-server</span><br><span class="line">$ <span class="keyword">for</span> file <span class="keyword">in</span> aggregated-metrics-reader.yaml auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml; <span class="keyword">do</span> wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/<span class="variable">$file</span>; <span class="keyword">done</span></span><br><span class="line">$ kubectl create -f .</span><br><span class="line">$ kubectl -n kube-system get pods -l k8s-app=metrics-server</span><br></pre></td></tr></table></figure></p><p> 配置清单需根据实际情况调整</p><p> metrics-server-deployment.yaml<br> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">     - name:</span> <span class="string">metrics-server</span></span><br><span class="line"><span class="attr">       image:</span> <span class="string">k8s.gcr.io/metrics-server-amd64:v0.3.2</span></span><br><span class="line"><span class="attr">       imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">     - name:</span> <span class="string">metrics-server</span></span><br><span class="line"><span class="attr">       image:</span> <span class="string">k8s.gcr.io/metrics-server-amd64:v0.3.2</span></span><br><span class="line"><span class="attr">       imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">       args:</span></span><br><span class="line"><span class="bullet">       -</span> <span class="bullet">--kubelet-preferred-address-types=InternalIP</span></span><br><span class="line"><span class="bullet">       -</span> <span class="bullet">--kubelet-insecure-tls</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span> <span class="string">//删除这行</span></span><br></pre></td></tr></table></figure></p><p>提示无法解析节点的主机名，是metrics-server这个容器不能通过CoreDNS 10.96.0.10:53解析各Node的主机名，metrics-server连节点时默认是连接节点的主机名，需要加个参数，让它连接节点的IP：“–kubelet-preferred-address-types=InternalIP”。因为10250是https端口，连接它时需要提供证书，所以加上–kubelet-insecure-tls，表示不验证客户端证书，此前的版本中使用–source=这个参数来指定不验证客户端证书。</p><div class="note warning">            <p>值得提醒的是，master最好以Pod形式运行，是因为用户定义资源，也就是kind:xxxx和apiVersion:xxxx现在都是用自带的，后续开发和接触到CRD的时候会创建APIService，如果APIService里选中了svc，那么请求kube-apiserver的web路由的时候kube-apiserver会把请求转发到你选中的svc上，这里可以看官方文件里一部分内容。当我们使用kubectl top node的时候实际是请求kube-apiserver的url路径/apis/metrics.k8s.io/v1beta1/nodes,由于创建了metrics-server的APIService，请求会被转发到svc的pod，pod工作流程是获取node列表，然后去请求node上的kubelet的metrics端口获取metrics信息收集起来，信息包括了node的基本cpu和内存以及上面跑的pod的cpu和内存。这之前流量是kube-apiserver到pod上中间经过svc的ip，如果没有kube-proxy和网络组件就无法通信。</p>          </div><p>等待30s-1m后，执行kubectl top指令查看<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1</span><br><span class="line">&#123;<span class="string">"kind"</span>:<span class="string">"APIResourceList"</span>,<span class="string">"apiVersion"</span>:<span class="string">"v1"</span>,<span class="string">"groupVersion"</span>:<span class="string">"metrics.k8s.io/v1beta1"</span>,<span class="string">"resources"</span>:[&#123;<span class="string">"name"</span>:<span class="string">"nodes"</span>,<span class="string">"singularName"</span>:<span class="string">""</span>,<span class="string">"namespaced"</span>:<span class="literal">false</span>,<span class="string">"kind"</span>:<span class="string">"NodeMetrics"</span>,<span class="string">"verbs"</span>:[<span class="string">"get"</span>,<span class="string">"list"</span>]&#125;,&#123;<span class="string">"name"</span>:<span class="string">"pods"</span>,<span class="string">"singularName"</span>:<span class="string">""</span>,<span class="string">"namespaced"</span>:<span class="literal">true</span>,<span class="string">"kind"</span>:<span class="string">"PodMetrics"</span>,<span class="string">"verbs"</span>:[<span class="string">"get"</span>,<span class="string">"list"</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">$ kubectl get apiservice|grep metrics</span><br><span class="line">v1beta1.metrics.k8s.io                 kube-system/metrics-server   True        2m</span><br><span class="line"></span><br><span class="line">$ kubectl top node</span><br><span class="line">NAME      CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-m1    113m         2%        1080Mi          14%       </span><br><span class="line">k8s-m2    133m         3%        1086Mi          14%       </span><br><span class="line">k8s-m3    100m         2%        1029Mi          13%       </span><br><span class="line">k8s-n1    146m         3%        403Mi           5%</span><br></pre></td></tr></table></figure></p><p>这时若有使用 HPA 的话，就能够正确获取Pod的CPU与Memory使用量了。HPA使用Prometheus的Metrics的话，可以阅读<a href="https://github.com/stefanprodan/k8s-prom-hpa#setting-up-a-custom-metrics-server" target="_blank" rel="noopener">Custom Metrics Server</a>来了解。</p><h1 id="Kubernetes-Extra-Addons"><a href="#Kubernetes-Extra-Addons" class="headerlink" title="Kubernetes Extra Addons"></a>Kubernetes Extra Addons</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;#9742;&lt;/p&gt;
&lt;h1 id=&quot;软件安装版本预览&quot;&gt;&lt;a href=&quot;#软件安装版本预览&quot; class=&quot;headerlink&quot; title=&quot;软件安装版本预览&quot;&gt;&lt;/a&gt;软件安装版本预览&lt;/h1&gt;&lt;div class=&quot;note warning&quot;&gt;
       
      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://yoursite.com/categories/Kubernetes/"/>
    
    
  </entry>
  
  <entry>
    <title>构建标准且人性化镜像</title>
    <link href="http://yoursite.com/2019/05/02/%E6%9E%84%E5%BB%BA%E6%A0%87%E5%87%86%E4%B8%94%E4%BA%BA%E6%80%A7%E5%8C%96%E9%95%9C%E5%83%8F/"/>
    <id>http://yoursite.com/2019/05/02/构建标准且人性化镜像/</id>
    <published>2019-05-02T13:48:00.000Z</published>
    <updated>2019-05-02T13:53:13.946Z</updated>
    
    <content type="html"><![CDATA[<h6 id="正确的FROM合适的镜像"><a href="#正确的FROM合适的镜像" class="headerlink" title="正确的FROM合适的镜像"></a>正确的FROM合适的镜像</h6><p>很多新手一上来就是FROM centos然后RUN 一堆yum install的，这样还停留在虚拟机的角度。可以FROM alpine或者干脆拿官方的改，alpine初期的时候问题蛮多的，很多人建议使用alpine做基础镜像最好是测试好再上线，现在alpine的快速发展，这种现象很少了。</p><h6 id="不要用imageID或者latest标签"><a href="#不要用imageID或者latest标签" class="headerlink" title="不要用imageID或者latest标签"></a>不要用imageID或者latest标签</h6><p>id的话不便于长期发展，而latest标签无法回滚。</p><h6 id="不要重复造轮子"><a href="#不要重复造轮子" class="headerlink" title="不要重复造轮子"></a>不要重复造轮子</h6><p>现在dockerhub上有很多的镜像了，很多人还是喜欢造轮子，造出来的镜像层又多，无用的文件又停留在层理，主进程还不是业务进程，还不支持传入环境变量来让用户选择场景和传入配置信息启动。</p><p>如果你的是一个java应用，那么你应该使用java作为基础应用，如果你是tomcat应用，你应该使用tomcat作为基础应用，而不是按照虚拟机的思维，把Java装好，然后装应用；tomcat也一样，装java，装tomcat，装应用。</p><h6 id="镜像大小"><a href="#镜像大小" class="headerlink" title="镜像大小"></a>镜像大小</h6><p>之前我举例的ADD添加源码包和RUN rm -f删掉ADD的源码包，虽说最终起来的容器看不到源码包。实际上文件还停留在镜像的层里，所以尽量合并和减少层防止层保持住文件。</p><p>最后一些零散的建议和常见错误</p><ul><li>编写entrypoint脚本让启动更人性化</li><li>同时如果是初期上docker到生产，考虑到排错啥的，可以在官方dockerfile里添加一些常见的排错命</li><li>尽量使用ENV和ARG让人不改或者少改Dockerfile即可做构建对应版本的镜像</li><li>容器时间不对的话可以安装包tzdate，声明变量TZ即可声明时区，或者构建的时候带上/etc/localtime或者运行的时候挂载宿主机的/etc/localtime。</li><li>如果是编译型语言，妥善利用多阶段构建（后面容器无法运行排错的时候会讲解多阶构建）</li><li>代码里应该要注意优雅退出。收到信号的时候释放东西啥的。</li></ul><h6 id="代码，war，jar，go编译的二进制到底应不应该放在镜像里？"><a href="#代码，war，jar，go编译的二进制到底应不应该放在镜像里？" class="headerlink" title="代码，war，jar，go编译的二进制到底应不应该放在镜像里？"></a>代码，war，jar，go编译的二进制到底应不应该放在镜像里？</h6><p>其实现在的java和php，还有go啥的依赖的运行环境基本不会变，变更发布新版本也就只有代码，war，jar和go编译的二进制，为此可以两种做法:</p><ul><li>全部打包到镜像里</li><li>不变的层做个镜像，启动利用entrypoint脚本接受传入的git分支或者war包啥的内网下载直链下载到容器里或者启动直接挂载nfs里的war包或者代码啥的启动</li></ul><p>很多人都是传统的第一种思维，看到第二种的时候直接张口说这样不行。如果后续接触到了k8s会发现k8s有个initContainers，谷歌也说了可以利用initContainers去初始化或者克隆git代码。</p><p>其实两种均可，例如第一种，在没有gc原生docker下，每一次发布都会老版本镜像存在，虽说层共享，但是最后的代码层的容量还是占据了宿主机容量的。</p><p>第二种每次启动都需要下载，需要网速，如果是内网可以尝试，代码或者war包啥的都是在容器层，不会吃宿主机多大容量。实在接受不了可以运维给研发做个这种通用镜像给他们用。</p><p>最后是推荐一个漠然大佬的示例，漠然大佬的github上很多镜像下载量很多，可以去他github看，这里我放下他的java的应用示例 <a href="https://github.com/Gozap/dockerfile" target="_blank" rel="noopener">https://github.com/Gozap/dockerfile</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;正确的FROM合适的镜像&quot;&gt;&lt;a href=&quot;#正确的FROM合适的镜像&quot; class=&quot;headerlink&quot; title=&quot;正确的FROM合适的镜像&quot;&gt;&lt;/a&gt;正确的FROM合适的镜像&lt;/h6&gt;&lt;p&gt;很多新手一上来就是FROM centos然后RUN 一堆yu
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>exec与entrypoint使用脚本</title>
    <link href="http://yoursite.com/2019/05/02/exec%E4%B8%8Eentrypoint%E4%BD%BF%E7%94%A8%E8%84%9A%E6%9C%AC/"/>
    <id>http://yoursite.com/2019/05/02/exec与entrypoint使用脚本/</id>
    <published>2019-05-02T13:31:00.000Z</published>
    <updated>2019-05-02T13:48:10.245Z</updated>
    
    <content type="html"><![CDATA[<p>现在很多有状态的官方镜像的ENTRYPOINT都是使用了一个脚本。例如redis<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">COPY docker-entrypoint.sh /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">ENTRYPOINT [<span class="string">"docker-entrypoint.sh"</span>]</span><br><span class="line"></span><br><span class="line">EXPOSE 6379</span><br><span class="line">CMD [<span class="string">"redis-server"</span>]</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"></span><br><span class="line"><span class="comment"># first arg is `-f` or `--some-option`</span></span><br><span class="line"><span class="comment"># or first arg is `something.conf`</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;1#-&#125;</span>"</span> != <span class="string">"<span class="variable">$1</span>"</span> ] || [ <span class="string">"<span class="variable">$&#123;1%.conf&#125;</span>"</span> != <span class="string">"<span class="variable">$1</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">set</span> -- redis-server <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># allow the container to be started with `--user`</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">'redis-server'</span> -a <span class="string">"<span class="variable">$(id -u)</span>"</span> = <span class="string">'0'</span> ]; <span class="keyword">then</span></span><br><span class="line">find . \! -user redis -<span class="built_in">exec</span> chown redis <span class="string">'&#123;&#125;'</span> +</span><br><span class="line"><span class="built_in">exec</span> gosu redis <span class="string">"<span class="variable">$0</span>"</span> <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure><p>最终运行的是docker-entrypoint.sh redis-server</p><p>第一个if的逻辑是如果docker run 选项 redis -x 或者–xx或者xxx.conf，就把脚本收到的$@改编成redis-server $@,例如我们可同docker run -d redis –port 7379修改启动的容器里的redis端口。如果我们传入的command不是-开头的也不是.conf结尾的字符，例如是date，则会跑到最后的逻辑执行我们的date命令不会启动redis-server</p><p>第二个if这里，如果满足第一个if或者直接默认的cmd下而且容器里用户uid是0，则把属主不是redis的文件改成redis用户，然后切成redis用户去启动redis-server。</p><p>我们可以看到entrypoint能在业务进程启动前做很多事情。而且优秀的镜像都离不开entrypoint脚本，能够根据用户传入的变量和command来切换启动的场景和配置。</p><p>前面说了，主进程一定要是业务进程，这里怎么是个脚本呢，那业务进程不就不是pid为1了吗？ 这里用了exec来退位让贤，最终redis-server还是pid为1的。可以简单几个命令讲解下exec的作用。</p><p>写个test.sh脚本，在脚本里用pstree -p，运行脚本bash test.sh查看进程层次</p><p><img src="/images/pasted-13.png" alt="upload successful"></p><p>发现pstree是在我们脚本bash(1998)的子进程</p><p>然后在脚本最后面加一行exec pstree -p看看输出</p><p><img src="/images/pasted-14.png" alt="upload successful"></p><p>我们发现bash进程运行的时候pid是2022，然后第二个pstree上升到了2022这一层次了，假设pid为a的命令或者二进制exec执行了命令b，那b就接替了a的pid。如果说我们entrypoint或者cmd使用脚本，那么我们一定要在脚本最后启动业务进程的时候前面加个exec让脚本退位让贤。</p><p>最后环境变量写配置文件涉及到修改，还有一些判断是否初次启动的有下面一些工具或者套路。</p><ul><li>xmlstarlet 处理xml</li><li>pip安装shyaml 处理yaml</li><li>jq读取json</li><li>nodejs的npm安装json可以修改json文件</li><li>处理excel或者csv使用in2csv，csvkit 提供了 in2csv，csvcut，csvjoin，csvgrep</li><li>touch -d “@0”写在构建的最后一个RUN里把时间戳设置为1970-1-1，然后用stat命令判断</li><li>if [ “$(stat -c “%Y” “${CONF_INSTALL}/conf/server.xml”)” -eq “0” ]; then</li><li>另外entrypoint脚本COPY进去的时候注意可执行权限，如果Windows上传到Linux构建会因为entrpoint脚本没带权限无法运行</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在很多有状态的官方镜像的ENTRYPOINT都是使用了一个脚本。例如redis&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile STOPSIGNAL</title>
    <link href="http://yoursite.com/2019/05/02/Dockerfile-STOPSIGNAL/"/>
    <id>http://yoursite.com/2019/05/02/Dockerfile-STOPSIGNAL/</id>
    <published>2019-05-02T13:20:00.000Z</published>
    <updated>2019-05-02T13:23:31.182Z</updated>
    
    <content type="html"><![CDATA[<p>格式，缺省信号为SIGTERM<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">STOPSIGNAL signal</span><br><span class="line">------</span><br><span class="line">STOPSIGNAL SIGTERM</span><br><span class="line">STOPSIGNAL 9</span><br></pre></td></tr></table></figure></p><p>可以是kill -l的信号名字也可以信号数字:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -l</span><br><span class="line"> 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP</span><br><span class="line"> 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL10) SIGUSR1</span><br><span class="line">11) SIGSEGV12) SIGUSR213) SIGPIPE14) SIGALRM15) SIGTERM</span><br><span class="line">16) SIGSTKFLT17) SIGCHLD18) SIGCONT19) SIGSTOP20) SIGTSTP</span><br><span class="line">21) SIGTTIN22) SIGTTOU23) SIGURG24) SIGXCPU25) SIGXFSZ</span><br><span class="line">26) SIGVTALRM27) SIGPROF28) SIGWINCH29) SIGIO30) SIGPWR</span><br><span class="line">31) SIGSYS34) SIGRTMIN35) SIGRTMIN+136) SIGRTMIN+237) SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+439) SIGRTMIN+540) SIGRTMIN+641) SIGRTMIN+742) SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+944) SIGRTMIN+1045) SIGRTMIN+1146) SIGRTMIN+1247) SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+1449) SIGRTMIN+1550) SIGRTMAX-1451) SIGRTMAX-1352) SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-1154) SIGRTMAX-1055) SIGRTMAX-956) SIGRTMAX-857) SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-659) SIGRTMAX-560) SIGRTMAX-461) SIGRTMAX-362) SIGRTMAX-2</span><br><span class="line">63) SIGRTMAX-164) SIGRTMAX</span><br></pre></td></tr></table></figure></p><p>docker run的选项可以覆盖镜像定义的STOPSIGNAL信号<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--stop-signal string           Signal to stop a container (default <span class="string">"SIGTERM"</span>)</span><br></pre></td></tr></table></figure></p><p>在docker stop停止运行容器的时候指定发送给容器里pid为1角色的信号。默认超时10秒，超时则发送kill强杀进程。一般业务进程都是pid为1，所有官方的进程都会处理收到的SIGTERM信号进行优雅收尾退出。</p><p>前面说过了如果CMD是/bin/sh格式的话，主进程是一个sh -c的进程，shell不用trap处理的话是无法转发信号的。下面我举个例子</p><p>例子是是网上找的，两种CMD方式启动的redis<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -y install redis-server &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">EXPOSE 6379</span><br><span class="line">CMD /usr/bin/redis-server</span><br><span class="line">----------------------------</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -y install redis-server &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">EXPOSE 6379</span><br><span class="line">CMD [<span class="string">"/usr/bin/redis-server"</span>]</span><br></pre></td></tr></table></figure></p><p>构建两种镜像，然后docker run -d img_name，然后docker stop这俩镜像启动的容器会发现exec的redis能在docker stop的时候收到信号优雅退出Received SIGTERM, scheduling shutdown<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[1] 11 Feb 08:13:01.633 * The server is now ready to accept connections on port 6379</span><br><span class="line">[1 | signal handler] (1455179074) Received SIGTERM, scheduling shutdown...</span><br><span class="line">[1] 11 Feb 08:24:34.259 <span class="comment"># User requested shutdown...</span></span><br><span class="line">[1] 11 Feb 08:24:34.259 * Saving the final RDB snapshot before exiting.</span><br><span class="line">[1] 11 Feb 08:24:34.262 * DB saved on disk</span><br><span class="line">[1] 11 Feb 08:24:34.262 <span class="comment"># Redis is now ready to exit, bye bye...</span></span><br></pre></td></tr></table></figure></p><p>而/bin/sh的形式的redis在docker stop后去docker logs看日志会发现根本没有优雅退出，类似于强制杀掉一样。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[5] 11 Feb 08:12:40.109 * The server is now ready to accept connections on port 6379</span><br></pre></td></tr></table></figure></p><p>这是因为/bin/sh形式启动的redis主进程是一个sh，shell不会转发信号，所以最后sh被超时的docker stop发送了kill信号杀掉，整个容器生存周期结束，redis没有触发signal handler。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;格式，缺省信号为SIGTERM&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile VOLUME</title>
    <link href="http://yoursite.com/2019/05/02/Dockerfile-VOLUME/"/>
    <id>http://yoursite.com/2019/05/02/Dockerfile-VOLUME/</id>
    <published>2019-05-02T13:13:00.000Z</published>
    <updated>2019-05-02T13:14:48.141Z</updated>
    
    <content type="html"><![CDATA[<h6 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h6><p>两种写法，无区别<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [<span class="string">"/data"</span>,<span class="string">"/mysql"</span>]</span><br><span class="line">VOLUME /var/<span class="built_in">log</span> /var/db</span><br></pre></td></tr></table></figure></p><p>之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。</p><p>为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;VOLUME&quot;&gt;&lt;a href=&quot;#VOLUME&quot; class=&quot;headerlink&quot; title=&quot;VOLUME&quot;&gt;&lt;/a&gt;VOLUME&lt;/h6&gt;&lt;p&gt;两种写法，无区别&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile ENTRYPOINT</title>
    <link href="http://yoursite.com/2019/05/02/Dockerfile-ENTRYPOINT/"/>
    <id>http://yoursite.com/2019/05/02/Dockerfile-ENTRYPOINT/</id>
    <published>2019-05-02T13:01:00.000Z</published>
    <updated>2019-05-02T13:12:57.146Z</updated>
    
    <content type="html"><![CDATA[<h6 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h6><p>和CMD用法也一样两种格式，唯一要注意的就是区别，CMD和ENTRYPOINT只有一个或者两者都有都可以，容器最终运行的命令为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;ENTRYPOINT&gt; &lt;CMD&gt;</span><br></pre></td></tr></table></figure></p><p><img src="/images/pasted-12.png" alt="upload successful"></p><p>alpine的root目录是没有文件的，所以ls /root没有输出，我们用选项去覆盖住entrypoint可以看到输出了date。注意一点是覆盖entrypoint的时候镜像的CMD会被忽略，我们真要调试的时候需要加command的话，可以在docker run的镜像后面加command和arg。</p><p>上面例子可以很形象的证明了是这个关系，最终运行的是<strong><entrypoint> <cmd></cmd></entrypoint></strong>，同时不光在docker run的时候覆盖掉CMD，也可以覆盖掉默认的entrypoint。很多时候我们可以主进程bash或者sh进去手动启动看看。老版本接触不多，不确定老版本有没有–entrypoint的选项。</p><p>最后如果是/bin/sh的entrypoint会忽略掉CMD和docker run的command参数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;ENTRYPOINT&quot;&gt;&lt;a href=&quot;#ENTRYPOINT&quot; class=&quot;headerlink&quot; title=&quot;ENTRYPOINT&quot;&gt;&lt;/a&gt;ENTRYPOINT&lt;/h6&gt;&lt;p&gt;和CMD用法也一样两种格式，唯一要注意的就是区别，CMD和ENTRYPOIN
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>创建私有YUM源</title>
    <link href="http://yoursite.com/2019/05/01/%E5%88%9B%E5%BB%BA%E7%A7%81%E6%9C%89YUM%E6%BA%90/"/>
    <id>http://yoursite.com/2019/05/01/创建私有YUM源/</id>
    <published>2019-04-30T17:25:00.000Z</published>
    <updated>2019-04-30T17:28:51.101Z</updated>
    
    <content type="html"><![CDATA[<h6 id="安装httpd"><a href="#安装httpd" class="headerlink" title="安装httpd"></a>安装httpd</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install httpd</span><br></pre></td></tr></table></figure><h6 id="安装所需软件"><a href="#安装所需软件" class="headerlink" title="安装所需软件"></a>安装所需软件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install rsync createrepo</span><br></pre></td></tr></table></figure><h6 id="创建相关目录"><a href="#创建相关目录" class="headerlink" title="创建相关目录"></a>创建相关目录</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/www/repos/centos/7/&#123;os,updates,extras&#125;/x86_64</span><br></pre></td></tr></table></figure><h6 id="赋予读写权限"><a href="#赋予读写权限" class="headerlink" title="赋予读写权限"></a>赋予读写权限</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod -R 755 /var/www/repos</span><br></pre></td></tr></table></figure><h6 id="从清华源同步"><a href="#从清华源同步" class="headerlink" title="从清华源同步"></a>从清华源同步</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rsync -avz --delete --exclude=<span class="string">'repodata'</span> \</span><br><span class="line">rsync://mirrors.tuna.tsinghua.edu.cn/centos/7/os/x86_64/ \</span><br><span class="line">/var/www/repos/centos/7/os/x86_64/</span><br><span class="line"> </span><br><span class="line">rsync -avz --delete --exclude=<span class="string">'repodata'</span> \</span><br><span class="line">rsync://mirrors.tuna.tsinghua.edu.cn/centos/7/updates/x86_64/ \</span><br><span class="line">/var/www/repos/centos/7/updates/x86_64/</span><br><span class="line"> </span><br><span class="line">rsync -avz --delete --exclude=<span class="string">'repodata'</span> \</span><br><span class="line">rsync://mirrors.tuna.tsinghua.edu.cn/centos/7/extras/x86_64/ \</span><br><span class="line">/var/www/repos/centos/7/extras/x86_64/</span><br></pre></td></tr></table></figure><h6 id="创建-metadata-repositories"><a href="#创建-metadata-repositories" class="headerlink" title="创建 metadata repositories"></a>创建 metadata repositories</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">createrepo /var/www/repos/centos/7/os/x86_64/ </span><br><span class="line">createrepo /var/www/repos/centos/7/updates/x86_64/ </span><br><span class="line">createrepo /var/www/repos/centos/7/extras/x86_64/</span><br></pre></td></tr></table></figure><h6 id="设置定时任务，每天同步"><a href="#设置定时任务，每天同步" class="headerlink" title="设置定时任务，每天同步"></a>设置定时任务，每天同步</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi /etc/cron.daily/update-repo</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">VER=<span class="string">'7'</span></span><br><span class="line">ARCH=<span class="string">'x86_64'</span></span><br><span class="line">REPOS=(os updates extras)</span><br><span class="line"><span class="keyword">for</span> REPO <span class="keyword">in</span> <span class="variable">$&#123;REPOS[@]&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    rsync -avz --delete --exclude=<span class="string">'repodata'</span> \</span><br><span class="line">    rsync://mirrors.tuna.tsinghua.edu.cn/centos/<span class="variable">$&#123;VER&#125;</span>/<span class="variable">$&#123;REPO&#125;</span>/<span class="variable">$&#123;ARCH&#125;</span>/ /var/www/repos/centos/<span class="variable">$&#123;VER&#125;</span>/<span class="variable">$&#123;REPO&#125;</span>/<span class="variable">$&#123;ARCH&#125;</span>/</span><br><span class="line">    createrepo /var/www/repos/centos/<span class="variable">$&#123;VER&#125;</span>/<span class="variable">$&#123;REPO&#125;</span>/<span class="variable">$&#123;ARCH&#125;</span>/</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h6 id="赋予权限"><a href="#赋予权限" class="headerlink" title="赋予权限"></a>赋予权限</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 755 /etc/cron.daily/update-repo</span><br></pre></td></tr></table></figure><h6 id="配置httpd主机使其他客户端访问"><a href="#配置httpd主机使其他客户端访问" class="headerlink" title="配置httpd主机使其他客户端访问"></a>配置httpd主机使其他客户端访问</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/httpd/conf.d/repos.conf</span></span><br><span class="line">Alias /repos /var/www/repos</span><br><span class="line">&lt;directory /var/www/repos&gt;</span><br><span class="line">    Options +Indexes</span><br><span class="line">    Require all granted</span><br><span class="line">&lt;/directory&gt;</span><br></pre></td></tr></table></figure><h6 id="启动httpd服务"><a href="#启动httpd服务" class="headerlink" title="启动httpd服务"></a>启动httpd服务</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start httpd</span><br><span class="line">systemctl <span class="built_in">enable</span> httpd</span><br></pre></td></tr></table></figure><h6 id="客户端的配置文件，其中10-105-26-110是源服务器地址"><a href="#客户端的配置文件，其中10-105-26-110是源服务器地址" class="headerlink" title="客户端的配置文件，其中10.105.26.110是源服务器地址"></a>客户端的配置文件，其中10.105.26.110是源服务器地址</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi /etc/yum.repos.d/CentOS-Base.repo</span></span><br><span class="line">[base]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Base</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra</span></span><br><span class="line">baseurl=http://10.105.26.110/repos/centos/<span class="variable">$releasever</span>/os/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Updates</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra</span></span><br><span class="line">baseurl=http://10.105.26.110/repos/centos/<span class="variable">$releasever</span>/updates/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Extras</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra</span></span><br><span class="line">baseurl=http://10.105.26.110/repos/centos/<span class="variable">$releasever</span>/extras/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;安装httpd&quot;&gt;&lt;a href=&quot;#安装httpd&quot; class=&quot;headerlink&quot; title=&quot;安装httpd&quot;&gt;&lt;/a&gt;安装httpd&lt;/h6&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Centos7修改网卡名称</title>
    <link href="http://yoursite.com/2019/05/01/Centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/"/>
    <id>http://yoursite.com/2019/05/01/Centos7修改网卡名称/</id>
    <published>2019-04-30T17:17:00.000Z</published>
    <updated>2019-04-30T17:20:35.355Z</updated>
    
    <content type="html"><![CDATA[<h6 id="修改设备名称"><a href="#修改设备名称" class="headerlink" title="修改设备名称"></a>修改设备名称</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">"s/ens33/eth0/g"</span> /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure><h6 id="重命名网卡配置文件"><a href="#重命名网卡配置文件" class="headerlink" title="重命名网卡配置文件"></a>重命名网卡配置文件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure><h6 id="修改grub文件"><a href="#修改grub文件" class="headerlink" title="修改grub文件"></a>修改grub文件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">"s/root/root net.ifnames=0 biosdevname=0/g"</span> /etc/default/grub</span><br></pre></td></tr></table></figure><h6 id="重新生成GRUB配置并更新内核参数，稍后重启"><a href="#重新生成GRUB配置并更新内核参数，稍后重启" class="headerlink" title="重新生成GRUB配置并更新内核参数，稍后重启"></a>重新生成GRUB配置并更新内核参数，稍后重启</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;修改设备名称&quot;&gt;&lt;a href=&quot;#修改设备名称&quot; class=&quot;headerlink&quot; title=&quot;修改设备名称&quot;&gt;&lt;/a&gt;修改设备名称&lt;/h6&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutt
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Dockerfile CMD</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-CMD/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-CMD/</id>
    <published>2019-04-30T06:39:00.000Z</published>
    <updated>2019-04-30T09:25:57.567Z</updated>
    
    <content type="html"><![CDATA[<h6 id="CMD-与进程前后台和容器存活的关系"><a href="#CMD-与进程前后台和容器存活的关系" class="headerlink" title="CMD 与进程前后台和容器存活的关系"></a>CMD 与进程前后台和容器存活的关系</h6><p>设置镜像运行出来的容器的缺省命令</p><p>有两种写法，写多个和FROM一个已经有CMD的镜像的话，以最后一个为准<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CMD [<span class="string">"executable"</span>, <span class="string">"param1"</span>, <span class="string">"param2"</span>] </span><br><span class="line">CMD <span class="built_in">command</span> param1 param2</span><br></pre></td></tr></table></figure></p><p>前者是exec格式也是推荐格式，后者是/bin/sh格式，exec和CMD还有ENTRYPOINT这三者之间联系非常紧密，后面单独将相关的知识点。这里先用一个例子讲/bin/sh格式啥意思</p><p><img src="/images/pasted-8.png" alt="upload successful"></p><p>我们发现pid为1的是一个/bin/sh的进程，而我们的进程在容器里在后面。容器是单独一个pid namespaces的。这里懒得去做个图了，借用下别人的图</p><p><img src="/images/pasted-9.png" alt="upload successful"></p><p>默认下所有进程在一个顶级的pid namespaces里，pid namespaces像一个树一样。从根到最后可以多级串。容器的pid namespaces实际上是在宿主机上能看到的，也就是下面，我们可以看到容器在宿主机上的进程，由于子namespaces无法看到父级的namespaces，所以容器里第一个进程(也就是cmd)认为自己是pid为1，容器里其余进程都是它的子进程</p><p><img src="/images/pasted-10.png" alt="upload successful"></p><p>在Linux中，只能给init已经安装信号处理函数的信号，其它信号都会被忽略，这可以防止init进程被误杀掉，即使是superuser。所以，kill -9 init不会kill掉init进程。但是容器的进程是在容器的ns里是init级别，我们可以在宿主机上杀掉它，之前线上的低版本docker 命令无法使用，同事无法停止错误容器，我便询问了进程名在宿主机找到后kill掉的。</p><p><img src="/images/pasted-11.png" alt="upload successful"></p><p>接下来说说为啥推荐exec格式，exec格式的话第一个进程是我们的sleep进程，大家可以自己去构建镜像试试。推荐用exec格式是因为pid 为1的进程承担着pid namespaces的存活周期，听不懂的话我举个例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]<span class="comment"># docker run -d alpine ls</span></span><br><span class="line">b2eedc510e718d2820ce79fcf630aa9521fc3525b9138a51f1f8bef496e2607a</span><br><span class="line">[root@docker ~]<span class="comment"># docker run -d alpine sleep 10</span></span><br><span class="line">bee830e62508b52796f588d6defe5419e35acb6c944f0151e0cb4b40a260ef81</span><br><span class="line">[root@docker ~]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES</span><br><span class="line">bee830e62508        alpine              <span class="string">"sleep 10"</span>          19 seconds ago      Exited (0) 7 seconds ago                        sad_lamarr</span><br><span class="line">b2eedc510e71        alpine              <span class="string">"ls"</span>                28 seconds ago      Exited (0) 26 seconds ago                       reverent_stallman</span><br></pre></td></tr></table></figure></p><p>先看下docker run命令格式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run --help</span></span><br><span class="line"></span><br><span class="line">Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure></p><p>docker run 后面镜像后面的command和arg会覆盖掉镜像的CMD。上面我那个例子覆盖掉centos镜像默认的CMD bash。我们可以看到ls的容器直接退出了，但是sleep 10的容器运行了10秒后就退出了。以上也说明了容器不是虚拟机，容器是个隔离的进程。</p><p>这说明了容器的存活是容器里pid为1的进程运行时长决定的。所以nginx的官方镜像里就是用的exec格式让nginx充当pid为1的角色。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span><br></pre></td></tr></table></figure></p><p>这里nginx启动带了选项是什么意思呢，我举个初学者自己造轮子做nginx镜像来举例，也顺带按照初学者重复造轮子碰到错误的时候应该怎样去排查？上面我是按照初学者虚拟机的思维去做一个nginx镜像，结果构建错误，我们发现有个失败的容器就是RUN那层创建出来的，前面我说的实际上docker build就是运行容器执行步骤然后最后底层调用commit的原因。</p><p>现在我们来手动排下错，哪步报错可以把那步到后面的全部注释掉后构建个镜像，然后我们run起来的时候带上-ti选项分配一个能输入的伪终端，最后的command用sh或者bash，这样容器的主进程就是bash或者sh了，我们在里面执行报错的RUN(这里我例子简单，所以我直接run -ti centos bash)。实际上会发现nginx是在epel-release的源里，接下来改下Dockerfile再构建试试.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat Dockerfile</span></span><br><span class="line">FROM centos</span><br><span class="line">RUN yum install -y epel-release \</span><br><span class="line">    &amp;&amp; yum install -y nginx</span><br><span class="line">CMD [<span class="string">"nginx"</span>]</span><br><span class="line">$ docker build -t <span class="built_in">test</span> .</span><br></pre></td></tr></table></figure></p><p>然后又是一个新手自己做镜像遇到的问题了，这个镜像运行了根本跑不起来，我们手动bash或者sh进去排查。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -p 80:80 <span class="built_in">test</span></span><br><span class="line">f13e98d4dc13b6fa13e375ca35cc58a23a340a07b677f0df245fc1ef3b7199c6</span><br><span class="line">$ docker ps -a</span><br><span class="line">CONTAINER ID     IMAGE        COMMAND      CREATED             STATUS                    PORTS               NAMES</span><br><span class="line">f13e98d4dc13     <span class="built_in">test</span>         <span class="string">"nginx"</span>      3 seconds ago       Exited (0) 1 second ago                       determined_elgamal</span><br></pre></td></tr></table></figure></p><p>似乎是卡主了？我们可以访问宿主机的ip:80看看会发现实际能访问到的，也就是说这样也是在运行，当然我们把CMD改成和官方一样直接docker run -d -p 80:80 test的话容器是不会退出的。</p><p>至于说为啥？答案就是前台的概念！</p><p>我们有没有发现我们手动执行nginx带关闭daemon选项发现类似于hang住一样，实际上它就是前台跑。</p><p>单独的nginx回车，实际上是它拉起来了nginx，然后它退出了，但是！！！，别忘记了你这个nginx是pid为1的角色，你退出了你下面子进程全部完蛋，容器也会显示退出。所以既然你最终要跑nginx，你nginx得是前台跑。</p><p>但是这里肯定也有人说如果我主进程跑一个不退出的进程，然后进去启动nginx不也跑起来了吗？这样是可以的，但是存在信号转发机制和要考虑优雅退出，这块知识我在后面指令STOPSIGNAL讲。</p><p>判断一个命令(或者说带上选项)是不是前台跑的最简单一个验证就是(主进程sh或者bash进去后)执行它看它有没有回到终端。例如ls和yes命令，我们会发现yes命令一直刷y没有回到终端。</p><p>其实发展到现在，很多以前只有daemon后台跑的进程都慢慢的在docker火热下开始有前台运行的选项或者配置了，例如</p><ul><li>redis的配置文件不写日志文件路径它就默认前台跑</li><li>uwsgi也是一样，命令行参数或者配置文件指定了日志文件路径就后台跑，否则前台跑</li><li>node本身是前台跑，但是一些信号可能不好处理，于是有了pm2</li><li>zabbix 的日志路径写console的话就是前台跑</li></ul><p>其实我们用上前台选项的话也无法用docker logs看容器的log，是因为docker logs查看的是容器里的标准输出信息，我们可以看到官方nginx镜像Dockerfile是这样做的。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># forward request and error logs to docker log collector</span></span><br><span class="line">&amp;&amp; ln -sf /dev/stdout /var/<span class="built_in">log</span>/nginx/access.log \</span><br><span class="line">&amp;&amp; ln -sf /dev/stderr /var/<span class="built_in">log</span>/nginx/error.log</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;CMD-与进程前后台和容器存活的关系&quot;&gt;&lt;a href=&quot;#CMD-与进程前后台和容器存活的关系&quot; class=&quot;headerlink&quot; title=&quot;CMD 与进程前后台和容器存活的关系&quot;&gt;&lt;/a&gt;CMD 与进程前后台和容器存活的关系&lt;/h6&gt;&lt;p&gt;设置镜像运行
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile EXPOSE</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-EXPOSE/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-EXPOSE/</id>
    <published>2019-04-30T06:33:00.000Z</published>
    <updated>2019-04-30T06:35:38.651Z</updated>
    
    <content type="html"><![CDATA[<h6 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h6><p>用法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]</span><br></pre></td></tr></table></figure></p><p>例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE 80/tcp</span><br><span class="line">EXPOSE 80/udp</span><br><span class="line">EXPOSE 80 443</span><br></pre></td></tr></table></figure></p><p>声明需要暴露的端口（缺省tcp），仅仅是声明并没有说写了它才能映射端口，对容器网络不熟悉的话后面会讲容器网络的。我们可以看到nginx官方镜像的Dockerfile里有写80。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE 80</span><br></pre></td></tr></table></figure></p><p>我们假设简单的run起来让外部访问的话可以这样<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 80:80 nginx:alpine</span><br></pre></td></tr></table></figure></p><p>这条命令是使用nginx:alpine镜像运行一个容器，把宿主机的80映射到容器的80端口上，我们可以访问宿主机ip:80就可以看到默认nginx的index页面，如果说是云主机80可能需要备案，可以改成81:80。可以自己把nginx官方dockerfile的EXPOSE删掉发现还可以映射的。</p><p>EXPOSE作用是告诉使用者应该把容器的哪个端口暴漏出去。另一个作用给docker run -P用的。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -P nginx:alpine</span><br></pre></td></tr></table></figure></p><p>会映射宿主机上随机没被bind的端口到EXPOSE的端口，例如 random_port:80</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;EXPOSE&quot;&gt;&lt;a href=&quot;#EXPOSE&quot; class=&quot;headerlink&quot; title=&quot;EXPOSE&quot;&gt;&lt;/a&gt;EXPOSE&lt;/h6&gt;&lt;p&gt;用法&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile ONBUILD</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-ONBUILD/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-ONBUILD/</id>
    <published>2019-04-30T06:28:00.000Z</published>
    <updated>2019-04-30T06:29:26.101Z</updated>
    
    <content type="html"><![CDATA[<h6 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h6><p>用法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONBUILD [INSTRUCTION]</span><br></pre></td></tr></table></figure></p><p>构建的时候并不会执行，只有在构建出来的镜像被FROM的时候才执行，例如<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM xxxx</span><br><span class="line">ONBUILD RUN <span class="built_in">cd</span> /root/ &amp;&amp; wget xxxx</span><br></pre></td></tr></table></figure></p><p>然后构建出镜像B里root目录并没有下载东西，只有FROM B构建的镜像才会执行这个RUN，这个用得很少，记住即可</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;ONBUILD&quot;&gt;&lt;a href=&quot;#ONBUILD&quot; class=&quot;headerlink&quot; title=&quot;ONBUILD&quot;&gt;&lt;/a&gt;ONBUILD&lt;/h6&gt;&lt;p&gt;用法&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile USER</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-USER/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-USER/</id>
    <published>2019-04-30T06:27:00.000Z</published>
    <updated>2019-04-30T06:27:54.607Z</updated>
    
    <content type="html"><![CDATA[<h6 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h6><p>两种写法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">USER &lt;user&gt;[:&lt;group&gt;] or</span><br><span class="line">USER &lt;UID&gt;[:&lt;GID&gt;]</span><br></pre></td></tr></table></figure></p><p>USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。</p><p>当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。可用可不用。</p><p>不用的情况建议给容器的最终进程指定用户去运行，例如nginx官方添加了一个不登陆的nginx用户，配置文件里指定使用这个用户运行nginx。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;USER&quot;&gt;&lt;a href=&quot;#USER&quot; class=&quot;headerlink&quot; title=&quot;USER&quot;&gt;&lt;/a&gt;USER&lt;/h6&gt;&lt;p&gt;两种写法&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;g
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile WORKDIR</title>
    <link href="http://yoursite.com/2019/04/30/Do/"/>
    <id>http://yoursite.com/2019/04/30/Do/</id>
    <published>2019-04-30T05:59:00.000Z</published>
    <updated>2019-04-30T06:12:29.352Z</updated>
    
    <content type="html"><![CDATA[<h6 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h6><p>声明后续指令的工作目录，目录不存在则创建，可以理解为mkdir -p dir &amp;&amp; cd dir</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /path/to/workdir</span><br></pre></td></tr></table></figure><p>可以在a中多次使用Dockerfile。如果提供了相对路径，则它将相对于前一条WORKDIR指令的路径 。例如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN <span class="built_in">pwd</span></span><br></pre></td></tr></table></figure></p><p>最终pwd命令的输出Dockerfile将是 /a/b/c</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;WORKDIR&quot;&gt;&lt;a href=&quot;#WORKDIR&quot; class=&quot;headerlink&quot; title=&quot;WORKDIR&quot;&gt;&lt;/a&gt;WORKDIR&lt;/h6&gt;&lt;p&gt;声明后续指令的工作目录，目录不存在则创建，可以理解为mkdir -p dir &amp;amp;&amp;amp; 
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile ADD</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-ADD/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-ADD/</id>
    <published>2019-04-30T05:56:00.000Z</published>
    <updated>2019-04-30T06:12:12.831Z</updated>
    
    <content type="html"><![CDATA[<h6 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h6><p>和COPY一样，但是源可以是一个url会自动下载，另外源是压缩包的话会自动解压，但是实际中不会使用它，因为前面讲RUN的时候说的层概念。例如下面是一个ADD用的多的举例<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ADD https://xxxxx/name.tar.gz /home/<span class="built_in">test</span>/</span><br><span class="line">RUN <span class="built_in">cd</span> /home/<span class="built_in">test</span> &amp;&amp; \</span><br><span class="line">    编译安装... \</span><br><span class="line">    rm -rf /home/<span class="built_in">test</span></span><br></pre></td></tr></table></figure></p><p>ADD下载源码包，然后RUN里编译安装完删除源码包。实际上后面的层起来的容器虽说读取不到源码包了，但是还是在镜像里，参照我之前的RUN里那个test.html的例子。</p><p>一般避免多余的层和容量都是RUN里去下载源码包，处理完后删掉源码包，参照nginx的dockerfile的第一个RUN。 </p><p><a href="https://github.com/nginxinc/docker-nginx/blob/7d7c67f2eaa6b2b32c718ba9d93f152870513c7c/mainline/alpine/Dockerfile#L7" target="_blank" rel="noopener">https://github.com/nginxinc/docker-nginx/blob/7d7c67f2eaa6b2b32c718ba9d93f152870513c7c/mainline/alpine/Dockerfile#L7</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;ADD&quot;&gt;&lt;a href=&quot;#ADD&quot; class=&quot;headerlink&quot; title=&quot;ADD&quot;&gt;&lt;/a&gt;ADD&lt;/h6&gt;&lt;p&gt;和COPY一样，但是源可以是一个url会自动下载，另外源是压缩包的话会自动解压，但是实际中不会使用它，因为前面讲RUN的时候说的层概
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile COPY</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-COPY/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-COPY/</id>
    <published>2019-04-30T05:42:00.000Z</published>
    <updated>2019-04-30T06:12:02.622Z</updated>
    
    <content type="html"><![CDATA[<h6 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h6><p>用法<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">COPY &lt;src&gt;  &lt;dest&gt;  </span><br><span class="line">COPY [<span class="string">"&lt;src&gt;"</span>,... <span class="string">"&lt;dest&gt;"</span>]  </span><br><span class="line">COPY home* /home</span><br></pre></td></tr></table></figure></p><p>复制本地的文件到容器中的目录，目录不存在则会自动创建，源可以是多个。在低版本的docker里如果源是绝对路径例如/root/data/nginx的话会把整个系统的根上传到docker daemon，会发现上传的内容等同于根的已用容量，例如下面<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cat Dockerfile</span><br><span class="line">FROM alpine</span><br><span class="line">COPY /root/data/nginx.tar.gz /root/home</span><br><span class="line">$ docker build -t <span class="built_in">test</span> .</span><br><span class="line">Sending build context to Docker daemon  7.8GB</span><br></pre></td></tr></table></figure></p><p>主要是因为上下文的概念，认为上下文的根是client的/，所以会把客户端的/上传到docker daemon，现在新版本是强制相对路径了，如果是绝对路径会报错。相对路径相对于build最后的.这个上下文路径为相对路径。</p><p>另外COPY还能指定uid:gid，如果容器的rootfs里没有文件/etc/passwd和/etc/group文件只能使用数字不能使用组名。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">COPY --chown=55:mygroup files* /somedir/</span><br><span class="line">COPY --chown=bin files* /somedir/</span><br><span class="line">COPY --chown=1 files* /somedir/</span><br><span class="line">COPY --chown=10:11 files* /somedir/</span><br></pre></td></tr></table></figure></p><p>COPY接受一个标志–from=&lt;name|index&gt;，该标志可用于将源位置设置为FROM .. AS <name> 主要用于多阶段构建，后面会举个例子来讲解多阶段构建，多阶段构建是17.05之后才出现的功能。</name></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;COPY&quot;&gt;&lt;a href=&quot;#COPY&quot; class=&quot;headerlink&quot; title=&quot;COPY&quot;&gt;&lt;/a&gt;COPY&lt;/h6&gt;&lt;p&gt;用法&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile RUN</title>
    <link href="http://yoursite.com/2019/04/30/Dockerfile-RUN/"/>
    <id>http://yoursite.com/2019/04/30/Dockerfile-RUN/</id>
    <published>2019-04-30T05:05:00.000Z</published>
    <updated>2019-04-30T06:11:56.631Z</updated>
    
    <content type="html"><![CDATA[<h6 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h6><p>有两种形式</p><ul><li>RUN command ( 该命令在shell中运行，默认情况下在Linux上是/bin/sh -c或windows的cmd /S /C)</li><li>RUN [“executable”, “param1”, “param2”] (exec 形式)</li></ul><p>exec形式不会调用shell先展开变量，也就是不会解析ENV或者ARG的变量，所以一般来讲用得比较多的就是第一种形式，多行的话可以利用\换行。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">RUN  .....\</span><br><span class="line">    &amp;&amp; addgroup -S nginx \</span><br><span class="line">&amp;&amp; adduser -D -S -h /var/cache/nginx -s /sbin/nologin -G nginx nginx \</span><br><span class="line">&amp;&amp; apk add --no-cache --virtual .build-deps \</span><br><span class="line">.....</span><br></pre></td></tr></table></figure></p><p>这里要注意的是一个RUN是一层，dockerfile的一些涉及到文件的指令和RUN都会是新的一层，主要是构建过程实际上还是容器去commit，目的相同的RUN尽量合并在同一个RUN里减少大小。下面我做个例子来说明原因<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine</span><br><span class="line">RUN apk add wget  &amp;&amp; wget https://www.baidu.com -O test.html</span><br><span class="line">RUN <span class="built_in">echo</span> 123 &gt; test.html</span><br></pre></td></tr></table></figure></p><p>构建并运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker build -t test .</span></span><br><span class="line">Sending build context to Docker daemon  2.048kB</span><br><span class="line">Step 1/3 : FROM alpine</span><br><span class="line"> ---&gt; cdf98d1859c1</span><br><span class="line">Step 2/3 : RUN apk add wget  &amp;&amp; wget https://www.baidu.com -O test.html</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 07bd55d265b8</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/1) Installing wget (1.20.3-r0)</span><br><span class="line">Executing busybox-1.29.3-r10.trigger</span><br><span class="line">OK: 6 MiB <span class="keyword">in</span> 15 packages</span><br><span class="line">--2019-04-30 05:38:10--  https://www.baidu.com/</span><br><span class="line">Resolving www.baidu.com... 58.217.200.39, 58.217.200.37</span><br><span class="line">Connecting to www.baidu.com|58.217.200.39|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 2443 (2.4K) [text/html]</span><br><span class="line">Saving to: <span class="string">'test.html'</span></span><br><span class="line"></span><br><span class="line">     0K ..                                                    100% 21.8M=0s</span><br><span class="line"></span><br><span class="line">2019-04-30 05:38:10 (21.8 MB/s) - <span class="string">'test.html'</span> saved [2443/2443]</span><br><span class="line"></span><br><span class="line">Removing intermediate container 07bd55d265b8</span><br><span class="line"> ---&gt; 9420c50ef6f7</span><br><span class="line">Step 3/3 : RUN <span class="built_in">echo</span> 123 &gt; test.html</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 8724c012ff49</span><br><span class="line">Removing intermediate container 8724c012ff49</span><br><span class="line"> ---&gt; b924abffdb62</span><br><span class="line">Successfully built b924abffdb62</span><br><span class="line">Successfully tagged <span class="built_in">test</span>:latest</span><br></pre></td></tr></table></figure></p><p>运行然后查看docker的存储目录查找<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]<span class="comment"># docker run --rm test cat test.html</span></span><br><span class="line">123</span><br><span class="line">[root@docker ~]<span class="comment"># find /var/lib/docker/overlay2/ -type f -name test.html</span></span><br><span class="line">/var/lib/docker/overlay2/3c4530c7cd077e1d6ec74135679fe7234eddc88fe72ada21f632cebfd26de4f5/diff/test.html</span><br><span class="line">/var/lib/docker/overlay2/802018b95e4f9b16e9946e2e827db5c3b0cd8631ac0759c31dffea212ff06d4f/diff/test.html</span><br><span class="line">[root@docker ~]<span class="comment"># cat /var/lib/docker/overlay2/3c4530c7cd077e1d6ec74135679fe7234eddc88fe72ada21f632cebfd26de4f5/diff/test.html</span></span><br><span class="line">123</span><br><span class="line">[root@docker ~]<span class="comment"># cat /var/lib/docker/overlay2/802018b95e4f9b16e9946e2e827db5c3b0cd8631ac0759c31dffea212ff06d4f/diff/test.html</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br></pre></td></tr></table></figure></p><p>发现两个文件都存在，前面说到了容器在读取文件的时候从上层往下查找，查找到了就返回，但是我的这个Dockerfile里第一个RUN下载了index页面，第二个改了文件内容。</p><p>可以证明一个RUN是一层，也证明了之前容器读取文件的逻辑。同时假设我们的目的是最终的123，我们可以俩个RUN合并了，这样就不会有多余的第一个RUN产生的test.html文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;RUN&quot;&gt;&lt;a href=&quot;#RUN&quot; class=&quot;headerlink&quot; title=&quot;RUN&quot;&gt;&lt;/a&gt;RUN&lt;/h6&gt;&lt;p&gt;有两种形式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RUN command ( 该命令在shell中运行，默认情况下在Linux上是/bin/sh
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
</feed>
